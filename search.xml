<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>【图像分类—ResNet V1】Deep Residual Learning for Image Recognition</title>
      <link href="/article/8.html"/>
      <url>/article/8.html</url>
      
        <content type="html"><![CDATA[<p>论文解决的主要问题是深层的神经网络很难训练；提出了一种残差学习框架来减轻网络训练。</p><a id="more"></a><p><img src="https://img-blog.csdnimg.cn/2021022417083119.png?text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTgzOTAzOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="一-、论文翻译"><a href="#一-、论文翻译" class="headerlink" title="一 、论文翻译"></a>一 、论文翻译</h1><blockquote><p>paper:<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a><a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" target="_blank" rel="noopener"> </a></p></blockquote><blockquote><p>论文解决的主要问题是深层的神经网络很难训练；提出了一种残差学习框架来减轻网络训练。</p></blockquote><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>更深的神经网络更难训练。我们提出了一种残差学习框架来减轻网络训练，这些网络比以前使用的网络更深。我们明确地将层变为学习关于层输入的残差函数，而不是学习未参考的函数。我们提供了全面的经验证据说明这些残差网络很容易优化，并可以显著增加深度来提高准确性。在ImageNet数据集上我们评估了深度高达152层的残差网络——比VGG深8倍但仍具有较低的复杂度。这些残差网络的集合在ImageNet测试集上取得了3.57%的错误率。这个结果在ILSVRC 2015分类任务上赢得了第一名。我们也在CIFAR-10上分析了100层和1000层的残差网络。</p><p>对于许多视觉识别任务而言，表示的深度是至关重要的。仅由于我们非常深度的表示，我们便在COCO目标检测数据集上得到了28%的相对提高。深度残差网络是我们向ILSVRC和COCO 2015竞赛提交的基础，我们也赢得了ImageNet检测任务，ImageNet定位任务，COCO检测和COCO分割任务的第一名。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>深度卷积神经网络导致了图像分类的一系列突破。深度网络自然地将低/中/高级特征和分类器以端到端多层方式进行集成，特征的“级别”可以通过堆叠层的数量（深度）来丰富。最近的证据显示网络深度至关重要，在具有挑战性的ImageNet数据集上领先的结果都采用了“非常深”的模型，深度从16到30之间。许多其它重要的视觉识别任务也从非常深的模型中得到了极大受益。</p><p>在深度重要性的推动下，出现了一个问题：学些更好的网络是否像堆叠更多的层一样容易？回答这个问题的一个障碍是梯度消失/爆炸这个众所周知的问题，它从一开始就阻碍了收敛。然而，这个问题通过标准初始化和中间标准化层在很大程度上已经解决，这使得数十层的网络能通过具有反向传播的随机梯度下降（SGD）开始收敛。</p><p>当更深的网络能够开始收敛时，暴露了一个退化问题：随着网络深度的增加，准确率达到饱和（这可能并不奇怪）然后迅速下降。意外的是，这种下降不是由过拟合引起的，并且在适当的深度模型上添加更多的层会导致更高的训练误差，正如中报告的那样，并且由我们的实验完全证实。图1显示了一个典型的例子。<br><img src="https://img-blog.csdnimg.cn/20210117163439557.png#pic_center" alt="在这里插入图片描述"></p><p>图1 20层和56层的“简单”网络在CIFAR-10上的训练误差（左）和测试误差（右）。更深的网络有更高的训练误差和测试误差。ImageNet上的类似现象如图4所示。</p><p>退化（训练准确率）表明不是所有的系统都很容易优化。让我们考虑一个较浅的架构及其更深层次的对象，为其添加更多的层。存在通过构建得到更深层模型的解决方案：添加的层是恒等映射，其他层是从学习到的较浅模型的拷贝。 这种构造解决方案的存在表明，较深的模型不应该产生比其对应的较浅模型更高的训练误差。但是实验表明，我们目前现有的解决方案无法找到与构建的解决方案相比相对不错或更好的解决方案（或在合理的时间内无法实现）。</p><p>在本文中，我们通过引入深度残差学习框架解决了退化问题。我们明确地让这些层拟合残差映射，而不是希望每几个堆叠的层直接拟合期望的基础映射。形式上，将期望的基础映射表示为$H(x)$，我们将堆叠的非线性层拟合另一个映射$F(x):=H(x)−x$。原始的映射重写为$F(x)+x$。我们假设残差映射比原始的、未参考的映射更容易优化。在极端情况下，如果一个恒等映射是最优的，那么将残差置为零比通过一堆非线性层来拟合恒等映射更容易。</p><p>公式F(x)+x可以通过带有“快捷连接”的前向神经网络（图2）来实现。快捷连接是那些跳过一层或更多层的连接。在我们的案例中，快捷连接简单地执行恒等映射，并将其输出添加到堆叠层的输出（图2）。恒等快捷连接既不增加额外的参数也不增加计算复杂度。整个网络仍然可以由带有反向传播的SGD进行端到端的训练，并且可以使用公共库轻松实现，而无需修改求解器。<br><img src="https://img-blog.csdnimg.cn/20210117163620107.png#pic_center" alt="在这里插入图片描述"></p><center>图2. 残差学习：构建块</center><br><p>我们在ImageNet上进行了综合实验来显示退化问题并评估我们的方法。我们发现：1）我们极深的残差网络易于优化，但当深度增加时，对应的“简单”网络（简单堆叠层）表现出更高的训练误差；2）我们的深度残差网络可以从大大增加的深度中轻松获得准确性收益，生成的结果实质上比以前的网络更好。</p><p>CIFAR-10数据集上也显示出类似的现象，这表明了优化的困难以及我们的方法的影响不仅仅是针对一个特定的数据集。我们在这个数据集上展示了成功训练的超过100层的模型，并探索了超过1000层的模型。</p><p>在ImageNet分类数据集中，我们通过非常深的残差网络获得了很好的结果。我们的152层残差网络是ImageNet上最深的网络，同时还具有比VGG网络更低的复杂性。我们的模型集合在ImageNet测试集上有3.57% top-5的错误率，并在ILSVRC 2015分类比赛中获得了第一名。极深的表示在其它识别任务中也有极好的泛化性能，并带领我们在进一步赢得了第一名：包括ILSVRC &amp; COCO 2015竞赛中的ImageNet检测，ImageNet定位，COCO检测和COCO分割。坚实的证据表明残差学习准则是通用的，并且我们期望它适用于其它的视觉和非视觉问题。</p><h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><p>残差表示。在图像识别中，VLAD是一种通过关于字典的残差向量进行编码的表示形式，Fisher矢量可以表示为VLAD的概率版本。它们都是图像检索和图像分类中强大的浅层表示。对于矢量量化，编码残差矢量被证明比编码原始矢量更有效。</p><p>在低级视觉和计算机图形学中，为了求解偏微分方程（PDE），广泛使用的Multigrid方法将系统重构为在多个尺度上的子问题，其中每个子问题负责较粗尺度和较细尺度的残差解。Multigrid的替代方法是层次化基础预处理，它依赖于表示两个尺度之间残差向量的变量。已经被证明这些求解器比不知道解的残差性质的标准求解器收敛得更快。这些方法表明，良好的重构或预处理可以简化优化。</p><p>快捷连接。导致快捷连接的实践和理论已经被研究了很长时间。训练多层感知机（MLP）的早期实践是添加一个线性层来连接网络的输入和输出。一些中间层直接连接到辅助分类器，用于解决梯度消失/爆炸。其它论文提出了通过快捷连接实现层间响应，梯度和传播误差的方法。在[44]中，一个“inception”层由一个快捷分支和一些更深的分支组成。</p><p>和我们同时进行的工作，“highway networks” 提出了门功能的快捷连接。这些门是数据相关且有参数的，与我们不具有参数的恒等快捷连接相反。当门控快捷连接“关闭”（接近零）时，高速网络中的层表示非残差函数。相反，我们的公式总是学习残差函数；我们的恒等快捷连接永远不会关闭，所有的信息总是通过，还有额外的残差函数要学习。此外，高速网络还没有证实极度增加的深度（例如，超过100个层）带来的准确性收益。</p><h2 id="3-深度残差学习"><a href="#3-深度残差学习" class="headerlink" title="3 深度残差学习"></a>3 深度残差学习</h2><h3 id="3-1-残差学习"><a href="#3-1-残差学习" class="headerlink" title="3.1 残差学习"></a>3.1 残差学习</h3><p>我们考虑H(x)作为几个堆叠层（不必是整个网络）要拟合的基础映射，x表示这些层中第一层的输入。假设多个非线性层可以渐近地近似复杂函数，它等价于假设它们可以渐近地近似残差函数，即H(x)−x(假设输入输出是相同维度)。因此，我们明确让这些层近似参数函数 F(x):=H(x)−x，而不是期望堆叠层近似H(x)。因此原始函数变为F(x)+x。尽管两种形式应该都能渐近地近似要求的函数（如假设），但学习的难易程度可能是不同的。</p><p>关于退化问题的反直觉现象激发了这种重构（图1左）。正如我们在引言中讨论的那样，如果添加的层可以被构建为恒等映射，更深模型的训练误差应该不大于它对应的更浅版本。退化问题表明求解器通过多个非线性层来近似恒等映射可能有困难。通过残差学习的重构，如果恒等映射是最优的，求解器可能简单地将多个非线性连接的权重推向零来接近恒等映射。</p><p>在实际情况下，恒等映射不太可能是最优的，但是我们的重构可能有助于对问题进行预处理。如果最优函数比零映射更接近于恒等映射，则求解器应该更容易找到关于恒等映射的抖动，而不是将该函数作为新函数来学习。我们通过实验（图7）显示学习的残差函数通常有更小的响应，表明恒等映射提供了合理的预处理。<br><img src="https://img-blog.csdnimg.cn/20210117163809689.png#pic_center" alt="在这里插入图片描述"><br>图7。层响应在CIFAR-10上的标准差（std）。这些响应是每个3×3层的输出，在BN之后非线性之前。上面：以原始顺序显示层。下面：响应按降序排列。</p><h3 id="3-2-快捷恒等映射"><a href="#3-2-快捷恒等映射" class="headerlink" title="3.2 快捷恒等映射"></a>3.2 快捷恒等映射</h3><p>我们每隔几个堆叠层采用残差学习。构建块如图2所示。在本文中我们考虑构建块正式定义为：</p><p>$$y=F(x,W_i)+x \tag{1}$$<br>$x$和$y$是考虑的层的输入和输出向量。函数$F(x,W_i)$表示要学习的残差映射。图2中的例子有两层，$F=W_2\sigma(W_1x)$中$\sigma$表示ReLU，为了简化写法忽略偏置项。$F+x$操作通过快捷连接和各个元素相加来执行。在相加之后我们采纳了第二种非线性（即$\sigma(y)$，看图2）。</p><p>方程(1)中的快捷连接既没有引入外部参数又没有增加计算复杂度。这不仅在实践中有吸引力，而且在简单网络和残差网络的比较中也很重要。我们可以公平地比较同时具有相同数量的参数，相同深度，宽度和计算成本的简单/残差网络（除了不可忽略的元素加法之外）。</p><p>方程(1)中$x$和$F$的维度必须是相等的。如果不是这种情况（例如，当更改输入/输出通道时），我们可以通过快捷连接执行线性投影Ws来匹配维度：</p><p>$$y=F(x,W_i)+W_sx \tag{2}$$<br>我们也可以使用方程(1)中的方阵Ws。但是我们将通过实验表明，恒等映射足以解决退化问题，并且是合算的，因此Ws仅在匹配维度时使用。</p><p>残差函数$F$的形式是可变的。本文中的实验包括有两层或三层（图5）的函数F，同时可能有更多的层。但如果$F$只有一层，方程(1)类似于线性层：$y=W_1x+x$，我们没有看到优势。</p><p><img src="https://img-blog.csdnimg.cn/20210117163857859.png#pic_center" alt="在这里插入图片描述"><br>图5。ImageNet的深度残差函数F。左：ResNet-34的构建块（在56×56的特征图上），如图3。右：ResNet-50/101/152的“bottleneck”构建块。</p><p>我们还注意到，为了简单起见，尽管上述符号是关于全连接层的，但它们同样适用于卷积层。函数$F(x,W_i)$可以表示多个卷积层。元素加法在两个特征图上逐通道进行。</p><h3 id="3-3-网络架构"><a href="#3-3-网络架构" class="headerlink" title="3.3. 网络架构"></a>3.3. 网络架构</h3><p>我们测试了各种简单/残差网络，并观察到了一致的现象。为了提供讨论的实例，我们描述了ImageNet的两个模型如下。</p><p><strong>简单网络</strong>。 我们简单网络的基准（图3，中间）主要受到VGG网络（图3，左图）的哲学启发。卷积层主要有3×3的滤波器，并遵循两个简单的设计规则：（i）对于相同的输出特征图尺寸，层具有相同数量的滤波器；（ii）如果特征图尺寸减半，则滤波器数量加倍，以便保持每层的时间复杂度。我们通过步长为2的卷积层直接执行下采样。网络以全局平均池化层和具有softmax的1000维全连接层结束。图3（中间）的加权层总数为34。</p><p><img src="https://img-blog.csdnimg.cn/20210117164024281.png#pic_center" alt="在这里插入图片描述"></p><p>图3。ImageNet的网络架构例子。左：作为参考的VGG-19模型40。中：具有34个参数层的简单网络（36亿FLOPs）。右：具有34个参数层的残差网络（36亿FLOPs）。带点的快捷连接增加了维度。表1显示了更多细节和其它变种。</p><p><img src="https://img-blog.csdnimg.cn/20210117164108856.png#pic_center" alt="在这里插入图片描述"><br>表1。ImageNet架构。构建块显示在括号中（也可看图5），以及构建块的堆叠数量。下采样通过步长为2的conv3_1, conv4_1和conv5_1执行。</p><p>值得注意的是我们的模型与VGG网络（图3左）相比，有更少的滤波器和更低的复杂度。我们的34层基准有36亿FLOP(乘加)，仅是VGG-19（196亿FLOP）的18%。</p><p><strong>残差网络</strong>。 基于上述的简单网络，我们插入快捷连接（图3，右），将网络转换为其对应的残差版本。当输入和输出具有相同的维度时（图3中的实线快捷连接）时，可以直接使用恒等快捷连接（方程（1））。当维度增加（图3中的虚线快捷连接）时，我们考虑两个选项：（A）快捷连接仍然执行恒等映射，额外填充零输入以增加维度。此选项不会引入额外的参数；（B）方程（2）中的投影快捷连接用于匹配维度（由1×1卷积完成）。对于这两个选项，当快捷连接跨越两种尺寸的特征图时，它们执行时步长为2。</p><h3 id="3-4-实现"><a href="#3-4-实现" class="headerlink" title="3.4 实现"></a>3.4 实现</h3><p>ImageNet中我们的实现遵循的实践。调整图像大小，其较短的边在[256,480]之间进行随机采样，用于尺度增强。224×224裁剪是从图像或其水平翻转中随机采样，并逐像素减去均值。使用了标准颜色增强。在每个卷积之后和激活之前，我们采用批量归一化（BN）。我们按照[13]的方法初始化权重，从零开始训练所有的简单/残差网络。我们使用批大小为256的SGD方法。学习速度从0.1开始，当误差稳定时学习率除以10，并且模型训练高达$60 \times10^4$次迭代。我们使用的权重衰减为0.0001，动量为0.9。</p><p>在测试阶段，为了比较学习我们采用标准的10-crop测试。对于最好的结果，我们采用全卷积形式，并在多尺度上对分数进行平均（图像归一化，短边位于{224, 256, 384, 480, 640}中）。</p><h2 id="4-实验"><a href="#4-实验" class="headerlink" title="4 实验"></a>4 实验</h2><h3 id="4-1-ImageNet分类"><a href="#4-1-ImageNet分类" class="headerlink" title="4.1 ImageNet分类"></a>4.1 ImageNet分类</h3><p>我们在ImageNet 2012分类数据集对我们的方法进行了评估，该数据集由1000个类别组成。这些模型在128万张训练图像上进行训练，并在5万张验证图像上进行评估。我们也获得了测试服务器报告的在10万张测试图像上的最终结果。我们评估了top-1和top-5错误率。</p><p>简单网络。我们首先评估18层和34层的简单网络。34层简单网络在图3（中间）。18层简单网络是一种类似的形式。有关详细的体系结构，请参见表1。</p><p>表2中的结果表明，较深的34层简单网络比较浅的18层简单网络有更高的验证误差。为了揭示原因，在图4（左图）中，我们比较训练过程中的训练/验证误差。我们观察到退化问题——虽然18层简单网络的解空间是34层简单网络解空间的子空间，但34层简单网络在整个训练过程中具有较高的训练误差。</p><p><img src="https://img-blog.csdnimg.cn/2021011716423757.png#pic_center" alt="在这里插入图片描述"><br>表2。ImageNet验证集上的Top-1错误率(%，10个裁剪图像测试)。相比于对应的简单网络，ResNet没有额外的参数。图4显示了训练过程。</p><p><img src="https://img-blog.csdnimg.cn/20210117164339696.png#pic_center" alt="在这里插入图片描述"><br>图4。在ImageNet上训练。细曲线表示训练误差，粗曲线表示中心裁剪图像的验证误差。左：18层和34层的简单网络。右：18层和34层的ResNet。在本图中，残差网络与对应的简单网络相比没有额外的参数。</p><p>我们认为这种优化难度不可能是由于梯度消失引起的。这些简单网络使用BN训练，这保证了前向传播信号有非零方差。我们还验证了反向传播的梯度，结果显示其符合BN的正常标准。因此既不是前向信号消失也不是反向信号消失。实际上，34层简单网络仍能取得有竞争力的准确率（表3），这表明在某种程度上来说求解器仍工作。我们推测深度简单网络可能有指数级低收敛特性，这影响了训练误差的降低。这种优化困难的原因将来会研究。</p><p><img src="https://img-blog.csdnimg.cn/20210117164446577.png#pic_center" alt="在这里插入图片描述"><br>表3。ImageNet验证集错误率（%，10个裁剪图像测试）。VGG16是基于我们的测试结果的。ResNet-50/101/152的选择B仅使用投影增加维度。</p><p><strong>残差网络</strong>。接下来我们评估18层和34层残差网络（ResNets）。基准架构与上述的简单网络相同，如图3（右）所示，预计每对3×3滤波器都会添加快捷连接。在第一次比较（表2和图4右侧）中，我们对所有快捷连接都使用恒等映射和零填充以增加维度（选项A）。所以与对应的简单网络相比，它们没有额外的参数。</p><p>我们从表2和图4中可以看到三个主要的观察结果。首先，残留学习的情况变了——34层ResNet比18层ResNet更好（2.8％）。更重要的是，34层ResNet显示出较低的训练误差，并且可以泛化到验证数据。这表明在这种情况下，退化问题得到了很好的解决，我们从增加的深度中设法获得了准确性收益。</p><p>第二，与对应的简单网络相比，由于成功的减少了训练误差，34层ResNet降低了3.5%的top-1错误率。这种比较证实了在极深系统中残差学习的有效性。</p><p>最后，我们还注意到18层的简单/残差网络同样地准确（表2），但18层ResNet收敛更快（图4右和左）。当网络“不过度深”时（18层），目前的SGD求解器仍能在简单网络中找到好的解。在这种情况下，ResNet通过在早期提供更快的收敛简便了优化。</p><p>恒等和投影快捷连接我们已经表明没有参数，恒等快捷连接有助于训练。接下来我们调查投影快捷连接（方程2）。在表3中我们比较了三个选项：(A) 零填充快捷连接用来增加维度，所有的快捷连接是没有参数的（与表2和图4右相同）；(B)投影快捷连接用来增加维度，其它的快捷连接是恒等的；（C）所有的快捷连接都是投影。</p><p>表3显示，所有三个选项都比对应的简单网络好很多。选项B比A略好。我们认为这是因为A中的零填充确实没有残差学习。选项C比B稍好，我们把这归因于许多（十三）投影快捷连接引入了额外参数。但A/B/C之间的细微差异表明，投影快捷连接对于解决退化问题不是至关重要的。因为我们在本文的剩余部分不再使用选项C，以减少内存/时间复杂性和模型大小。恒等快捷连接对于不增加下面介绍的瓶颈结构的复杂性尤为重要。</p><p>更深的瓶颈结构。接下来我们描述ImageNet中我们使用的更深的网络网络。由于关注我们能承受的训练时间，我们将构建块修改为瓶颈设计。对于每个残差函数F，我们使用3层堆叠而不是2层（图5）。三层是1×1，3×3和1×1卷积，其中1×1层负责减小然后增加（恢复）维度，使3×3层成为具有较小输入/输出维度的瓶颈。图5展示了一个示例，两个设计具有相似的时间复杂度。</p><p>无参数恒等快捷连接对于瓶颈架构尤为重要。如果图5（右）中的恒等快捷连接被投影替换，则可以显示出时间复杂度和模型大小加倍，因为快捷连接是连接到两个高维端。因此，恒等快捷连接可以为瓶颈设计得到更有效的模型。</p><p>50层ResNet：我们用3层瓶颈块替换34层网络中的每一个2层块，得到了一个50层ResNet（表1）。我们使用选项B来增加维度。该模型有38亿FLOP。</p><p>101层和152层ResNet：我们通过使用更多的3层瓶颈块来构建101层和152层ResNets（表1）。值得注意的是，尽管深度显著增加，但152层ResNet（113亿FLOP）仍然比VGG-16/19网络（153/196亿FLOP）具有更低的复杂度。</p><p>50/101/152层ResNet比34层ResNet的准确性要高得多（表3和4）。我们没有观察到退化问题，因此可以从显著增加的深度中获得显著的准确性收益。所有评估指标都能证明深度的收益（表3和表4）。</p><p>与最先进的方法比较。在表4中，我们与以前最好的单一模型结果进行比较。我们基准的34层ResNet已经取得了非常有竞争力的准确性。我们的152层ResNet具有单模型4.49％的top-5错误率。这种单一模型的结果胜过以前的所有综合结果（表5）。我们结合了六种不同深度的模型，形成一个集合（在提交时仅有两个152层）。这在测试集上得到了3.5％的top-5错误率（表5）。这次提交在2015年ILSVRC中荣获了第一名。</p><p><img src="https://img-blog.csdnimg.cn/20210117164730510.png#pic_center" alt="在这里插入图片描述"><br>表4。单一模型在ImageNet验证集上的错误率（%）(除了†是测试集上报告的错误率)。</p><p><img src="https://img-blog.csdnimg.cn/20210117164654928.png#pic_center" alt="在这里插入图片描述"></p><p>表5。模型综合的错误率(%)。top-5错误率是ImageNet测试集上的并由测试服务器报告的。</p><h3 id="4-2-CIFAR-10和分析"><a href="#4-2-CIFAR-10和分析" class="headerlink" title="4.2 CIFAR-10和分析"></a>4.2 CIFAR-10和分析</h3><p>我们对CIFAR-10数据集进行了更多的研究，其中包括10个类别中的5万张训练图像和1万张测试图像。我们介绍了在训练集上进行训练和在测试集上进行评估的实验。我们的焦点在于极深网络的行为，但不是推动最先进的结果，所以我们有意使用如下的简单架构。</p><p>简单/残差架构遵循图3（中/右）的形式。网络输入是32×32的图像，每个像素减去均值。第一层是3×3卷积。然后我们在大小为{32,16,8}的特征图上分别使用了带有3×3卷积的6n个堆叠层，每个特征图大小使用2n层。滤波器数量分别为{16,32,64}。下采样由步长为2的卷积进行。网络以全局平均池化，一个10维全连接层和softmax作为结束。共有6n+2个堆叠的加权层。下表总结了这个架构：</p><p><img src="https://img-blog.csdnimg.cn/20201218141750496.png#pic_center" alt="在这里插入图片描述"><br>当使用快捷连接时，它们连接到成对的3×3卷积层上（共3n个快捷连接）。在这个数据集上，我们在所有案例中都使用恒等快捷连接（即选项A），因此我们的残差模型与对应的简单模型具有完全相同的深度，宽度和参数数量。</p><p>我们使用的权重衰减为0.0001和动量为0.9，并采用和BN中的权重初始化，但没有使用丢弃。这些模型在两个GPU上进行训练，批处理大小为128。我们开始使用的学习率为0.1，在32k次和48k次迭代后学习率除以10，并在64k次迭代后终止训练，这是由45k/5k的训练/验证集分割决定的。我们按照简单数据增强进行训练：每边填充4个像素，并从填充图像或其水平翻转图像中随机采样32×32的裁剪图像。对于测试，我们只评估原始32×32图像的单一视图。</p><p>我们比较了n=3,5,7,9，得到了20层，32层，44层和56层的网络。图6（左）显示了简单网络的行为。深度简单网络经历了深度增加，随着深度增加表现出了更高的训练误差。这种现象类似于ImageNet中（图4，左）和MNIST中的现象，表明这种优化困难是一个基本的问题。</p><p><img src="https://img-blog.csdnimg.cn/20210117164911125.png#pic_center" alt="在这里插入图片描述"><br>图6。在CIFAR-10上训练。虚线表示训练误差，粗线表示测试误差。左：简单网络。简单的110层网络错误率超过60%没有展示。中间：ResNet。右：110层ResNet和1202层ResNet。</p><p>图6（中）显示了ResNet的行为。与ImageNet的情况类似（图4，右），我们的ResNet设法克服优化困难并随着深度的增加展示了准确性收益。</p><p>我们进一步探索了n=18得到了110层的ResNet。在这种情况下，我们发现0.1的初始学习率对于收敛来说太大了。因此我们使用0.01的学习率开始训练，直到训练误差低于80%（大约400次迭代），然后学习率变回到0.1并继续训练。学习过程的剩余部分与前面做的一样。这个110层网络收敛的很好（图6，中）。它与其它的深且窄的网络例如FitNet和Highway相比有更少的参数，但结果仍在目前最好的结果之间（6.43%，表6）。</p><p><img src="https://img-blog.csdnimg.cn/20210117165039510.png#pic_center" alt="在这里插入图片描述"><br>表6。在CIFAR-10测试集上的分类误差。所有的方法都使用了数据增强。对于ResNet-110，我们运行了5次并展示了“最好的(mean±std)”</p><p><strong>层响应分析</strong>。图7显示了层响应的标准偏差（std）。这些响应每个3×3层的输出，在BN之后和其他非线性（ReLU/加法）之前。对于ResNets，该分析揭示了残差函数的响应强度。图7显示ResNet的响应比其对应的简单网络的响应更小。这些结果支持了我们的基本动机（第3.1节），残差函数通常具有比非残差函数更接近零。我们还注意到，更深的ResNet具有较小的响应幅度，如图7中ResNet-20，56和110之间的比较所证明的。当层数更多时，单层ResNet趋向于更少地修改信号。</p><p><strong>探索超过1000层</strong>。我们探索超过1000层的过深的模型。我们设置n=200，得到了1202层的网络，其训练如上所述。我们的方法显示没有优化困难，这个103层网络能够实现训练误差&lt;0.1％（图6，右图）。其测试误差仍然很好（7.93％，表6）。</p><p>但是，这种极深的模型仍然存在着开放的问题。这个1202层网络的测试结果比我们的110层网络的测试结果更差，虽然两者都具有类似的训练误差。我们认为这是因为过拟合。对于这种小型数据集，1202层网络可能是不必要的大（19.4M）。在这个数据集应用强大的正则化，如maxout或者dropout来获得最佳结果。在本文中，我们不使用maxout/dropout，只是简单地通过设计深且窄的架构简单地进行正则化，而不会分散集中在优化难点上的注意力。但结合更强的正规化可能会改善结果，我们将来会研究。</p><h3 id="4-3-在PASCAL和MS-COCO上的目标检测"><a href="#4-3-在PASCAL和MS-COCO上的目标检测" class="headerlink" title="4.3 在PASCAL和MS COCO上的目标检测"></a>4.3 在PASCAL和MS COCO上的目标检测</h3><p>我们的方法对其他识别任务有很好的泛化性能。表7和表8显示了PASCAL VOC 2007和2012以及COCO的目标检测基准结果。我们采用更快的R-CNN作为检测方法。在这里，我们感兴趣的是用ResNet-101替换VGG-16。使用这两种模式的检测实现（见附录）是一样的，所以收益只能归因于更好的网络。最显著的是，在有挑战性的COCO数据集中，COCO的标准度量指标（mAP@[.5，.95]）增长了6.0％，相对改善了28％。这种收益完全是由于学习表示。</p><p><img src="https://img-blog.csdnimg.cn/20210117165203540.png#pic_center" alt="在这里插入图片描述"><br>表7。在PASCAL VOC 2007/2012测试集上使用基准Faster R-CNN的目标检测mAP(%)。更好的结果请看附录。</p><p><img src="https://img-blog.csdnimg.cn/20210117165237461.png#pic_center" alt="在这里插入图片描述"><br>表8。在COCO验证集上使用基准Faster R-CNN的目标检测mAP(%)。更好的结果请看附录。</p><p>基于深度残差网络，我们在ILSVRC &amp; COCO 2015竞赛的几个任务中获得了第一名，分别是：ImageNet检测，ImageNet定位，COCO检测，COCO分割。跟多细节请看附录。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="A-对象检测基准"><a href="#A-对象检测基准" class="headerlink" title="A.对象检测基准"></a>A.对象检测基准</h3><p>在本节中，我们介绍基于基线Faster R-CNN 系统的检测方法。这些模型由ImageNet分类模型初始化，然后对目标检测数据进行微调。在ILSVRC和COCO 2015检测竞赛时，我们已经使用ResNet-50 / 101进行了实验。</p><p>与以往使用的VGG-16不同，我们的ResNet没有隐藏fc层。我们采用“转换功能地图上的网络”（NoC）的想法来解决此问题。我们使用那些步幅不大于16个像素的图层（即conv1，conv2x，conv3x和conv4x，在ResNet-101中总共91个convlayers;表1）来计算全图像共享conv特征图。我们认为这些层类似于VGG-16中的13个conv层，这样做，ResNet和VGG-16都具有相同总步幅（16像素）的conv特征图。这些层由区域提议网络（RPN，生成300个提议）和快速R-CNN检测网络共享。 RoI合并在conv51之前执行。在此RoI共享的功能上，每个区域都采用了conv5x和up的所有层，起到了VGG-16的fc层的作用。最终分类层被两个同级层替代（分类和框回归）。</p><p>对于BN层的使用，在预训练之后，我们在ImageNet上计算每个层的BN统计量（均值和方差）。训练集。然后在微调期间固定BN层以进行对象检测。这样，BNlayers成为具有恒定偏移和比例的线性激活，并且不会通过微调更新BN统计信息。固定BN层主要是为了减少快速R-CNN训练中的内存消耗。</p><h4 id="PASCAL-VOC"><a href="#PASCAL-VOC" class="headerlink" title="PASCAL VOC"></a>PASCAL VOC</h4><p>对于PASCAL VOC 2007测试集，我们使用VOC 2007中的5ktrainvalimage和VOC 2012中的16ktrain-valimage进行训练（“ 07 + 12”）。对于PASCAL VOC 2012测试集，我们使用VOC 2007中的10ktrainval + testimages和VOC 2012中的16ktrainvalimages进行训练（“ 07 ++ 12”）。用于训练Faster R-CNN的超参数与[32]中的相同。表7示出了结果。与VGG-16相比，ResNet-101将mAP提高了3％以上。收益的增加完全是由于ResNet获得了改进的功能。</p><h4 id="MS-COCO"><a href="#MS-COCO" class="headerlink" title="MS COCO"></a>MS COCO</h4><p>MS COCO数据集涉及80个对象类别。我们评估了PASCAL VOC指标（mAP @IoU = 0.5）和标准COCO指标（mAP @IoU = .5：.05：.95）。我们将火车上的80k图像用于训练，将val上的40k图像用于评估。我们的COCO检测系统与PASCALVOC相似。我们使用8 GPU实现训练COCO模型，因此RPN步骤的最小批量大小为8张图像（即每个GPU 1个），而快速R-CNN步骤的最小批量大小为16张图像。 RPN步骤和Fast R-CNN步骤均以0.001的学习率进行了240k迭代的训练，然后以0.0001进行了80k迭代的训练。</p><p>表8显示了MS COCO验证集的结果。 ResNet-101的mAP@[.5，.95]比VGG-16增加了6％，相对改善了28％，这完全是由更好的网络所学到的功能所致。值得注意的是，mAP@[.5，.95]的绝对增长（6.0％）几乎与mAP @ .5的绝对增长（6.9％）一样大。这表明，加深者网络可以同时提高识别能力和定位能力。</p><h3 id="B-对象检测的改进"><a href="#B-对象检测的改进" class="headerlink" title="B.对象检测的改进"></a>B.对象检测的改进</h3><p>为了完整起见，我们报告了比赛的进步。这些改进基于深层功能，因此应该从残余学习中受益。</p><h4 id="MS-COCO-1"><a href="#MS-COCO-1" class="headerlink" title="MS COCO"></a>MS COCO</h4><p><em>Box细化</em>。我们的盒细化部分遵循迭代定位。在Faster R-CNN中，最终输出是与其提案框不同的回归框。因此，我们可以从回归框中合并一个新功能，并获得新的分类分数和新的回归框。我们将这300个新预测与原始300个预测结合在一起。非最大抑制（NMS）应用于预测框的并集，使用IoUthreshold为0.3 ，然后进行框投票。盒子重新细化可将mAP提高约2点（表9）</p><p><img src="https://img-blog.csdnimg.cn/20210119103110772.png#pic_center" alt="在这里插入图片描述"><br>表9。使用Faster R-CNN和ResNet-101在MS COCO上进行的对象检测改进。</p><p><em>全局上下文</em>。我们在FastR-CNN步骤中结合全局上下文。给定全图像转换特征图，通过全局空间金字塔池（具有“单级”金字塔）来合并特征，可以使用整个图像的边界框作为RoI将其实现为“ RoI”池。将此合并的功能馈入后RoI层以获得全局上下文功能。将此全局特征与原始的按区域特征串联在一起，然后是同级分类和框回归图层。这种新的结构是端到端的。全局上下文将mAP@ .5提高了大约1个点（表9）</p><p><em>多尺度测试</em>。在上面，所有结果都是通过单尺度训练/测试获得的，其中图像的较短边是600像素。通过从特征金字塔中选择尺度来开发多尺度训练/测试，使用maxout层来进行了开发。在当前的实现中，我们已经执行了以下的多尺度测试；由于时间有限，我们尚未执行多尺度训练。此外，我们仅针对Fast R-CNN步骤（但尚未针对RPN步骤）执行多尺度测试。通过训练有素的模型，我们可以在图像金字塔上计算转换特征图，其中图像的短边为s∈{200,400,600,800,1000}</p><p>我们从下面的金字塔中选择两个相邻的比例尺。 RoI池和后续层在这两个比例尺的特征图上执行，它们被maxout合并。多尺度测试将mAP提高了2个百分点（表9）。</p><p><em>使用验证数据</em>。接下来，我们使用80k + 40k trainval集合进行训练，使用20k test-dev集合进行评估。测试开发集没有公开可用的基础事实，并且结果由评估服务器报告。在此设置下，结果的mAP@ .5为55.7％，mAP@ [.5，.95]为34.9％（表9）。这是我们的单模结果。</p><p><em>集成</em>。在Faster R-CNN中，该系统旨在学习区域提议以及对象分类器，因此可以使用集成来完成这两项任务。我们使用一个整体来提议区域，并且提议的联合集由每个区域分类器的整体来处理。表9显示了基于3个网络的合计结果。在测试开发集上，mAP分别为59.0％和37.4％，该结果在COCO 2015的检测任务中排名第一。</p><h4 id="PASCAL-VOC-1"><a href="#PASCAL-VOC-1" class="headerlink" title="PASCAL VOC"></a>PASCAL VOC</h4><p>我们基于上述模型重新访问PASCAL VOC数据集。使用COCO数据集上的单个模型（表9中为55.7％mAP@ .5），我们可以在PAS-CAL VOC集合上微调该模型。还采用了改进的框精，上下文和多尺度测试。通过这样做我们在PASCAL VOC 2007（表10）和83.8％PASCAL VOC 2012（表11）上实现了85.6％的mAP。 PASCAL VOC 2012的结果比以前的最新结果高10点。</p><p><img src="https://img-blog.csdnimg.cn/20210119103800709.png#pic_center" alt="在这里插入图片描述"><br>表10。 PASCAL VOC 2007测试集的检测结果。基线是Faster R-CNN系统。 “ baseline +++”系统在表9中包括框优化，上下文和多尺度测试。</p><p><img src="https://img-blog.csdnimg.cn/20210119104141236.png#pic_center" alt="在这里插入图片描述"><br>表11. PASCAL VOC 2012测试集的检测结果。基线是Faster R-CNN系统。表9中的“基线+++”系统包括框优化，上下文和多尺度测试。</p><h4 id="ImageNet检测"><a href="#ImageNet检测" class="headerlink" title="ImageNet检测"></a>ImageNet检测</h4><p>ImageNet检测（DET）任务涉及200个对象类别。精度由mAP@ .5评估。 ImageNet DET的目标检测算法与表9中的MS COCO相同。网络在1000类ImageNet分类集上进行了预训练，并在DET数据上进行了微调。我们将验证设置分为两部分（val1/val2）。我们使用DET训练集和val1set对检测模型进行微调。 val2集用于验证。我们不使用其他ILSVRC 2015数据。我们使用ResNet-101的单一模型具有58.8% mAP且 3个模型的集成在DET测试集上具有62.1％的mAP（表12）。<em>该结果在ILSVRC 2015的ImageNet检测任务中获得了第一名</em>，比第二名多了8.5分（绝对值）。</p><h3 id="C-ImageNet定位"><a href="#C-ImageNet定位" class="headerlink" title="C. ImageNet定位"></a>C. ImageNet定位</h3><p>ImageNet定位（LOC）任务需要对对象进行分类和定位对象。 我们假设首先采用图像级分类器来预测图像的类别标签，而定位算法仅考虑了基于预测类别的边界框预测。我们采用“每类回归”（PCR）策略，为每个类学习边框回归。我们预先训练网络以进行ImageNet分类，然后对其进行微调以进行定位。我们在提供的1000级ImageNet训练集中训练网络。</p><p>我们的定位算法基于RPN框架，并做了一些修改。与不区分类别的方式不同，我们用于定位的RPN是按aper-classform设计的。该RPN以两个同级1×1卷积层结束，用于二进制分类（cls）和边框回归（reg），cls和reg 都属于per类。具体来说，cls具有1000维的输出，并且每个维都是二进制逻辑回归，用于预测是否为对象类。 reg具有1000×4-d输出，由1000个类别的盒形回归组成。我们的边界框回归是参考每个位置的多个翻译不变的“锚定”框。</p><p>与我们的ImageNet分类训练（第3.4节）中一样，我们随机采样224×224种作物以进行数据增强。我们使用256幅图像的小批量进行微调。为了避免负样本占主导地位，每个图像随机采样8个锚点，其中正负锚点的比例为1：1 。为了进行测试，将网络完全卷积地应用到图像上。</p><p>表13比较了定位的结果。我们首先使用地面真理类作为分类预测来执行“ oracle”测试。VGG的论文使用groundtruth类的中心裁剪误差为33.1％（表13）。在相同的设置下，我们使用ResNet-101 net的RPN方法可将中央作物误差大大降低至13.3％。此比较证明了我们框架的出色性能。通过密集（完全卷积）和多尺度测试，我们的ResNet-101使用地面真理类的错误率为11.7％。使用ResNet-101预测类别（前5名分类错误率为4.6％，表4），前5名定位错误率为14.4％。</p><p><img src="https://img-blog.csdnimg.cn/20210119105634292.png#pic_center" alt="在这里插入图片描述"><br>表13. ImageNet验证上的定位错误率（％）。在“ GT类的LOC错误” 列中，使用了地面真实类。在“测试”列中，“ 1-crop”表示对224×224像素的中心作物进行测试，“ dense”表示密集（完全卷积）和多尺度测试。</p><p>以上结果仅基于Faster R-CNN 中的投标网络（RPN）。可以使用Faster R-CNN中的检测网络（Fast R-CNN）来改善结果。但是我们注意到，在该数据集上，一张图像通常包含一个主要对象，并且投标区域彼此高度重叠，因此具有非常相似的RoI合并特征。结果，Fast R-CNN 的以图像为中心的训练会产生小的变化样本，这对于随机训练可能是不希望的。因此，在我们目前的实验中，我们使用以RoI为中心的原始R-CNN代替Fast R-CNN。</p><p>我们的R-CNN实现如下。我们在训练图像上应用如上训练的每类RPN，以预测地面真理类的边界框。这些预测的框起着与类相关的建议的作用。对于每个训练图像，最高得分的200个建议被提取为训练R-CNN分类器的训练样本。图像区域是从提案中裁剪出来的，扭曲为224×224像素，然后馈入R-CNN中的分类网络。该网络的输出包括cls 和 reg的两个同级fc层，也为每类形式。此R-CNN网络在训练集上进行了微调，以RoI为中心的微型批次大小为256。进行测试时，RPN为每个预测的类别生成得分最高的200个提案，并且R-CNN网络用于更新这些提案的得分和方框位置。</p><p>这种方法将前5位的定位误差降低到10.6％（表13）。这是我们在验证集上的单模型结果。将网络集成用于分类和定位，我们在测试集上实现了9.0％的前五名本地化错误。这个数字大大超过了ILSVRC 14的结果（表14），显示出64％的错误相对减少。该结果在ILSVRC 2015的ImageNet本地化任务中获得了第一名。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文翻译 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ResNetV1 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【图像分类—GoogLeNet Inception V3】Rethinking the Inception Architecture for Computer Vision</title>
      <link href="/article/7.html"/>
      <url>/article/7.html</url>
      
        <content type="html"><![CDATA[<p>分析了Inception优化的一些历史情况；提出了设计Inception的四个原则；提出分解卷积核的方式；辅助分类器的作用；提出缩小feature的结构。</p><a id="more"></a><img width="600" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320142934.png"><blockquote><p>论文：<a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">Rethinking the Inception Architecture for Computer Vision</a></p></blockquote><blockquote><p>分析了Inception优化的一些历史情况；提出了设计Inception的四个原则；提出分解卷积核的方式；辅助分类器的作用；提出缩小feature的结构。</p></blockquote><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>对许多任务而言，卷积网络是目前最新的计算机视觉解决方案的核心。从2014年开始，深度卷积网络开始变成主流，在各种基准数据集上都取得了实质性成果。对于大多数任务而言，虽然增加的模型大小和计算成本都趋向于转化为直接的质量收益（只要提供足够的标注数据去训练），但计算效率和低参数计数仍是各种应用场景的限制因素，例如移动视觉和大数据场景。目前，我们正在探索增大网络的方法，目标是通过适当的分解卷积和积极的正则化来尽可能地有效利用增加的计算。我们在ILSVRC 2012分类挑战赛的验证集上评估了我们的方法，结果证明我们的方法超过了目前最先进的方法并取得了实质性收益：对于单一框架评估错误率为：21.2% top-1和5.6% top-5，使用的网络计算代价为每次推断需要进行50亿次乘加运算并使用不到2500万的参数。通过四个模型组合和多次评估，我们报告了3.5% top-5和17.3% top-1的错误率。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>从2012年Krizhevsky等人赢得了ImageNet竞赛起，他们的网络“AlexNet”已经成功了应用到了许多计算机视觉任务中，例如目标检测，分割，行人姿势评估，视频分类，目标跟踪和超分辨率。</p><p>这些成功推动了一个新研究领域，这个领域主要专注于寻找更高效运行的卷积神经网络。从2014年开始，通过利用更深更宽的网络，网络架构的质量得到了明显改善。VGGNet和GoogLeNet在2014 ILSVRC 分类挑战上取得了类似的高性能。一个有趣的发现是在分类性能上的收益趋向于转换成各种应用领域上的显著质量收益。这意味着深度卷积架构上的架构改进可以用来改善大多数越来越多地依赖于高质量、可学习视觉特征的其它计算机视觉任务的性能。网络质量的改善也导致了卷积网络在新领域的应用，在AlexNet特征不能与手工精心设计的解决方案竞争的情况下，例如，检测时的候选区域生成。</p><p>尽管VGGNet具有架构简洁的强有力特性，但它的成本很高：评估网络需要大量的计算。另一方面，GoogLeNet的Inception架构也被设计为在内存和计算预算严格限制的情况下也能表现良好。例如，GoogleNet只使用了500万参数，与其前身AlexNet相比减少了12倍，AlexNet使用了6000万参数。此外，VGGNet使用了比AlexNet大约多3倍的参数。</p><p>Inception的计算成本也远低于VGGNet或其更高性能的后继者。这使得可以在大数据场景中，在大量数据需要以合理成本处理的情况下或在内存或计算能力固有地受限情况下，利用Inception网络变得可行，例如在移动视觉设定中。通过应用针对内存使用的专门解决方案或通过计算技巧优化某些操作的执行，可以减轻部分这些问题。但是这些方法增加了额外的复杂性。此外，这些方法也可以应用于优化Inception架构，再次扩大效率差距。</p><p>然而，Inception架构的复杂性使得更难以对网络进行更改。如果单纯地放大架构，大部分的计算收益可能会立即丢失。此外，并没有提供关于导致GoogLeNet架构的各种设计决策的贡献因素的明确描述。这使得它更难以在适应新用例的同时保持其效率。例如，如果认为有必要增加一些Inception模型的能力，将滤波器组大小的数量加倍的简单变换将导致计算成本和参数数量增加4倍。这在许多实际情况下可能会被证明是禁止或不合理的，尤其是在相关收益适中的情况下。在本文中，我们从描述一些一般原则和优化思想开始，对于以有效的方式扩展卷积网络来说，这被证实是有用的。虽然我们的原则不局限于Inception类型的网络，但是在这种情况下，它们更容易观察，因为Inception类型构建块的通用结构足够灵活，可以自然地合并这些约束。这通过大量使用降维和Inception模块的并行结构来实现，这允许减轻结构变化对邻近组件的影响。但是，对于这样做需要谨慎，因为应该遵守一些指导原则来保持模型的高质量。</p><h2 id="2-通用设计原则"><a href="#2-通用设计原则" class="headerlink" title="2 通用设计原则"></a>2 通用设计原则</h2><p>这里我们将介绍一些具有卷积网络的、具有各种架构选择的、基于大规模实验的设计原则。在这一点上，以下原则的效用是推测性的，另外将来的实验证据将对于评估其准确性和有效领域是必要的。然而，严重偏移这些原则往往会导致网络质量的恶化，修正检测到的这些偏差状况通常会导致改进的架构。</p><ol><li><p>避免表征瓶颈，尤其是在网络的前面。前馈网络可以由从输入层到分类器或回归器的非循环图表示。这为信息流定义了一个明确的方向。对于分离输入输出的任何切口，可以访问通过切口的信息量。应该避免极端压缩的瓶颈。一般来说，在达到用于着手任务的最终表示之前，表示大小应该从输入到输出缓慢减小。理论上，信息内容不能仅通过表示的维度来评估，因为它丢弃了诸如相关结构的重要因素；维度仅提供信息内容的粗略估计。</p></li><li><p>更高维度的表示在网络中更容易局部处理。在卷积网络中增加每个图块的激活允许更多解耦的特征。所产生的网络将训练更快。</p></li><li><p>空间聚合可以在较低维度嵌入上完成，而不会在表示能力上造成许多或任何损失。例如，在执行更多展开（例如3×3）卷积之前，可以在空间聚合之前减小输入表示的维度，没有预期的严重不利影响。我们假设，如果在空间聚合上下文中使用输出，则相邻单元之间的强相关性会导致维度缩减期间的信息损失少得多。鉴于这些信号应该易于压缩，因此尺寸减小甚至会促进更快的学习。</p></li><li><p>平衡网络的宽度和深度。通过平衡每个阶段的滤波器数量和网络的深度可以达到网络的最佳性能。增加网络的宽度和深度可以有助于更高质量的网络。然而，如果两者并行增加，则可以达到恒定计算量的最佳改进。因此，计算预算应该在网络的深度和宽度之间以平衡方式进行分配。</p></li></ol><p>虽然这些原则可能是有意义的，但并不是开箱即用的直接使用它们来提高网络质量。我们的想法是仅在不明确的情况下才明智地使用它们。</p><h2 id="3-基于大滤波器尺寸分解卷积"><a href="#3-基于大滤波器尺寸分解卷积" class="headerlink" title="3 基于大滤波器尺寸分解卷积"></a>3 基于大滤波器尺寸分解卷积</h2><p>GoogLeNet网络的大部分初始收益来源于大量地使用降维。这可以被视为以计算有效的方式分解卷积的特例。考虑例如1×1卷积层之后接一个3×3卷积层的情况。在视觉网络中，预期相近激活的输出是高度相关的。因此，我们可以预期，它们的激活可以在聚合之前被减少，并且这应该会导致类似的富有表现力的局部表示。</p><p>在这里，我们将在各种设定中探索卷积分解的其它方法，特别是为了提高解决方案的计算效率。由于Inception网络是全卷积的，每个权重对应每个激活的一次乘法。因此，任何计算成本的降低会导致参数数量减少。这意味着，通过适当的分解，我们可以得到更多的解耦参数，从而加快训练。此外，我们可以使用计算和内存节省来增加我们网络的滤波器组的大小，同时保持我们在单个计算机上训练每个模型副本的能力。</p><h3 id="3-1-分解到更小的卷积"><a href="#3-1-分解到更小的卷积" class="headerlink" title="3.1 分解到更小的卷积"></a>3.1 分解到更小的卷积</h3><p>具有较大空间滤波器（例如5×5或7×7）的卷积在计算方面往往不成比例地昂贵。例如，具有n个滤波器的5×5卷积在具有m个滤波器的网格上比具有相同数量的滤波器的3×3卷积的计算量高25/9=2.78倍。当然，5×5滤波器在更前面的层可以捕获更远的单元激活之间、信号之间的依赖关系，因此滤波器几何尺寸的减小带来了很大的表现力。然而，我们可以询问5×5卷积是否可以被具有相同输入尺寸和输出深度的参数较小的多层网络所取代。如果我们放大5×5卷积的计算图，我们看到每个输出看起来像一个小的完全连接的网络，在其输入上滑过5×5的块（见图1）。由于我们正在构建视觉网络，所以通过两层的卷积结构再次利用平移不变性来代替全连接的组件似乎是很自然的：第一层是3×3卷积，第二层是在第一层的3×3输出网格之上的一个全连接层（见图1）。通过在输入激活网格上滑动这个小网络，用两层3×3卷积来替换5×5卷积（比较图4和5）。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320142949.png"><center>图1：Mini网络替换5×5卷积</center><br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320142958.png"><center>图4：[20]中描述的最初的Inception模块。</center><br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143008.png"><p>图5：Inception模块中每个5×5卷积由两个3×3卷积替换，正如第2小节中原则3建议的那样。</p><p>该设定通过相邻块之间共享权重明显减少了参数数量。为了分析预期的计算成本节省，我们将对典型的情况进行一些简单的假设：我们可以假设$n=\alpha m$，也就是我们想通过常数$\alpha$因子来改变激活/单元的数量。由于5×5卷积是聚合的，$\alpha$通常比1略大（在GoogLeNet中大约是1.5）。用两个层替换5×5层，似乎可以通过两个步骤来实现扩展：在两个步骤中通过$\sqrt \alpha$增加滤波器数量。为了简化我们的估计，通过选择$\alpha=1$（无扩展），如果我们单纯地滑动网络而不重新使用相邻网格图块之间的计算，我们将增加计算成本。滑动该网络可以由两个3×3的卷积层表示，其重用相邻图块之间的激活。这样，我们最终得到一个计算量减少到$\frac {9+9} {25} ×$的网络，通过这种分解导致了28％的相对增益。每个参数在每个单元的激活计算中只使用一次，所以参数计数具有完全相同的节约。不过，这个设置提出了两个一般性的问题：这种替换是否会导致任何表征力的丧失？如果我们的主要目标是对计算的线性部分进行分解，是不是建议在第一层保持线性激活？我们已经进行了几个控制实验（例如参见图2），并且在分解的所有阶段中使用线性激活总是逊于使用修正线性单元。我们将这个收益归因于网络可以学习的增强的空间变化，特别是如果我们对输出激活进行批标准化。当对维度减小组件使用线性激活时，可以看到类似的效果。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143016.png"><p>图2：两个Inception模型间几个控制实验中的一个，其中一个分解为线性层+ ReLU层，另一个使用两个ReLU层。在三亿八千六百万次运算后，在验证集上前者达到了76.2% top-1准确率，后者达到了77.2% top-1的准确率。</p><h3 id="3-2-空间分解为不对称卷积"><a href="#3-2-空间分解为不对称卷积" class="headerlink" title="3.2 空间分解为不对称卷积"></a>3.2 空间分解为不对称卷积</h3><p>上述结果表明，大于3×3的卷积滤波器可能不是通常有用的，因为它们总是可以简化为3×3卷积层序列。我们仍然可以问这个问题，是否应该把它们分解成更小的，例如2×2的卷积。然而，通过使用非对称卷积，可以做出甚至比2×2更好的效果，即n×1。例如使用3×1卷积后接一个1×3卷积，相当于以与3×3卷积相同的感受野滑动两层网络（参见图3）。如果输入和输出滤波器的数量相等，那么对于相同数量的输出滤波器，两层解决方案便宜33％。相比之下，将3×3卷积分解为两个2×2卷积表示仅节省了11％的计算量。</p><img width="200" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143024.png"><p>图3：替换3×3卷积的Mini网络。网络的更低层由带有3个输出单元的3×1构成。</p><br><p>在理论上，我们可以进一步论证，可以通过1×n卷积和后面接一个n×1卷积替换任何n×n卷积，并且随着n增长，计算成本节省显著增加（见图6）。实际上，我们发现，采用这种分解在前面的层次上不能很好地工作，但是对于中等网格尺寸（在m×m特征图上，其中m范围在12到20之间），其给出了非常好的结果。在这个水平上，通过使用1×7卷积，然后是7×1卷积可以获得非常好的结果。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143031.png"><p>图6：n×n卷积分解后的Inception模块。在我们提出的架构中，对17×17的网格我们选择n=7。（滤波器尺寸可以通过原则3选择）</p><h2 id="4-利用辅助分类器"><a href="#4-利用辅助分类器" class="headerlink" title="4 利用辅助分类器"></a>4 利用辅助分类器</h2><p>引入辅助分类器的概念，以改善非常深的网络的收敛。最初的动机是将有用的梯度推向较低层，使其立即有用，并通过抵抗非常深的网络中的消失梯度问题来提高训练过程中的收敛。Lee等人也认为辅助分类器促进了更稳定的学习和更好的收敛。有趣的是，我们发现辅助分类器在训练早期并没有导致改善收敛：在两个模型达到高精度之前，有无侧边网络的训练进度看起来几乎相同。接近训练结束，辅助分支网络开始超越没有任何分支的网络的准确性，达到了更高的稳定水平。</p><p>另外，在网络的不同阶段使用了两个侧分支。移除更下面的辅助分支对网络的最终质量没有任何不利影响。再加上前一段的观察结果，这意味着最初的假设，这些分支有助于演变低级特征很可能是不适当的。相反，我们认为辅助分类器起着正则化项的作用。这是由于如果侧分支是批标准化的或具有丢弃层，则网络的主分类器性能更好。这也为推测批标准化作为正则化项给出了一个弱支持证据。</p><h2 id="5-有效的网格尺寸减少"><a href="#5-有效的网格尺寸减少" class="headerlink" title="5 有效的网格尺寸减少"></a>5 有效的网格尺寸减少</h2><p>传统上，卷积网络使用一些池化操作来缩减特征图的网格大小。为了避免表示瓶颈，在应用最大池化或平均池化之前，需要扩展网络滤波器的激活维度。例如，开始有一个带有$k$个滤波器的$d \times d$网格，如果我们想要达到一个带有$2k$个滤波器的$\frac{d}{2}\times \frac{d}{2}$网格，我们首先需要用$2k$个滤波器计算步长为1的卷积，然后应用一个额外的池化步骤。这意味着总体计算成本由在较大的网格上使用$2d^2k^2$次运算的昂贵卷积支配。一种可能性是转换为带有卷积的池化，因此导致$2(\frac{d}{2})^2k^2$次运算，将计算成本降低为原来的四分之一。然而，由于表示的整体维度下降到$(\frac{d}{2})^2k$，会导致表示能力较弱的网络（参见图9），这会产生一个表示瓶颈。我们建议另一种变体，其甚至进一步降低了计算成本，同时消除了表示瓶颈（见图10），而不是这样做。我们可以使用两个平行的步长为2的块：$P$和$C$。$P$是一个池化层（平均池化或最大池化）的激活，两者都是步长为$2$，其滤波器组连接如图10所示。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143039.png"><p>图9：减少网格尺寸的两种替代方式。左边的解决方案违反了第2节中不引入表示瓶颈的原则1。右边的版本计算量昂贵3倍。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143046.png"><p>图10：缩减网格尺寸的同时扩展滤波器组的Inception模块。它不仅廉价并且避免了原则1中提出的表示瓶颈。右侧的图表示相同的解决方案，但是从网格大小而不是运算的角度来看。</p><h2 id="6-Inception-v2"><a href="#6-Inception-v2" class="headerlink" title="6 Inception-v2"></a>6 Inception-v2</h2><p>在这里，我们连接上面的点，并提出了一个新的架构，在ILSVRC 2012分类基准数据集上提高了性能。我们的网络布局在表1中给出。注意，基于与3.1节中描述的同样想法，我们将传统的$7 \times 7$卷积分解为3个$3\times 3$卷积。对于网络的Inception部分，我们在$ 35 \times 35$处有$3$个传统的Inception模块，每个模块有$288$个滤波器。使用第5节中描述的网格缩减技术，这将缩减为$17\times 17$的网格，具有$768$个滤波器。这之后是图5所示的$5$个分解的Inception模块实例。使用图10所示的网格缩减技术，这被缩减为$8 \times 8 \times 1280$的网格。在最粗糙的$8 \times 8$级别，我们有两个如图6所示的Inception模块，每个块连接的输出滤波器组的大小为2048。网络的详细结构，包括Inception模块内滤波器组的大小，在补充材料中给出，在提交的tar文件中的model.txt中给出。然而，我们已经观察到，只要遵守第2节的原则，对于各种变化网络的质量就相对稳定。虽然我们的网络深度是$42$层，但我们的计算成本仅比GoogLeNet高出约$2.5$倍，它仍比VGGNet要高效的多。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143053.png"><p>表1：提出的网络架构的轮廓。每个模块的输出大小是下一模块的输入大小。我们正在使用图10所示的缩减技术的变种，以缩减应用时Inception块间的网格大小。我们用0填充标记了卷积，用于保持网格大小。这些Inception模块内部也使用0填充，不会减小网格大小。所有其它层不使用填充。选择各种滤波器组大小来观察第2节的原理4。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143059.png"><p>图7：具有扩展的滤波器组输出的Inception模块。这种架构被用于最粗糙的（8×8）网格，以提升高维表示，如第2节原则2所建议的那样。我们仅在最粗的网格上使用了此解决方案，因为这是产生高维度的地方，稀疏表示是最重要的，因为与空间聚合相比，局部处理（1×1 卷积）的比率增加。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143105.png"><p>图8：最后17×17层之上的辅助分类器。 侧头中的层的批标准化导致top-1 0.4％的绝对收益。下轴显示执行的迭代次数，每个批次大小为32。</p><h2 id="7-通过标签平滑进行模型正则化"><a href="#7-通过标签平滑进行模型正则化" class="headerlink" title="7 通过标签平滑进行模型正则化"></a>7 通过标签平滑进行模型正则化</h2><p>我们提出了一种通过估计训练期间标签丢弃的边缘化效应来对分类器层进行正则化的机制。</p><p>对于每个训练样本$x$，我们的模型计算每个标签的概率$p(k \mid x)=\frac{\exp \left(z_{k}\right)}{\sum_{i=1}^{K} \exp \left(z_{i}\right)}$。这里，$z_i$是对数单位或未归一化的对数概率。考虑这个训练样本在标签上的实际分布$q(k|x)$，因此归一化后$\sum_kq(k|x)=1$。为了简洁，我们省略$p$和$q$对样本$x$的依赖。我们将样本损失定义为交叉熵：$\ell=−\sum^{K}_{k=1}log(p(k))q(k)$。最小化交叉熵等价于最大化标签对数似然期望，其中标签是根据它的实际分布$q(k)$选择的。交叉熵损失对于$z_k$是可微的，因此可以用来进行深度模型的梯度训练。其梯度有一个更简单的形式：$\frac{\partial \ell }{\partial z_k}=p(k)−q(k)$，它的范围在−1到1之间。</p><p>考虑单个真实标签$y$的例子，对于所有$k≠y$，有$q(y)=1$，$q(k)=0$。在这种情况下，最小化交叉熵等价于最大化正确标签的对数似然。对于一个特定的样本$x$，其标签为$y$，对于$q(k)=\delta_{k,y}$，最大化其对数概率，$\delta_{k,y}$为狄拉克$\delta$函数，当且仅当$k=y$时，$\delta$函数值为1，否则为0。对于有限的$z_k$，不能取得最大值，但对于所有$k≠y$，如果$z_y≫z_k$——也就是说，如果对应实际标签的逻辑单元远大于其它的逻辑单元，那么对数概率会接近最大值。然而这可能会引起两个问题。首先，它可能导致过拟合：如果模型学习到对于每一个训练样本，分配所有概率到实际标签上，那么它不能保证泛化能力。第二，它鼓励最大的逻辑单元与所有其它逻辑单元之间的差距变大，与有界限的梯度$\frac{\partial \ell}{\partial z_k}$相结合，这会降低模型的适应能力。直观上讲这会发生，因为模型变得对它的预测过于自信。</p><p>我们提出了一个鼓励模型不那么自信的机制。如果目标是最大化训练标签的对数似然，这可能不是想要的，但它确实使模型正规化并使其更具适应性。这个方法很简单。考虑标签$u(k)$的分布和平滑参数$\epsilon$，与训练样本$x$相互独立。对于一个真实标签为$y$的训练样本，我们用</p><p>$$q^{\prime}(k|x) = (1-\epsilon) \delta_{k,y} + \epsilon u(k)$$</p><p>代替标签分布$q(k)=\delta_{k,y}$，其由最初的实际分布$q(k|x)$和固定分布$u(k)$混合得到，它们的权重分别为$1−\epsilon$和$\epsilon$。这可以看作获得标签k的分布如下：首先，将其设置为真实标签$k=y$；其次，用分布$u(k)$中的采样和概率$\epsilon$替代$k$。我们建议使用标签上的先验分布作为$u(k)$。在我们的实验中，我们使用了均匀分布$u(k)=1/K$，以便使得</p><p>$$q^{\prime}(k) = (1-\epsilon) \delta_{k,y} + \frac{\epsilon}{K}.$$<br>我们将真实标签分布中的这种变化称为标签平滑正则化，或LSR。</p><p>注意，LSR实现了期望的目标，阻止了最大的逻辑单元变得比其它的逻辑单元更大。实际上，如果发生这种情况，则一个$q(k)$将接近1，而所有其它的将会接近0。这会导致$q^{\prime}(k)$有一个大的交叉熵，因为不同于$q(k)=\delta_{k,y}$，所有的$q^{\prime}(k)$都有一个正的下界。</p><p>LSR的另一种解释可以通过考虑交叉熵来获得：</p><p>$$H(q^{\prime},p) = -\sum_{k=1}^K \log p(k) q’(k) = (1-\epsilon)H(q, p) + \epsilon H(u, p)$$</p><p>因此，LSR等价于用一对这样的损失$H(q,p)$和$H(u,p)$来替换单个交叉熵损失$H(q,p)$。第二个损失惩罚预测的标签分布$p$与先验$u$之间的偏差，其中相对权重为$\frac{\epsilon}{1−\epsilon}$。注意，由于$H(u,p)=D_{KL}(u|p)+H(u)$和$H(u)$是固定的，因此这个偏差可以等价地被KL散度捕获。当u是均匀分布时，$H(u,p)$是度量预测分布$p$与均匀分布不同的程度，也可以通过负熵$−H(p)$来度量（但不等价）；我们还没有实验过这种方法。</p><p>在我们的$K=1000$类的ImageNet实验中，我们使用了$u(k)=1/1000$和$\epsilon=0.1$。对于ILSVRC 2012，我们发现对于top-1错误率和top-5错误率，持续提高了大约0.2%（参见表3）。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143121.png"><p>表3：单张裁剪图像的实验结果，比较各种影响因素的累积影响。我们将我们的数据与Ioffe等人发布的单张裁剪图像的最好推断结果进行了比较。在“Inception-v2”行，变化是累积的并且接下来的每一行都包含除了前面的变化之外的新变化。最后一行是所有的变化，我们称为“Inception-v3”。遗憾的是，He等人仅报告了10个裁剪图像的评估结果，但没有单张裁剪图像的结果，报告在下面的表4中。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143128.png"><p>表4：单模型，多裁剪图像的实验结果，比较各种影响因素的累积影响。我们将我们的数据与ILSVRC 2012分类基准中发布的最佳单模型推断结果进行了比较。</p><h2 id="8-训练方法"><a href="#8-训练方法" class="headerlink" title="8 训练方法"></a>8 训练方法</h2><p>我们在TensorFlow分布式机器学习系统上使用随机梯度方法训练了我们的网络，使用了50个副本，每个副本在一个NVidia Kepler GPU上运行，批处理大小为32，100个epoch。我们之前的实验使用动量方法，衰减值为0.9，而我们最好的模型是用RMSProp实现的，衰减值为0.9，$\epsilon=1.0$。我们使用0.045的学习率，每两个epoch以0.94的指数速率衰减。此外，阈值为2.0的梯度裁剪被发现对于稳定训练是有用的。使用随时间计算的运行参数的平均值来执行模型评估。</p><h2 id="9-低分辨率输入上的性能"><a href="#9-低分辨率输入上的性能" class="headerlink" title="9 低分辨率输入上的性能"></a>9 低分辨率输入上的性能</h2><p>视觉网络的典型用例是用于检测的后期分类，例如在Multibox上下文中。这包括分析在某个上下文中包含单个对象的相对较小的图像块。任务是确定图像块的中心部分是否对应某个对象，如果是，则确定该对象的类别。这个挑战的是对象往往比较小，分辨率低。这就提出了如何正确处理低分辨率输入的问题。</p><p>普遍的看法是，使用更高分辨率感受野的模型倾向于导致显著改进的识别性能。然而，区分第一层感受野分辨率增加的效果和较大的模型容量、计算量的效果是很重要的。如果我们只是改变输入的分辨率而不进一步调整模型，那么我们最终将使用计算上更便宜的模型来解决更困难的任务。当然，由于减少了计算量，这些解决方案很自然就出来了。为了做出准确的评估，模型需要分析模糊的提示，以便能够“幻化”细节。这在计算上是昂贵的。因此问题依然存在：如果计算量保持不变，更高的输入分辨率会有多少帮助。确保不断努力的一个简单方法是在较低分辨率输入的情况下减少前两层的步长，或者简单地移除网络的第一个池化层。</p><p>为了这个目的我们进行了以下三个实验：</p><ol><li>步长为2，大小为299×299的感受野和最大池化。</li><li>步长为1，大小为151×151的感受野和最大池化。</li><li>步长为1，大小为79×79的感受野和第一层之后没有池化。</li></ol><p>所有三个网络具有几乎相同的计算成本。虽然第三个网络稍微便宜一些，但是池化层的成本是无足轻重的（在总成本的1％以内）。在每种情况下，网络都进行了训练，直到收敛，并在ImageNet ILSVRC 2012分类基准数据集的验证集上衡量其质量。结果如表2所示。虽然分辨率较低的网络需要更长时间去训练，但最终结果却与较高分辨率网络的质量相当接近。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143138.png"><p>表2：当感受野尺寸变化时，识别性能的比较，但计算代价是不变的。</p><p>但是，如果只是单纯地按照输入分辨率减少网络尺寸，那么网络的性能就会差得多。然而，这将是一个不公平的比较，因为我们将在比较困难的任务上比较一个便宜16倍的模型。</p><p>表2的这些结果也表明，有人可能会考虑在R-CNN的上下文中对更小的对象使用专用的高成本低分辨率网络。</p><h2 id="10-实验结果和比较"><a href="#10-实验结果和比较" class="headerlink" title="10 实验结果和比较"></a>10 实验结果和比较</h2><p>表3显示了我们提出的体系结构（Inception-v2）识别性能的实验结果，架构如第6节所述。每个Inception-v2行显示了累积变化的结果，包括突出显示的新修改加上所有先前修改的结果。标签平滑是指在第7节中描述的方法。分解的7×7包括将第一个7×7卷积层分解成3×3卷积层序列的改变。BN-auxiliary是指辅助分类器的全连接层也批标准化的版本，而不仅仅是卷积。我们将表3最后一行的模型称为Inception-v3，并在多裁剪图像和组合设置中评估其性能。</p><p>我们所有的评估都在ILSVRC-2012验证集上的48238个非黑名单样本中完成。我们也对所有50000个样本进行了评估，结果在top-5错误率中大约为0.1%，在top-1错误率中大约为0.2%。在本文即将出版的版本中，我们将在测试集上验证我们的组合结果，但是我们上一次对BN-Inception的春季测试表明测试集和验证集错误趋于相关性很好。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210320143145.png"><p>表5：模型组合评估结果，比较多模型，多裁剪图像的报告结果。我们的数据与ILSVRC 2012分类基准数据集上发布的最好模型组合推断结果的比较。所有的结果，除了在验证集上的top-5模型组合结果。模型组合在验证集上取得了3.46% top-5错误率。</p><h2 id="11-结论"><a href="#11-结论" class="headerlink" title="11  结论"></a>11  结论</h2><p>我们提供了几个设计原则来扩展卷积网络，并在Inception体系结构的背景下进行研究。这个指导可以导致高性能的视觉网络，与更简单、更单一的体系结构相比，它具有相对适中的计算成本。Inception-v3的最高质量版本在ILSVR 2012分类上的单裁剪图像评估中达到了21.2％的top-1错误率和5.6％的top-5错误率，达到了新的水平。与Ioffe等中描述的网络相比，这是通过增加相对适中（$2.5/times$）的计算成本来实​​现的。尽管如此，我们的解决方案所使用的计算量比基于更密集网络公布的最佳结果要少得多：我们的模型比He等的结果更好——将top-5(top-1)的错误率相对分别减少了25% (14%)，然而在计算代价上便宜了六倍，并且使用了至少减少了五倍的参数（估计值）。我们的四个Inception-v3模型的组合效果达到了3.5％，多裁剪图像评估达到了3.5％的top-5的错误率，这相当于比最佳发布的结果减少了25％以上，几乎是ILSVRC 2014的冠军GoogLeNet组合错误率的一半。</p><p>我们还表明，可以通过感受野分辨率为79×79的感受野取得高质量的结果。这可能证明在检测相对较小物体的系统中是有用的。我们已经研究了在神经网络中如何分解卷积和积极降维可以导致计算成本相对较低的网络，同时保持高质量。较低的参数数量、额外的正则化、批标准化的辅助分类器和标签平滑的组合允许在相对适中大小的训练集上训练高质量的网络。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文翻译 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GoogLeNetV3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【图像分类—GoogLeNet Inception V2】Batch Normalization</title>
      <link href="/article/6.html"/>
      <url>/article/6.html</url>
      
        <content type="html"><![CDATA[<p>BN的提出是为了克服深度神经网络难以训练的弊病，减轻了对参数初始化的依赖；训练更快，可以使用更高的学习率；BN一定程度上增加了泛化能力，dropout等技术可以去掉。</p><a id="more"></a><img width="600" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210319211025.png"><h1 id="论文翻译"><a href="#论文翻译" class="headerlink" title="论文翻译"></a>论文翻译</h1><blockquote><p>论文：<a href="http://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p></blockquote><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>训练深度神经网络的复杂性在于每层输入的分布在训练过程中会发生变化，因为前面的层的参数会发生变化。通过要求较低的学习率和仔细的参数初始化减慢了训练，并且使具有饱和非线性的模型训练起来非常困难。我们将这种现象称为内部协变量转移，并通过标准化层输入来解决这个问题。我们的方法力图使标准化成为模型架构的一部分，并为每个训练小批量数据执行标准化。批标准化使我们能够使用更高的学习率，并且不用太注意初始化。它也作为一个正则化项，在某些情况下不需要Dropout。将批量标准化应用到最先进的图像分类模型上，批标准化在取得相同的精度的情况下，减少了14倍的训练步骤，并以显著的差距击败了原始模型。使用批标准化网络的组合，我们改进了在ImageNet分类上公布的最佳结果: 达到了4.9％ top-5的验证误差(和4.8％测试误差)，超过了人类评估者的准确性。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>深度学习在视觉、语音等诸多方面显著提高了现有技术的水平。随机梯度下降(SGD)已经被证明是训练深度网络的有效方式，并且已经使用诸如动量(Sutskever，2013)和Adagrad(Duchi, 2011)等SGD变种取得了最先进的性能。SGD优化网络参数$\Theta$，以最小化损失<br>$$\Theta = \arg \min_\Theta \frac{1}{N}\sum_{i=1}^N \ell(x_i, \Theta)$$</p><p>$x_{1\ldots N}$是训练数据集。使用SGD，训练将逐步进行，在每一步中，我们考虑一个大小为$m$的小批量数据$x_{1 \ldots m}$。通过计算$\frac {1} {m} \sum _{i=1} ^m \frac {\partial \ell(x_i, \Theta)} {\partial \Theta}$，使用小批量数据来近似损失函数关于参数的梯度。使用小批量样本，而不是一次一个样本，在一些方面是有帮助的。首先，小批量数据的梯度损失是训练集上的梯度估计，其质量随着批量增加而改善。第二，由于现代计算平台提供的并行性，对一个批次的计算比单个样本计算$m$次效率更高。</p><p>虽然随机梯度是简单有效的，但它需要仔细调整模型的超参数，特别是优化中使用的学习速率以及模型参数的初始值。训练的复杂性在于每层的输入受到前面所有层的参数的影响——因此当网络变得更深时，网络参数的微小变化就会被放大。</p><p>层输入的分布变化是一个问题，因为这些层需要不断适应新的分布。当学习系统的输入分布发生变化时，据说会经历协变量转移(Shimodaira，2000)。这通常是通过域适应(Jiang，2008)来处理的。然而，协变量漂移的概念可以扩展到整个学习系统之外，应用到学习系统的一部分，例如子网络或一层。考虑网络计算</p><p>$$\ell = F_2(F_1(u, \Theta_1), \Theta_2)$$</p><p>$F_1$ 和$F_2$是任意变换，学习参数$\Theta_1$，$\Theta_2$以便最小化损失$\ell$。学习$\Theta_2$可以看作输入$x=F_1(u,\Theta_1)$送入到子网络</p><p>$$\ell = F_2(x, \Theta_2)$$</p><p>例如，梯度下降步骤<br>$$\Theta_2\leftarrow \Theta_2 - \frac {\alpha} {m} \sum_{i=1}^m \frac {\partial F_2(x_i,\Theta_2)} {\partial \Theta_2}$$</p><p>对于批大小$m$和学习率$\alpha$）与输入为$x$的单独网络$F_2$完全等价。因此，输入分布特性使训练更有效——例如训练数据和测试数据之间有相同的分布——也适用于训练子网络。因此$x$的分布在时间上保持固定是有利的。然后，$\Theta_2$不必重新调整来补偿$x$分布的变化。</p><p>子网络输入的固定分布对于子网络外的层也有积极的影响。考虑一个激活函数为$g(x) = \frac{1}{1+\exp(-x)}$的层，$u$是层输入，权重矩阵$W$和偏置向量$b$是要学习的层参数，$g(x) = \frac{1}{1+\exp(-x)}$。随着$|x|$的增加，$g^{\prime}(x)$趋向于0。这意味着对于$x=Wu+b$的所有维度，除了那些具有小的绝对值之外，流向$u$的梯度将会消失，模型将缓慢的进行训练。然而，由于$x$受$W,b$和下面所有层的参数的影响，训练期间那些参数的改变可能会将$x$的许多维度移动到非线性的饱和状态并减慢收敛。这个影响随着网络深度的增加而放大。在实践中，饱和问题和由此产生的梯度消失通常通过使用修正线性单元(Nair &amp; Hinton, 2010) $ReLU(x)=\max(x,0)$，仔细的初始化(Bengio &amp; Glorot, 2010; Saxe et al., 2013)和小的学习率来解决。然而，如果我们能保证非线性输入的分布在网络训练时保持更稳定，那么优化器将不太可能陷入饱和状态，训练将加速。</p><p>我们把训练过程中深度网络内部结点的分布变化称为内部协变量转移。消除它可以保证更快的训练。我们提出了一种新的机制，我们称为为批标准化，它是减少内部协变量转移的一个步骤，这样做可以显著加速深度神经网络的训练。它通过标准化步骤来实现，标准化步骤修正了层输入的均值和方差。批标准化减少了梯度对参数或它们的初始值尺度上的依赖，对通过网络的梯度流动有有益的影响。这允许我们使用更高的学习率而没有发散的风险。此外，批标准化使模型正则化并减少了对Dropout(Srivastava et al., 2014)的需求。最后，批标准化通过阻止网络陷入饱和模式让使用饱和非线性成为可能。</p><p>在4.2小节，我们将批标准化应用到性能最好的ImageNet分类网络上，并且表明我们可以使用仅7％的训练步骤来匹配其性能，并且可以进一步超过其准确性一大截。通过使用批标准化训练的网络的集合，我们取得了top-5错误率，其改进了ImageNet分类上已知的最佳结果。</p><h2 id="2-减少内部协变量转变"><a href="#2-减少内部协变量转变" class="headerlink" title="2 减少内部协变量转变"></a>2 减少内部协变量转变</h2><p>由于训练过程中网络参数的变化，我们将内部协变量转移定义为网络激活分布的变化。为了改善训练，我们寻求减少内部协变量转移。随着训练的进行，通过固定层输入$x$的分布，我们期望提高训练速度。众所周知(LeCun et al., 1998b; Wiesler &amp; Ney, 2011)如果对网络的输入进行白化，网络训练将会收敛的更快——即输入线性变换为具有零均值和单位方差，并去相关。当每一层观察下面的层产生的输入时，实现每一层输入进行相同的白化将是有利的。通过白化每一层的输入，我们将采取措施实现输入的固定分布，消除内部协变量转移的不良影响。</p><p>我们考虑在每个训练步骤或在某些间隔来白化激活值，通过直接修改网络或根据网络激活值来更改优化方法的参数(Wiesler et al., 2014; Raiko et al., 2012; Povey et al., 2014; Desjardins &amp; Kavukcuoglu)。然而，如果这些修改分散在优化步骤中，那么梯度下降步骤可能会试图以要求标准化进行更新的方式来更新参数，这会降低梯度下降步骤的影响。例如，考虑一个层，其输入u加上学习到的偏置$b$，通过减去在训练集上计算的激活值的均值对结果进行归一化：$\hat x=x - E[x]$，$x=u+b$, $X={x_{1\ldots N}}$是训练集上$x$值的集合，$E[x] = \frac{1}{N}\sum_{i=1}^N x_i$。如果梯度下降步骤忽略了E[x]对b的依赖，那它将更新$b\leftarrow b+\Delta b$，其中$\Delta b\propto -\partial{\ell}/\partial{\hat x}$。然后$u+(b+\Delta b) -E[u+(b+\Delta b)] = u+b-E[u+b]$。因此，结合b的更新和接下来标准化中的改变会导致层的输出没有变化，从而导致损失没有变化。随着训练的继续，$b$将无限增长而损失保持不变。如果标准化不仅中心化而且缩放了激活值，问题会变得更糟糕。我们在最初的实验中已经观察到了这一点，当标准化参数在梯度下降步骤之外计算时，模型会爆炸。</p><p>上述方法的问题是梯度下降优化没有考虑到标准化中发生的事实。为了解决这个问题，我们希望确保对于任何参数值，网络总是产生具有所需分布的激活值。这样做将允许关于模型参数损失的梯度来解释标准化，以及它对模型参数$\Theta$的依赖。设$x$为层的输入，将其看作向量，$\mathcal{X}$是这些输入在训练集上的集合。标准化可以写为变换</p><p>$$\hat x=Norm(x,\mathcal{X})$$</p><p>它不仅依赖于给定的训练样本x而且依赖于所有样本X——它们中的每一个都依赖于Θ，如果x是由另一层生成的。对于反向传播，我们将需要计算Jacobians $\frac {\partial Norm(x,\mathcal X)} {\partial x}$和$\frac {\partial Norm(x,\mathcal X)} {\partial \mathcal X}$；忽略后一项会导致上面描述的爆炸。在这个框架中，白化层输入是昂贵的，因为它要求计算协方差矩阵$Cov[x]=E_{x\in \mathcal X}[x x^T]- E[x]E[x]^T$和它的平方根倒数，从而生成白化的激活$Cov[x]^{-1/2}(x-E[x])$和这些变换进行反向传播的偏导数。这促使我们寻求一种替代方案，以可微分的方式执行输入标准化，并且在每次参数更新后不需要对整个训练集进行分析。</p><p>以前的一些方法(例如(Lyu＆Simoncelli，2008))使用通过单个训练样本计算的统计信息，或者在图像网络的情况下，使用给定位置处不同特征图上的统计。然而，通过丢弃激活值绝对尺度改变了网络的表示能力。我们希望通过对相对于整个训练数据统计信息的单个训练样本的激活值进行归一化来保留网络中的信息。</p><h2 id="3-通过Mini-Batch统计进行标准化"><a href="#3-通过Mini-Batch统计进行标准化" class="headerlink" title="3 通过Mini-Batch统计进行标准化"></a>3 通过Mini-Batch统计进行标准化</h2><p>由于每一层输入的整个白化是代价昂贵的并且不是到处可微分的，因此我们做了两个必要的简化。首先是我们将单独标准化每个标量特征，从而代替在层输入输出对特征进行共同白化，使其具有零均值和单位方差。对于具有$d$维输入$x = (x^{(1)}\ldots x^{(d)})$的层，我们将标准化每一维</p><p>$$\hat x^{(k)} = \frac{x^{(k)} - E[x^{(k)}]} {\sqrt {Var[x^{(k)}]}}$$</p><p>其中期望和方差在整个训练数据集上计算。如(LeCun et al., 1998b)中所示，这种标准化加速了收敛，即使特征没有去相关。</p><p>注意简单标准化层的每一个输入可能会改变层可以表示什么。例如，标准化sigmoid的输入会将它们约束到非线性的线性状态。为了解决这个问题，我们要确保插入到网络中的变换可以表示恒等变换。为了实现这个，对于每一个激活值$x^{(k)}$，我们引入成对的参数$\gamma^{(k)}，\beta^{(k)}$，它们会归一化和移动标准化值：</p><p>$$y^{(k)} = \gamma^{(k)}\hat x^{(k)} + \beta^{(k)}.$$</p><p>这些参数与原始的模型参数一起学习，并恢复网络的表示能力。实际上，通过设置$\gamma^{(k)} = \sqrt{Var[x^{(k)}]}$和$\beta^{(k)} = E[x^{(k)}]$，我们可以重新获得原始的激活值，如果这是要做的最优的事。</p><p>每个训练步骤的批处理设置是基于整个训练集的，我们将使用整个训练集来标准化激活值。然而，当使用随机优化时，这是不切实际的。因此，我们做了第二个简化：由于我们在随机梯度训练中使用小批量，每个小批量产生每次激活平均值和方差的估计。这样，用于标准化的统计信息可以完全参与梯度反向传播。注意，通过计算每一维的方差而不是联合协方差，可以实现小批量的使用；在联合情况下，将需要正则化，因为小批量大小可能小于白化的激活值的数量，从而导致单个协方差矩阵。</p><p>考虑一个大小为$m$的小批量数据$\mathcal B$。由于标准化被单独地应用于每一个激活，所以让我们集中在一个特定的激活$x^{(k)}$，为了清晰忽略$k$。在小批量数据里我们有这个激活的$m$个值，</p><p>$$\mathcal B=\lbrace x_{1\ldots m} \rbrace.$$</p><p>设标准化值为$\hat x_{1\ldots m}$，它们的线性变换为$y_{1\ldots m}$。我们把变换</p><p>$$BN_{\gamma,\beta}: x_{1\ldots m}\rightarrow y_{1\ldots m}$$</p><p>看作批标准化变换。我们在算法1中提出了BN变换。在算法中，为了数值稳定，$\epsilon$是一个加到小批量数据方差上的常量。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210319210911.png"><p>BN变换可以添加到网络上来操纵任何激活。在公式$y = BN_{\gamma,\beta}(x)$中，我们指出参数$\gamma$和$\beta$需要进行学习，但应该注意到在每一个训练样本中BN变换不单独处理激活。相反，$BN_{\gamma,\beta}(x)$取决于训练样本和小批量数据中的其它样本。缩放和移动的值$y$传递到其它的网络层。标准化的激活值$\hat x$在我们的变换内部，但它们的存在至关重要。只要每个小批量的元素从相同的分布中进行采样，如果我们忽略$\epsilon$，那么任何$\hat x$值的分布都具有期望为0，方差为1。这可以通过观察$\sum_{i=1}^m \hat x_i = 0$和$\frac {1} {m} \sum_{i=1}^m \hat x_i^2 = 1$看到，并取得预期。每一个标准化的激活值$\hat x^{(k)}$可以看作由线性变换$y^{(k)}=\gamma^{(k)}\hat x^{(k)}+\beta^{(k)}$组成的子网络的输入，接下来是原始网络的其它处理。所有的这些子网络输入都有固定的均值和方差，尽管这些标准化的$\hat x^{(k)}$的联合分布可能在训练过程中改变，但我们预计标准化输入的引入会加速子网络的训练，从而加速整个网络的训练。</p><p>在训练过程中我们需要通过这个变换反向传播损失ℓ的梯度，以及计算关于BN变换参数的梯度。我们使用的链式法则如下(简化之前)：</p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">  <mtable displaystyle="true" columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" rowspacing="3pt">    <mtr>      <mtd>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msub>              <mrow>                <mover>                  <mi>x</mi>                  <mo stretchy="false">^</mo>                </mover>              </mrow>              <mrow>                <mi>i</mi>              </mrow>            </msub>          </mrow>        </mfrac>      </mtd>      <mtd>        <mi></mi>        <mo>=</mo>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msub>              <mi>y</mi>              <mrow>                <mi>i</mi>              </mrow>            </msub>          </mrow>        </mfrac>        <mo>⋅</mo>        <mi>γ</mi>      </mtd>    </mtr>    <mtr>      <mtd>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msubsup>              <mi>σ</mi>              <mrow>                <mrow>                  <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">B</mi>                </mrow>              </mrow>              <mrow>                <mn>2</mn>              </mrow>            </msubsup>          </mrow>        </mfrac>      </mtd>      <mtd>        <mi></mi>        <mo>=</mo>        <munderover>          <mo data-mjx-texclass="OP">∑</mo>          <mrow>            <mi>i</mi>            <mo>=</mo>            <mn>1</mn>          </mrow>          <mrow>            <mi>m</mi>          </mrow>        </munderover>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msub>              <mrow>                <mover>                  <mi>x</mi>                  <mo stretchy="false">^</mo>                </mover>              </mrow>              <mrow>                <mi>i</mi>              </mrow>            </msub>          </mrow>        </mfrac>        <mo>⋅</mo>        <mrow data-mjx-texclass="INNER">          <mo data-mjx-texclass="OPEN">(</mo>          <msub>            <mi>x</mi>            <mrow>              <mi>i</mi>            </mrow>          </msub>          <mo>−</mo>          <msub>            <mi>μ</mi>            <mrow>              <mrow>                <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">B</mi>              </mrow>            </mrow>          </msub>          <mo data-mjx-texclass="CLOSE">)</mo>        </mrow>        <mo>⋅</mo>        <mfrac>          <mrow>            <mo>−</mo>            <mn>1</mn>          </mrow>          <mn>2</mn>        </mfrac>        <msup>          <mrow data-mjx-texclass="INNER">            <mo data-mjx-texclass="OPEN">(</mo>            <msubsup>              <mi>σ</mi>              <mrow>                <mrow>                  <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">B</mi>                </mrow>              </mrow>              <mrow>                <mn>2</mn>              </mrow>            </msubsup>            <mo>+</mo>            <mi>ϵ</mi>            <mo data-mjx-texclass="CLOSE">)</mo>          </mrow>          <mrow>            <mo>−</mo>            <mn>3</mn>            <mrow>              <mo>/</mo>            </mrow>            <mn>2</mn>          </mrow>        </msup>      </mtd>    </mtr>    <mtr>      <mtd>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msub>              <mi>μ</mi>              <mrow>                <mrow>                  <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">B</mi>                </mrow>              </mrow>            </msub>          </mrow>        </mfrac>      </mtd>      <mtd>        <mi></mi>        <mo>=</mo>        <munderover>          <mo data-mjx-texclass="OP">∑</mo>          <mrow>            <mi>i</mi>            <mo>=</mo>            <mn>1</mn>          </mrow>          <mrow>            <mi>m</mi>          </mrow>        </munderover>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msub>              <mrow>                <mover>                  <mi>x</mi>                  <mo stretchy="false">^</mo>                </mover>              </mrow>              <mrow>                <mi>i</mi>              </mrow>            </msub>          </mrow>        </mfrac>        <mo>⋅</mo>        <mfrac>          <mrow>            <mo>−</mo>            <mn>1</mn>          </mrow>          <msqrt>            <msubsup>              <mi>σ</mi>              <mrow>                <mrow>                  <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">B</mi>                </mrow>              </mrow>              <mrow>                <mn>2</mn>              </mrow>            </msubsup>            <mo>+</mo>            <mi>ϵ</mi>          </msqrt>        </mfrac>      </mtd>    </mtr>    <mtr>      <mtd>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msub>              <mi>x</mi>              <mrow>                <mi>i</mi>              </mrow>            </msub>          </mrow>        </mfrac>      </mtd>      <mtd>        <mi></mi>        <mo>=</mo>        <munderover>          <mo data-mjx-texclass="OP">∑</mo>          <mrow>            <mi>i</mi>            <mo>=</mo>            <mn>1</mn>          </mrow>          <mrow>            <mi>m</mi>          </mrow>        </munderover>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msub>              <mrow>                <mover>                  <mi>x</mi>                  <mo stretchy="false">^</mo>                </mover>              </mrow>              <mrow>                <mi>i</mi>              </mrow>            </msub>          </mrow>        </mfrac>        <mo>⋅</mo>        <mfrac>          <mrow>            <mo>−</mo>            <mn>1</mn>          </mrow>          <msqrt>            <msubsup>              <mi>σ</mi>              <mrow>                <mrow>                  <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">B</mi>                </mrow>              </mrow>              <mrow>                <mn>2</mn>              </mrow>            </msubsup>            <mo>+</mo>            <mi>ϵ</mi>          </msqrt>        </mfrac>        <mo>+</mo>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msubsup>              <mi>σ</mi>              <mrow>                <mrow>                  <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">B</mi>                </mrow>              </mrow>              <mrow>                <mn>2</mn>              </mrow>            </msubsup>          </mrow>        </mfrac>        <mo>⋅</mo>        <mfrac>          <mrow>            <mn>2</mn>            <mrow data-mjx-texclass="INNER">              <mo data-mjx-texclass="OPEN">(</mo>              <msub>                <mi>x</mi>                <mrow>                  <mi>i</mi>                </mrow>              </msub>              <mo>−</mo>              <msub>                <mi>μ</mi>                <mrow>                  <mrow>                    <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">B</mi>                  </mrow>                </mrow>              </msub>              <mo data-mjx-texclass="CLOSE">)</mo>            </mrow>          </mrow>          <mi>m</mi>        </mfrac>        <mo>+</mo>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msub>              <mi>μ</mi>              <mrow>                <mrow>                  <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">B</mi>                </mrow>              </mrow>            </msub>          </mrow>        </mfrac>        <mo>⋅</mo>        <mfrac>          <mn>1</mn>          <mi>m</mi>        </mfrac>      </mtd>    </mtr>    <mtr>      <mtd>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>γ</mi>          </mrow>        </mfrac>      </mtd>      <mtd>        <mi></mi>        <mo>=</mo>        <munderover>          <mo data-mjx-texclass="OP">∑</mo>          <mrow>            <mi>i</mi>            <mo>=</mo>            <mn>1</mn>          </mrow>          <mrow>            <mi>m</mi>          </mrow>        </munderover>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msub>              <mi>y</mi>              <mrow>                <mi>i</mi>              </mrow>            </msub>          </mrow>        </mfrac>        <mo>⋅</mo>        <msub>          <mrow>            <mover>              <mi>x</mi>              <mo stretchy="false">^</mo>            </mover>          </mrow>          <mrow>            <mi>i</mi>          </mrow>        </msub>      </mtd>    </mtr>    <mtr>      <mtd>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>β</mi>          </mrow>        </mfrac>      </mtd>      <mtd>        <mi></mi>        <mo>=</mo>        <munderover>          <mo data-mjx-texclass="OP">∑</mo>          <mrow>            <mi>i</mi>            <mo>=</mo>            <mn>1</mn>          </mrow>          <mrow>            <mi>m</mi>          </mrow>        </munderover>        <mfrac>          <mrow>            <mi mathvariant="normal">∂</mi>            <mi>ℓ</mi>          </mrow>          <mrow>            <mi mathvariant="normal">∂</mi>            <msub>              <mi>y</mi>              <mrow>                <mi>i</mi>              </mrow>            </msub>          </mrow>        </mfrac>      </mtd>    </mtr>  </mtable></math><p>因此，BN变换是将标准化激活引入到网络中的可微变换。这确保了在模型训练时，层可以继续学习输入分布，表现出更少的内部协变量转移，从而加快训练。此外，应用于这些标准化的激活上的学习到的仿射变换允许BN变换表示恒等变换并保留网络的能力。</p><h3 id="3-1-批标准化网络的训练和推断"><a href="#3-1-批标准化网络的训练和推断" class="headerlink" title="3.1 批标准化网络的训练和推断"></a>3.1 批标准化网络的训练和推断</h3><p>为了批标准化一个网络，根据算法1，我们指定一个激活的子集，然后在每一个激活中插入BN变换。任何以前接收$x$作为输入的层现在接收$BN(x)$作为输入。采用批标准化的模型可以使用批梯度下降，或者用小批量数据大小为$m&gt;1$的随机梯度下降，或使用它的任何变种例如Adagrad (Duchi et al., 2011)进行训练。依赖小批量数据的激活值的标准化可以有效地训练，但在推断过程中是不必要的也是不需要的；我们希望输出只确定性地取决于输入。为此，一旦网络训练完成，我们使用总体统计来进行标准化</p><p>$$\hat x=\frac {x - E[x]} {\sqrt{Var[x] + \epsilon}},$$</p><p>而不是小批量数据统计。跟训练过程中一样，如果忽略$\epsilon$，这些标准化的激活具有相同的均值0和方差1。我们使用无偏方差估计$Var[x] = \frac {m} {m-1} \cdot E_\mathcal B[\sigma_\mathcal B^2]$，其中期望是在大小为m的小批量训练数据上得到的，$\sigma_\mathcal B^2$是其样本方差。使用这些值移动平均，我们在训练过程中可以跟踪模型的准确性。由于均值和方差在推断时是固定的，因此标准化是应用到每一个激活上的简单线性变换。它可以进一步由缩放$\gamma$和转移$\beta$组成，以产生代替$BN(x)$的单线性变换。算法2总结了训练批标准化网络的过程。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210319210919.png"><h3 id="3-2-批标准化卷积网络"><a href="#3-2-批标准化卷积网络" class="headerlink" title="3.2. 批标准化卷积网络"></a>3.2. 批标准化卷积网络</h3><p>批标准化可以应用于网络的任何激活集合。这里我们专注于仿射变换和元素级非线性组成的变换：</p><p>$$z = g(Wu+b)$$</p><p>其中$W$和$b$是模型学习的参数，$g(\cdot)$是非线性例如sigmoid或ReLU。这个公式涵盖了全连接层和卷积层。我们在非线性之前通过标准化$x=Wu+b$加入BN变换。我们也可以标准化层输入$u$，但由于$u$可能是另一个非线性的输出，它的分布形状可能在训练过程中改变，并且限制其第一矩或第二矩不能去除协变量转移。相比之下，$Wu+b$更可能具有对称，非稀疏分布，即“更高斯”(Hyvärinen＆Oja，2000)；对其标准化可能产生具有稳定分布的激活。</p><p>注意，由于我们对$Wu+b$进行标准化，偏置$b$可以忽略，因为它的效应将会被后面的中心化取消(偏置的作用会归入到算法1的$\beta$)。因此，$z=g(Wu+b)$被</p><p>$$z = g(BN(Wu))$$</p><p>替代，其中BN变换独立地应用到$x=Wu$的每一维，每一维具有单独的成对学习参数$\gamma^{(k)}$，$\beta^{(k)}$。</p><p>另外，对于卷积层我们希望标准化遵循卷积特性——为的是同一特征映射的不同元素，在不同的位置，以相同的方式进行标准化。为了实现这个，我们在所有位置联合标准化了小批量数据中的所有激活。在算法1中，我们让$\mathcal B$是跨越小批量数据的所有元素和空间位置的特征图中所有值的集合——因此对于大小为$m$的小批量数据和大小为p×q的特征映射，我们使用有效的大小为$m^{\prime}=|\mathcal B| = m\cdot p, q$的小批量数据。我们每个特征映射学习一对参数$\gamma^{(k)}$和$\beta^{(k)}$，而不是每个激活。算法2进行类似的修改，以便推断期间BN变换对在给定的特征映射上的每一个激活应用同样的线性变换。</p><h3 id="3-3-批标准化可以提高学习率"><a href="#3-3-批标准化可以提高学习率" class="headerlink" title="3.3 批标准化可以提高学习率"></a>3.3 批标准化可以提高学习率</h3><p>在传统的深度网络中，学习率过高可能会导致梯度爆炸或梯度消失，以及陷入差的局部最小值。批标准化有助于解决这些问题。通过标准化整个网络的激活值，在数据通过深度网络传播时，它可以防止层参数的微小变化被放大。例如，这使sigmoid非线性更容易保持在它们的非饱和状态，这对训练深度sigmoid网络至关重要，但在传统上很难实现。</p><p>批标准化也使训练对参数的缩放更有弹性。通常，大的学习率可能会增加层参数的缩放，这会在反向传播中放大梯度并导致模型爆炸。然而，通过批标准化，通过层的反向传播不受其参数缩放的影响。实际上，对于标量$a$，</p><p>$$BN(Wu) = BN((aW)u)$$</p><p>我们有</p><p>$$\frac {\partial BN((aW)u)} {\partial u}= \frac {\partial BN(Wu)} {\partial u} \ \frac {\partial BN((aW)u)} {\partial (aW)}=\frac {1} {a} \cdot \frac {\partial BN(Wu)} {\partial W}$$</p><p>因此标量不影响层的Jacobian行列式，从而不影响梯度传播。此外，更大的权重会导致更小的梯度，并且批标准化会稳定参数的增长。</p><p>我们进一步推测，批标准化可能会导致雅可比行列式的奇异值接近于1，这被认为对训练是有利的(Saxe et al., 2013)。考虑具有标准化输入的两个连续的层，并且变换位于这些标准化向量之间：$\hat z = F(\hat x)$。如果我们假设$\hat x$和$\hat z$是高斯分布且不相关的，那么$F(\hat x)\approx J \hat x$是对给定模型参数的一个线性变换，x^和z^有单位方差，并且$I=Cov[\hat z] =J Cov[\hat x] J^T = JJ^T$。因此，$J$是正交的，其保留了反向传播中的梯度大小。尽管上述假设在现实中不是真实的，但我们希望批标准化有助于梯度传播更好的执行。这有待于进一步研究。</p><h2 id="4-实验"><a href="#4-实验" class="headerlink" title="4 实验"></a>4 实验</h2><h3 id="4-1-随时间激活"><a href="#4-1-随时间激活" class="headerlink" title="4.1 随时间激活"></a>4.1 随时间激活</h3><p>为了验证内部协变量转移对训练的影响，以及批标准化对抗它的能力，我们考虑了在MNIST数据集上预测数字类别的问题(LeCun et al., 1998a)。我们使用非常简单的网络，28x28的二值图像作为输入，以及三个全连接层，每层100个激活。每一个隐藏层用sigmoid非线性计算$y=g(Wu+b)$，权重$W$初始化为小的随机高斯值。最后的隐藏层之后是具有10个激活(每类1个)和交叉熵损失的全连接层。我们训练网络50000次迭代，每份小批量数据中有60个样本。如第3.1节所述，我们在网络的每一个隐藏层后添加批标准化。我们对基准线和批标准化网络之间的比较感兴趣，而不是实现在MNIST上的最佳性能(所描述的架构没有)。</p><p>图1(a)显示了随着训练进行，两个网络在提供的测试数据上正确预测的分数。批标准化网络具有更高的测试准确率。为了调查原因，我们在训练过程中研究了原始网络$N$和批标准化网络$N_{BN}^{tr}$(Alg. 2)中的sigmoid输入。在图1(b，c)中，我们显示，对于来自每个网络的最后一个隐藏层的一个典型的激活，其分布如何演变。原始网络中的分布随着时间的推移而发生显著变化，无论是平均值还是方差，都会使后面的层的训练复杂化。相比之下，随着训练的进行，批标准化网络中的分布更加稳定，这有助于训练。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210319210926.png"><p>图1：(a)使用批标准化和不使用批标准化训练的网络在MNIST上的测试准确率，以及训练的迭代次数。批标准化有助于网络训练的更快，取得更高的准确率。(b，c)典型的sigmoid在训练过程中输入分布的演变，显示为15%，50%，85%。批标准化使分布更稳定并降低了内部协变量转移。</p><h3 id="4-2-ImageNet分类"><a href="#4-2-ImageNet分类" class="headerlink" title="4.2 ImageNet分类"></a>4.2 ImageNet分类</h3><p>我们将批标准化化应用于在ImageNet分类任务(Russakovsky等，2014)上训练的Inception网络的新变种(Szegedy等，2014)。网络具有大量的卷积和池化层，和一个softmax层用来在1000个可能之中预测图像的类别。卷积层使用ReLU作为非线性。与(Szegedy等人，2014年)中描述的网络的主要区别是5×5卷积层被两个连续的3x3卷积层替换，最多可以有128个滤波器。该网络包含$13.6 \cdot 10^6$个参数，除了顶部的softmax层之外，没有全连接层。在其余的文本中我们将这个模型称为Inception。训练在大型分布式架构(Dean et al。，2012)上进行，10个模型副本中的每一个都使用了5个并行步骤，使用异步带动量的SGD(Sutskever等，2013)，小批量数据大小为32。随着训练进行，所有网络都通过计算验证准确率@1来评估，即每幅图像使用单个裁剪图像，在1000个可能性中预测正确标签的概率。</p><p>在我们的实验中，我们评估了几个带有批标准化的Inception修改版本。在所有情况下，如第3.2节所述，批标准化以卷积方式应用于每个非线性的输入，同时保持架构的其余部分不变。</p><h4 id="4-2-1-加速BN网络"><a href="#4-2-1-加速BN网络" class="headerlink" title="4.2.1. 加速BN网络"></a>4.2.1. 加速BN网络</h4><p>将批标准化简单添加到网络中不能充分利用我们方法的优势。为此，我们进行了以下修改：</p><p><strong>提高学习率</strong>。在批标准化模型中，我们已经能够从高学习率中实现训练加速，没有不良的副作用(第3.3节)。</p><p><strong>删除丢弃</strong>。我们发现从BN-Inception中删除丢弃可以使网络实现更高的验证准确率。我们推测，批标准化提供了类似丢弃的正则化收益，因为对于训练样本观察到的激活受到了同一小批量数据中样本随机选择的影响。</p><p><strong>更彻底地搅乱训练样本</strong>。我们启用了分布内部搅乱训练数据，这样可以防止同一个例子一起出现在小批量数据中。这导致验证准确率提高了约1％，这与批标准化作为正则化项的观点是一致的：它每次被看到时都会影响一个样本，在我们的方法中内在的随机化应该是最有益的。</p><p><strong>减少L2全中正则化</strong>。虽然在Inception中模型参数的L2损失会控制过拟合，但在修改的BN-Inception中，损失的权重减少了5倍。我们发现这提高了在提供的验证数据上的准确性。</p><p><strong>加速学习率衰减</strong>。在训练Inception时，学习率呈指数衰减。因为我们的网络训练速度比Inception更快，所以我们将学习速度降低加快6倍。</p><p><strong>删除局部响应归一化</strong>。虽然Inception和其它网络(Srivastava等人，2014)从中受益，但是我们发现使用批标准化它是不必要的。</p><p><strong>减少光照扭曲</strong>。因为批标准化网络训练更快，并且观察每个训练样本更少的次数，所以通过更少地扭曲它们，我们让训练器关注更多的“真实”图像。</p><h4 id="4-2-2-单网络分类"><a href="#4-2-2-单网络分类" class="headerlink" title="4.2.2 单网络分类"></a>4.2.2 单网络分类</h4><p>我们评估了下面的网络，所有的网络都在LSVRC2012训练数据上训练，并在验证数据上测试：</p><p>Inception：在4.2小节开头描述的网络，以0.0015的初始学习率进行训练。</p><p>BN-Baseline：每个非线性之前加上批标准化，其它的与Inception一样。</p><p>BN-x5：带有批标准化的Inception，修改在4.2.1小节中。初始学习率增加5倍到了0.0075。原始Inception增加同样的学习率会使模型参数达到机器无限大。</p><p>BN-x30：类似于BN-x5，但初始学习率为0.045(Inception学习率的30倍)。</p><p>BN-x5-Sigmoid：类似于BN-x5，但使用sigmoud非线性$g(t)=\frac{1}{1+\exp(-x)}$来代替ReLU。我们也尝试训练带有sigmoid的原始Inception，但模型保持在相当于机会的准确率。</p><p>在图2中，我们显示了网络的验证集准确率，作为训练步骤次数的函数。Inception网络在$31 \cdot 10^6$次训练步骤后达到了72.2％的准确率。图3显示，对于每个网络，达到同样的72.2％准确率需要的训练步骤数量，以及网络达到的最大验证集准确率和达到该准确率的训练步骤数量。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210319210934.png"><p>图2：Inception和它的批标准化变种在单个裁剪图像上的验证准确率以及训练步骤的数量。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210319210939.png"><p>图3：对于Inception和批量归一化变量，要达到Inception的最大准确性(72.2％)和网络所达到的最大准确性，所需的训练步骤数。</p><p>通过仅使用批标准化(BN-Baseline)，我们在不到Inception一半的训练步骤数量内将准确度与其相匹配。通过应用4.2.1小节中的修改，我们显著提高了网络的训练速度。BN-x5需要比Inception少14倍的步骤就达到了72.2％的准确率。有趣的是，进一步提高学习率(BN-x30)使得该模型最初训练有点慢，但可以使其达到更高的最终准确率。这种现象是违反直觉的，应进一步调查。在$6 \cdot 10^6$步骤之后，BN-x30达到74.8％的准确率，即比Inception达到72.2％的准确率所需的步骤减少了5倍。</p><p>我们也证实了尽管训练这样的网络是众所周知的困难，但是当使用sigmoid作为非线性时，内部协变量转移的减少允许具有批标准化的深层网络被训练。的确，BN-x5-Sigmoid取得了69.8％的准确率达。没有批标准化，使用sigmoid的Inception从未达到比1/1000准确率更好的结果。</p><h4 id="4-2-3-组合分类"><a href="#4-2-3-组合分类" class="headerlink" title="4.2.3 组合分类"></a>4.2.3 组合分类</h4><p>目前在ImageNet大型视觉识别竞赛中报道的最佳结果是传统模型(Wu et al，2015)的Deep Image组合和(He等，2015)的组合模型。后者报告了ILSVRC测试服务器评估的4.94％的top-5错误率。这里我们在测试服务器上报告4.82％的测试错误率。这提高了以前的最佳结果，并且根据(Russakovsky等，2014)这超过了人类评估者的评估准确率。</p><p>对于我们的组合，我们使用了6个网络。每个都是基于BN-x30的，进行了以下一些修改：增加卷积层中的初始重量；使用Dropout(丢弃概率为5％或10％，而原始Inception为40％)；模型最后的隐藏层使用非卷积批标准化。每个网络在大约$6 \cdot 10^6$个训练步骤之后实现了最大的准确率。组合预测是基于组成网络的预测类概率的算术平均。组合和多裁剪图像推断的细节与(Szegedy et al，2014)类似。</p><p>我们在图4中证实了批标准化使我们能够在ImageNet分类挑战基准上设置新的最佳结果。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210319210945.png"><p>图4：批标准化Inception与以前的最佳结果在提供的包含5万张图像的验证集上的比较。组合结果是在测试集上由测试服务器评估的结果。BN-Inception组合在验证集的5万张图像上取得了4.9% top-5的错误率。所有报道的其它结果是在验证集上。</p><h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a>5 结论</h2><p>我们提出了一个新的机制，大大加快了深度网络的训练。它是基于前提协变量转移的，已知其会使机器学习系统的训练复杂化，也适用于子网络和层，并且从网络的内部激活中去除它可能有助于训练。我们提出的方法从其标准化激活中获取其功能，并将这种标准化合并到网络架构本身。这确保了标准化可以被用来训练网络的任何优化方法进行恰当的处理。为了让深度网络训练中常用的随机优化方法可用，我们对每个小批量数据执行标准化，并通过标准化参数来反向传播梯度。批标准化每个激活只增加了两个额外的参数，这样做可以保持网络的表示能力。我们提出了一个算法，其用于构建，训练和执行推断批标准化网络。所得到的网络可以用饱和非线性进行训练，能更容忍增加的训练率，并且通常不需要丢弃来进行正则化。</p><p>仅仅将批标准化添加到了最新的图像分类模型中便在训练中取得了实质的加速。通过进一步提高学习率，删除丢弃和应用批标准化所提供的其它修改，我们只用了少部分的训练步骤就达到了以前的技术水平——然后在单网络图像分类中击败了最先进的技术。此外，通过组合多个使用批标准化训练的模型，我们在ImageNet上的表现显著优于最好的已知系统。</p><p>我们的方法与(Gülçehre＆Bengio，2013)的标准化层相似，尽管这两个方法解决的目标不同。批标准化寻求在整个训练过程中激活值的稳定分布，并且对非线性的输入进行归一化，因为这时更有可能稳定分布。相反，标准化层被应用于非线性的输出，这导致了更稀疏的激活。我们没有观察到非线性输入是稀疏的，无论是有批标准化还是没有批标准化。批标准化的其它显著差异包括学习到的缩放和转移允许BN变换表示恒等，卷积层处理以及不依赖于小批量数据的确定性推断。</p><p>在这项工作中，我们没有探索批标准化可能实现的全部可能性。我们的未来工作包括将我们的方法应用于循环神经网络(Pascanu et al，2013)，其中内部协变量转移和梯度消失或爆炸可能特别严重，这将使我们能够更彻底地测试假设标准化改善了梯度传播(第3.3节)。需要对批标准化的正则化属性进行更多的研究，我们认为这是BN-Inception中删除丢弃时我们观察到的改善的原因。我们计划调查批标准化是否有助于传统意义上的域自适应——即网络执行标准化是否能够更容易泛化到新的数据分布，也许仅仅是对总体均值和方差的重新计算(Alg.2)。最后，我们认为，该算法的进一步理论分析将允许更多的改进和应用。</p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p><strong>使用的初始模型的变体</strong></p><p>图5记录了与GoogleNet架构相比与架构相比所做的更改。有关此表的解释，请参考(Szegedy等，2014)。与GoogLeNet模型相比，值得注意的架构更改包括：</p><ul><li>5x5卷积层被两个串联的3x3卷积层替代。这最大深度增加了9 层权重层。同时，它增加了25%的参数量，增加了30%的计算量。</li><li>28x28 Inception模块的数量从2个增加到3个。</li><li>在模块内部，有时使用平均池，有时使用最大池。这在与表的池层相对应的条目中表示。</li><li>在任何两个Inception模块之间没有跨板池化层，但是在模块3c，4e中的过滤器级联之前采用了stride-2卷积/池化层。</li></ul><p>我们的模型在第一卷积层上使用了带有深度乘数8的可分离卷积。这减少了计算成本，同时增加了训练时的内存消耗。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210319210953.png"><center>图5：Inception结构。</center><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文翻译 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GoogLeNetV2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【图像分类—NIN】Network in Network</title>
      <link href="/article/4.html"/>
      <url>/article/4.html</url>
      
        <content type="html"><![CDATA[<p>文章提出在每个局部感受野中进行更加复杂的运算，提出了对卷积层的改进算法：MLP卷积层。传统的卷积神经网络一般来说是由：线性卷积层、池化层、全连接层堆叠起来的网络，卷积层通过线性滤波器进行线性卷积运算，然后在接个非线性激活函数，最终生成特征图。</p><a id="more"></a><img width="600" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318193941.png"><h1 id="一、论文翻译"><a href="#一、论文翻译" class="headerlink" title="一、论文翻译"></a>一、论文翻译</h1><blockquote><p>论文：<a href="https://arxiv.org/abs/1312.4400" target="_blank" rel="noopener">Network In Network</a></p></blockquote><blockquote><p>文章提出在每个局部感受野中进行更加复杂的运算，提出了对卷积层的改进算法：MLP卷积层。传统的卷积神经网络一般来说是由：线性卷积层、池化层、全连接层堆叠起来的网络，卷积层通过线性滤波器进行线性卷积运算，然后在接个非线性激活函数，最终生成特征图。</p></blockquote><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>我们提出了一种新型的深度网络结构，称为“Network In Network”（NIN），它可以增强模型在感受野（receptive field）内对局部区域（local patches）的辨别能力。传统的卷积层使用线性滤波器来扫描输入，后面接一个非线性激活函数。而我们则构建了一些结构稍复杂的微型神经网络来抽象receptive field内的数据。 我们用多层感知器实例化微型神经网络，这是一种有效的函数逼近器。特征图可以通过微型神经网络在输入上滑动得到，类似于CNN；接下来特征图被传入下一层。深度NIN可以通过堆叠上述结构实现。通过微型网络增强局部模型，我们就可以在分类层中利用所有特征图的全局平均池化层（GAP），这样更容易解释且比传统的全连接层更不容易过拟合。我们证明了NIN在CIFAR-10和CIFAR-100上得到了有史以来最佳的表现以及在SVHN和MNIST数据集上合理的表现。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>卷积神经网络（CNN）由卷积层和池化层交替组成。卷积层使用线性滤波器和底层receptive field做内积，然后接一个非线性的激活函数，得到的输出称作特征图（feature map）。</p><p>CNN的卷积滤波器是底层数据块的广义线性模型（generalized linear model ）（GLM），而且我们认为它的抽象程度较低。这里的抽象较低是指该特征对同一概念的变体是不变的。用更有效的非线性函数逼近器代替GLM可以增强局部模型的抽象能力。当样本的隐含概念（latent concept）线性可分时，GLM可以达到很好的抽象程度，例如：这些概念的变体都在GLM分割平面的同一边，而传统的CNN就默认了这个假设——认为隐含概念（latent concept）是线性可分的。然而，同一概念的数据通常是非线性流形的（nonlinear manifold），捕捉这些概念的表达通常都是输入的高维非线性函数。在NIN中，GLM用“微型网络”结构替代，该结构是一个非线性函数逼近器。在本项研究中，我们选择多层感知器实例化微型网络，该感知器是一个通用函数逼近器，也是一个通过反向传播训练的神经网络。</p><p>最终结构我们称为“mlpconv”层，与CNN的比较见图1.</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318193956.png"><p>图1 线性卷积层与mlpconv层的比较。线性卷积层包含线性滤波器，而mlpconv层包含的是微型网络（本文选择多层感知器）。两种层都将局部感受野映射到了隐含概念的置信度值 </p><p>线性卷积层和mlpconv层都从局部感受野（receptive field）映射到了输出特征向量。mlpconv 层将局部块的输入通过一个由全连接层和非线性激活函数组成的多层感知器（MLP）映射到了输出的特征向量。MLP在所有局部感受野中共享。特征图通过用像CNN一样的方式在输入上滑动MLP得到，NIN的总体结构是一系列mplconv层的堆叠。被称作“Network In Network”（NIN），因为内部含有MLP。</p><p>我们没有采用传统CNN的全连接层进行分类，而是直接通过全局平均池化层（GAP）输出最后一个mlpconv层特征图的空间平均值作为类别的置信度值，然后将得到的向量输入softmax层。在传统的CNN中，很难解释如何将来自分类层（objective cost layer）的分类信息传递回前一个卷积层，因为全连接层像一个黑盒一样。相比之下，全局平均池化层（GAP）更有意义且容易解释，因为它强化了特征图与分类的对应关系，这是通过使用微型网络构成的局部建模器实现的。此外，全连接层更容易过拟合且严重依赖于dropout正则化，而GAP则本身就是一个结构化的正则化器，能避免整体结构的过拟合。</p><h2 id="2-卷积神经网络"><a href="#2-卷积神经网络" class="headerlink" title="2 卷积神经网络"></a>2 卷积神经网络</h2><p>经典卷积神经网络由卷积层和空间池化层交替堆叠产生。卷积层通过线性卷积滤波器接一个非线性激活函数（如rectifier，sigmoid，tanh等等）生成特征图。例如使用rectifier激活函数，特征图的计算如下：<br>$$f_{i,j,k} = max(w^T_kx_{ij},0) \tag{1}$$<br>这里的$(i, j)$是特征图像素的索引，$x_{ij}$代表以位置$(i, j)$为中心的输入块，$k$用来索引特征图的颜色通道。</p><p>当隐含概念线性可分时，这种线性卷积足以用于抽象，但是要想得到更好的抽象，应该是用输入数据的高度非线性函数。在传统的CNN中，这可以通过利用一套完整的滤波器来弥补，覆盖所有隐含概念的变化。也就是说，单独的线性滤波器可以学习检测同一概念的不同变化。但是同一概念使用太多的滤波器会给下一层带来额外的负担，需要考虑来自前一层的所有变化的组合，来自更高层的滤波器会映射到原始输入的更大区域，它通过结合下层的较低级概念生成较高级的概念，因此，我们认为在每一个局部块结合生成更高级概念之前就作出更好的抽象是更有益的。</p><p>在最近的maxout网络中，特征图的数目通过在affine feature maps上做最大池化来减少（affine feature maps是线性卷积未通过激活函数的直接结果）。线性函数的最大化使分段线性逼近器能逼近任何凸函数。与执行线性可分的传统卷积层相比，maxout网络更有效，因为它能分离在凸集内的概念。这种改进使maxout网络在几个基准数据集上表现出色。</p><p>但是maxout网络加了一个前提：隐含概念位于输入空间的凸集内，而这是不一定的。因此应该使用一个更通用的函数逼近器，在隐含概念处于更复杂的分布时也依然能用。我们通过使用新的“Network In Network”结构在实现这个需求，在每个卷积层内引入一个微型网络，来计计算和抽象每个局部块的特征。</p><p>在输入上滑动微型网络已经在之前的研究中提出过。比如，Sturctured Multilayer Perceptron(SMLP)在输入图片的不同块中使用了共享的多层感知器；在另一项研究中，基于神经网络的滤波器被训练以用于面部检测。但是，他们都是针对某个特定问题设计的，且滑动的网络结构都只有一层。NIN则从一个通用的角度上提出，微型网络被整合到CNN结构中，以追求对各级特征的更好的抽象。</p><h2 id="3-网络中的网络"><a href="#3-网络中的网络" class="headerlink" title="3 网络中的网络"></a>3 网络中的网络</h2><p>我们首先强调提出的“Network In Network”结构的关键组成：3.1节和3.2节分别介绍了MLP卷积层和全局平均池化层。然后我们在3.3节详细介绍NIN整体。</p><h3 id="3-1-MLP卷积层"><a href="#3-1-MLP卷积层" class="headerlink" title="3.1 MLP卷积层"></a>3.1 MLP卷积层</h3><p>由于隐含概念的分布一开始并不知道，所以用一个通用函数逼近器做局部块的特征提取，因为它能逼近隐含概念的更多抽象表示。Radial basis network和多层感知器是两个众所周知的通用函数逼近器。我们使用多层感知器，有两个原因，首先，多层感知器与卷积神经网络的结构一样，都是通过反向传播训练。其次多层感知器本身就是一个深度模型，符合特征再利用的精神。这种多层感知器层在文本被称作mlpconv，我们用它来替代GLM（general linear model）在输入上做卷积。图1展示了线性卷积层和mplconv层的不同。mlpconv层的计算如下：</p><p>$$<br>f^1_{i,j,k_1} = max({w_{k_1}^1}^{T}x_{ij}+b_{k_1},0) \ \tag{2}\<br>\cdots\\<br>f^n_{i,j,k_n} = max({w_{k_n}^n}^{T}f_{ij}^{n-1}+b_{k_n},0)<br>$$</p><p>这里n是多层感知器中的层编号。rectified为多层感知器的激活函数。</p><p>从cross channel（cross feature map）池化的角度来看，公式2等效于级联普通卷积层的cross channel parametric pooling。每个池化层在输入特征图上做加权线性重组，然后通过rectifier函数。池化了的cross channel特征图又在下一层池化，如此一遍又一遍重复。级联的cross channel parameteric pooling结构允许复杂的和可学习的cross channel信息进行交互。</p><p>cross channel parametric pooling层也等效于一个1x1卷积核的卷积层。这个解释可以更直观的理解NIN的结构。</p><p><strong>与maxout层的比较</strong>: maxout网络中的maxout层在affine feature maps上做了最大池化，maxout层的特征图计算如下：<br>$$f_{i,j,k} = \mathop{max}\limits_{m}({w^T_{k_m}}x_{ij}) \tag{3}$$</p><p>maxout线性函数形成了一个分段线性函数，可以给任何凸函数建模。对于一个凸函数来说，函数值在特定阈值下的样本点形成一个凸集，因此，通过拟合局部块的凸函数，可以形成样本点在凸集内的概念的分割超平面（例如，l2 balls, convex cones）。mlpconv层和maxout层的不同之处在与见凸函数拟合器用通用函数拟合器替代，使其能对更多的隐含概念分布建模。</p><h3 id="3-2-全局平均池"><a href="#3-2-全局平均池" class="headerlink" title="3.2 全局平均池"></a>3.2 全局平均池</h3><p>传统卷积神经网络在网络的较低层执行卷积。对于分类任务，最后一个卷积层得到的特征图被向量化然后送入全连接层，接一个softmax逻辑回归层。这种结构将卷积结构与传统神经网络分类器连接起来，见卷积层作为特征提取器，得到的特征用传统方式进行分类。</p><p>但是，全连接层容易过拟合，从而阻碍了整个网络的泛化能力。后来dropout被Hinton等人提出，用于正则化，在训练过程中随机地将全连接层的一半激活值置零，改善了它的泛化能力并且很大程度地预防了过拟合。</p><p>在本文中，我们提出了另一个策略，叫做全局平均池化层，用它来替代CNN中的全连接层。想法是在最后一个mlpconv层生成一个分类任务中相应类别的特征图。我们没有在特征图最顶端增加全连接层，而是求每个特征图的平均值，得到的结果向量直接输入softmax层。GAP相比全连接层的优点在于通过增强特征图与类比间的对应关系使卷积结构保留的更好，使特征图分类是可信的得到很好的解释；另一个优点是GAP层中没有参数设置，因此避免了过拟合；此外，GAP汇聚了空间信息，所以对输入的空间转换更鲁棒。</p><p>我们可以看到GAP作为一个正则化器，加强了特征图与概念（类别）的可信度的联系。这是通过mlpconv层实现的，因为他们比GLM更好逼近置信图（conficence maps）。</p><h3 id="3-3-网络中的网络结构"><a href="#3-3-网络中的网络结构" class="headerlink" title="3.3 网络中的网络结构"></a>3.3 网络中的网络结构</h3><p>NIN的整体结构是一系列mlpconve层的堆叠，最上层接一个GAP层和分类层。mlpconv层间的子层可以被相加，像CNN和maxout网络一样。图2展示了一个包含三个mlpconv层的NIN。每个mlpconv层，包含一个三层的感知器，NIN和微型网络的层数都是灵活的，可以根据具体任务微调。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194007.png"><p>图2 NIN的整体结构。本文的NIN由三个mlpconve层和一个GAP层堆叠而成。</p><h2 id="4-实验"><a href="#4-实验" class="headerlink" title="4 实验"></a>4 实验</h2><h3 id="4-1-概况"><a href="#4-1-概况" class="headerlink" title="4.1 概况"></a>4.1 概况</h3><p>我们在四个基准数据集上评估了NIN：CIFAR-10，CIFAR-100，SVHN和MNIST。网络在这些数据上都使用三层堆叠mplconv层结构，mlpconv层后面都跟随一个最大池化层，把原输入样本缩减一倍。作为正则化器，除了最后一个mlpconv层外所有输出都加一个dropout。除非特别说明，否则实验部分的所有全连接层都用全局平均池化层替代。另一个正则化方法是和Krizhevsky等人一样的权重衰减。图2展示了本节所用的NIN网络整体结构，详细的参数设置在补充材料中。我们使用由AlexKrizhevsky开发的超快速cuda-convnet代码来实现我们的网络。数据预处理和训练集验证集的拆分同Goodfellow。</p><p>我们的训练过程同Krizhevsky等人一样。也就是说，我们手动初始化了权重以及学习率，使用128小批次训练。训练层初始化权重和学习率开始，直到训练集上的准确率停止改善，然后损失率减少10倍，再继续训练，重复直到学习率衰减到1%。</p><h3 id="4-2-CIFAR-10"><a href="#4-2-CIFAR-10" class="headerlink" title="4.2 CIFAR-10"></a>4.2 CIFAR-10</h3><p>CIFAR-10数据集由10类自然图片组成，有50000张训练图片，10000张测试图片，每张图片是32x32的RGB图片。对于这个数据集，我们使用与Goodfellow在maxout network中相同的global contrast normalization和ZCA白化。我们用训练集的最后10000张图片做验证集。</p><p>实验中每个mlpconv层的特征图数与maxout网络相同。有两个超参数用验证集微调，如局部感受野（local receptive field）的大小和权重衰减。超参数调整好后固定，然后重新在训练集合验证集上训练，将最终模型用于测试集。我们在测试集上得到了10.41%的错误率，比当前最优结果降低1%。</p><p>表1展示了与先前方法的对比。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194013.png"><p>我们实验证明，mlpconv层间使用dropout可以通过增加模型泛化能力来提升模型表现。如图3所示，在mlpconv层间引用dropout层错误率减少了20%多。这一结果与Goodfellow等人的一致，所以本文的所有模型mlpconv层间都加了dropout。没有dropout的模型在CIFAR-10数据集上错误率是14.5%，已经超过之前最好的使用正则化的模型（除了maxout）。由于没有dropout的maxout不可靠，所以本文只与有dropout正则器的版本比较。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194018.png"><p>与先前一样，我们也在做了位移和水平翻转的数据增强的CIFAR-10数据集上对我们的方法做了评估，在测试集上达到了8.81%的错误率，创了新纪录。</p><h3 id="4-3-CIFAR-100"><a href="#4-3-CIFAR-100" class="headerlink" title="4.3 CIFAR-100"></a>4.3 CIFAR-100</h3><p>CIFAR-100和CIFAR-10数据规模一样，只是分为100类。因此每一类图的数目是CIFAR-10的1/10。对于CIFAR-100，我们不调整超参数，而是使用和CIFAR-10一样的设置。位移的不同是最后一个mlpconv层输出100个特征图。CIFAR-100在测试集上的错误率为35.68%，超了当前不做数据增强最好的表现1%多。详细的表现比较见表2。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194024.png"><h3 id="4-4-Street-View-House-Numbers"><a href="#4-4-Street-View-House-Numbers" class="headerlink" title="4.4 Street View House Numbers"></a>4.4 Street View House Numbers</h3><p>SVHN数据集由630,420 32x32的彩图组成，分为训练集、测试集和额外集。这个数据集的任务是识别出每张图中间的数字。训练和测试过程同Goodfellow，也就是说，每一类从训练集中选择400张图，从额外集中选200张图作为验证集。剩余的训练集和额外集用于训练。验证集只用于调整超参数，不用于训练。</p><p>数据集的预处理也同Goodfellow，即local contrast normalization。用于SVHN的结构和参数设置同CIFAR-10一样，由三个mlpconv层加GAP组成。我们在这个数据集上得到2.35%的错误率。我们将结果与其他没有做数据增强的方法结果进行比较，如表3所示。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194029.png"><h3 id="4-5-MNIST"><a href="#4-5-MNIST" class="headerlink" title="4.5 MNIST"></a>4.5 MNIST</h3><p>MNIST数据集由28x28的0-9手写数字组成。有60000张训练集图片和10000张测试集图片。对于这个数据集，网络结构同CIFAR-10一样，只是每个mlpconv层的特征图数减少了，因为MNIST比CIFAR-10简单。与先前使用卷积神经网络的结果对比如表4.</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194035.png"><p>我们得到了0.47%的表现，但是没有当前最好的0.45%好，因为MNIST的错误率已经非常低了。</p><h3 id="4-6-作为正则化器的全局平均池"><a href="#4-6-作为正则化器的全局平均池" class="headerlink" title="4.6 作为正则化器的全局平均池"></a>4.6 作为正则化器的全局平均池</h3><p>GAP层和全连接层很相似，都对特征向量做了线性转换。不同的是转换矩阵。GAP的转换矩阵是事先定义的并且仅在共享相同值的块对角线元素上是非零的。全连接层可以有复杂矩阵变换且值是通过反向传播设置的。为了研究GAP的正则化影响，我们用GAP替换全连接层，模型其他部分相同。我们评估了全连接层前面有dropout和没有dropout的模型，都在CIFAR-10上测试，表现比较如表5.</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194041.png"><p>如表5所示，全连接层没有dropout的表现最差，11.59%，与预期一样，全连接层没有正则化器会过拟合。全连接层前增加了dropout后测试集错误率为10.88%。GAP在三者比较中得到了最低错误率10.41%。</p><p>然后我们探索了GAP对传统CNN来说是否也有同样的正则化影响。我们实例化了一个像Hiton等人描述的传统CNN，由三个卷积层和一个局部连接层（local connection layer）组成。局部连接层生成16个特征图，传给没有dropout的全连接层。为了比较的公正性，我们把局部连接层的特征图数从16减到了10，因为GAP的每个类别只允许一个特征图。GAP的等价网络由dropout+带有GAP的全连接层替代，表现在CIFAR-10上测试。</p><p>全连接层的CNN模型只能得到17.56%的错误率，添加dropout后与Hinton等人提到的表现相近——15.99%。用GAP替换全连接层，我们达到16.46%的错误率，与没有dropout的CNN相比提升了1%。这又一次验证了GAP层作为正则化器的有效性。尽管比dropout稍差一些，但是我们认为GAP可能对线性卷积要求过高，因为它需要带有rectified激活函数的线性滤波器来为类别的置信图建模。</p><h3 id="4-7-NIN的可视化"><a href="#4-7-NIN的可视化" class="headerlink" title="4.7 NIN的可视化"></a>4.7 NIN的可视化</h3><p>我们通过GAP来增强NIN最后一个mlpconv层的特征图，使其作为分类是可信的，这可能会加强局部感受野的建模。为了知道这个目标实现了多少，我们提取和可视化了在CIFAR-10上训练的模型的来自最后一个mlpconv层的特征图。</p><p>图4展示了CIFAR-10上测试集上选择的10类的一些示例图和相关特征图。如预期，特征图的最大激活区域和输入的相关真实分类吻合，这明显是GAP加强过的。在真实分类的特征图内，可以看到最大的激活区域出现在与原物体相同的区域，在结构化物体中尤其如此，例如图4第二行的车。注意这些特征图的分类只用类别信息进行训练，如果使用有边界框标注的图片效果会更好。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194050.png"><p>可视化证明了NIN的有效性，通过用mlpconv层建模得到一个更强的局部感受野，使其有效，然后GAP增强了特征图类别的学习。下一步研究可以用于物体侦测，侦测结果可以基于与Farabet等人的场景标记工作相同的类别级特征图来实现。</p><h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a>5 结论</h2><p>我们提出了一个新的深度网络，叫做“Network In Network”（NIN），用于分类任务。这个新结构有mlpconv层组成，使用多层感知器对输入进行卷积，用GAP代替传统CNN中的全连接层。mlpconv层对局部块建模更好，GAP充当结构化正则化器，防止了过拟合。用NIN的这两个组件，我们得到了当前在CIFAR-10，CIFAR-100和SVHN数据集上最好的表现。通过可视化特征图，我们证明了来自NIN的最后一个mlpconv层的特征图得到的分类是可信的，并且使通过NIN做物体侦测变成了可能。</p><hr><h1 id="二、论文解读"><a href="#二、论文解读" class="headerlink" title="二、论文解读"></a>二、论文解读</h1><h2 id="1-Network-In-Network"><a href="#1-Network-In-Network" class="headerlink" title="1 Network In Network"></a>1 Network In Network</h2><p>CNN高层特征其实是低层特征通过某种运算的组合, 至于这个运算的目的就是提取高维特征, 线性卷积层采用的是离散卷积运算, 那么能不能改进这个运算使得特征提取更加高效呢, 基于这种思想, 文章提出在每个局部感受野中进行更加复杂的运算，提出了对卷积层的改进算法：<strong>MLP卷积层</strong></p><p>传统的卷积神经网络一般来说是由：线性卷积层、池化层、全连接层堆叠起来的网络，卷积层通过线性滤波器进行线性卷积运算，然后在接个非线性激活函数，最终生成特征图。一般来说线性卷积层用来提取线性可分的特征，但所提取的特征高度非线性时，需要更加多的filters来提取各种潜在的特征，这样就导致filters太多，使得网络参数太多，网络过于复杂对于计算压力太大且容易过拟合。这就产生了传统卷积网络的两个痛点:</p><ul><li>线性卷积层在处理高度非线性的底层特征时, 使得网络参数过多</li><li>传统的CNN最后一层都是全连接层，参数个数非常之多，容易引起过拟合</li></ul><h2 id="2-MLP卷积层"><a href="#2-MLP卷积层" class="headerlink" title="2 MLP卷积层"></a>2 MLP卷积层</h2><p>如下图所示:</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194057.png"><p>(a): 左图是一个<strong>线性卷积层</strong>, 该层在局部感受野上的运算可以理解为一个单层的网络<br>(b): 右图是一个<strong>MLP卷积层</strong>, 该层可以看成是每个卷积的局部感受野中还包含了一个微型的多层网络, 使得计算比传统CNN更加复杂, 从而提高对非线性特征的提取能力</p><p>MLP卷积层可以理解为在一个传统的CNN卷积层的基础上把网络在局部感受野的尺度上做深, 增加单个NIN的特征表示能力</p><h2 id="3-全局均值池化"><a href="#3-全局均值池化" class="headerlink" title="3 全局均值池化"></a>3 全局均值池化</h2><p>传统的卷积神经网络卷积运算一般是出现在低层网络。对于分类问题，最后一个卷积层的特征图通过量化然后与全连接层连接，最后在接一个softmax逻辑回归分类层。这种网络结构，使得卷积层和传统的神经网络层连接在一起。我们可以把卷积层看做是特征提取器，然后得到的特征再用传统的神经网络进行分类。传统CNN网络中最后全连接层参数过多很容易导致过拟合，造成网络的泛化能力差，Alexnet中使用dropout来防止过拟合提高网络的泛化能力。</p><p><strong>文章提出采用全局均值池化的方法，替代传统CNN中的全连接层</strong>。与传统的全连接层不同，对每个特征图(feature map)的整张图片进行全局均值池化，这样每张特征图都可以得到一个输出。<strong>采用均值池化，可以大大减小网络的参数数量，避免模型过拟合，另一方面它有一个特点，每张特征图相当于一个输出特征，然后这个特征就表示了输出类的特征</strong>。这样如果我们在做1000个分类任务的时候，我们网络在设计的时候，最后一层的特征图个数就要选择1000</p><p><strong>网络结构</strong><br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194102.png"></p><p>在全局结构图中我们可看到:</p><ul><li>在局部网络中, 在局部感受野进行卷积运算的基础上又加了两层小的全连接层</li></ul><ol><li>NIN的实现方式</li></ol><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194107.png"><ul><li><p>由Caffe的prototxt文件可知, 在实现NIN的时候, 全连接层的实现方式为:设置一个滤波器大小为1,步长为1的卷积层实现全连接层</p></li><li><p>由输出尺寸公式得, 内部小网络的增加并不改变输出数据体的大小:<br>$$\frac{W−F+2P}{S}+1=\frac{W−1+0}{1}+1=W$$</p></li></ul><ol start="2"><li>全局均值池化</li></ol><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318194113.png"><ul><li>在Alexnet网络中最后一个卷积层输出的特征图大小是6∗6, pooling的<strong>大小选择6，方法选择：AVE进行全局均值池化</strong></li></ul><p>综上, 在AlexNet的基础上, 只需要简简单单的把卷积核的大小变一下，然后最后一层的全连接层直接用avg pooling替换一下就可以实现了</p><p>参考：</p><ol><li><a href="https://arxiv.org/abs/1312.4400" target="_blank" rel="noopener">《Network In Network》</a></li><li><a href="http://dgschwend.github.io/netscope/#/preset/nin" target="_blank" rel="noopener">nin imagenet</a></li><li><a href="http://simtalk.cn/2016/10/05/Network-In-Network/" target="_blank" rel="noopener">Network In Network</a></li><li><a href="https://github.com/BVLC/caffe/wiki/Model-Zoo#network-in-network-model" target="_blank" rel="noopener">Network in Network model</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文翻译 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NiN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【图像分类—GoogLeNet Inception V1】Going Deeper With Convolutions</title>
      <link href="/article/3.html"/>
      <url>/article/3.html</url>
      
        <content type="html"><![CDATA[<p>Google Inception Net 首次出现在 ILSVRC 2014的比赛中（和VGGNet 同年），就以较大优势取得了第一名。它最大的特点就是控制了计算量和参数量的同时，获得了非常好的分类性能——top-5 错误率 6.67%。Inception V1 有22 层深，比 AlexNet的8层或者 VGGNet的19层还要更深。但其大小却比AlexNet和VGG小很多，计算量只有 15亿次浮点运算，同时只有500万的参数量，仅为 AlexNet 参数量（6000万）的 1/12。</p><a id="more"></a><img width="600" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318152602.png"><h1 id="一、论文翻译"><a href="#一、论文翻译" class="headerlink" title="一、论文翻译"></a>一、论文翻译</h1><blockquote><p>论文：<a href="https://arxiv.org/pdf/1409.4842v1.pdf" target="_blank" rel="noopener">Going deeper with convolutions</a></p></blockquote><blockquote><p>Google Inception Net 首次出现在 ILSVRC 2014的比赛中（和VGGNet 同年），就以较大优势取得了第一名。它最大的特点就是控制了计算量和参数量的同时，获得了非常好的分类性能——top-5 错误率 6.67%。Inception V1 有22 层深，比 AlexNet的8层或者 VGGNet的19层还要更深。但其大小却比AlexNet和VGG小很多，计算量只有 15亿次浮点运算，同时只有500万的参数量，仅为 AlexNet 参数量（6000万）的 1/12。</p></blockquote><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>我们在ImageNet大规模视觉识别挑战赛2014（ILSVRC14）上提出了一种代号为Inception的深度卷积神经网络结构，并在分类和检测上取得了新的最好结果。这个架构的主要特点是提高了网络内部计算资源的利用率。通过精心的手工设计，我们在增加了网络深度和广度的同时保持了计算预算不变。为了优化质量，架构的设计以赫布理论和多尺度处理直觉为基础。我们在ILSVRC14提交中应用的一个特例被称为GoogLeNet，一个22层的深度网络，其质量在分类和检测的背景下进行了评估。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>过去三年中，由于深度学习和卷积网络的发展，我们的目标分类和检测能力得到了显著提高。一个令人鼓舞的消息是，大部分的进步不仅仅是更强大硬件、更大数据集、更大模型的结果，而主要是新的想法、算法和网络结构改进的结果。例如，ILSVRC 2014竞赛中最靠前的输入除了用于检测目的的分类数据集之外，没有使用新的数据资源。我们在ILSVRC 2014中的GoogLeNet提交实际使用的参数只有两年前Krizhevsky等人获胜结构参数的1/12，而结果明显更准确。在目标检测前沿，最大的收获不是来自于越来越大的深度网络的简单应用，而是来自于深度架构和经典计算机视觉的协同，像Girshick等人的R-CNN算法那样。</p><p>另一个显著因素是随着移动和嵌入式设备的推动，我们的算法的效率很重要——尤其是它们的电力和内存使用。值得注意的是，正是包含了这个因素的考虑才得出了本文中呈现的深度架构设计，而不是单纯的为了提高准确率。对于大多数实验来说，模型被设计为在一次推断中保持15亿乘加的计算预算，所以最终它们不是单纯的学术好奇心，而是能在现实世界中应用，甚至是以合理的代价在大型数据集上使用。</p><p>在本文中，我们将关注一个高效的计算机视觉深度神经网络架构，代号为Inception，它的名字来自于Lin等人网络论文中的Network与著名的“we need to go deeper”网络迷的结合。在我们的案例中，单词“deep”用在两个不同的含义中：首先，在某种意义上，我们以“Inception module”的形式引入了一种新层次的组织方式，在更直接的意义上增加了网络的深度。一般来说，可以把Inception模型看作论文的逻辑顶点同时从Arora等人的理论工作中受到了鼓舞和引导。这种架构的好处在ILSVRC 2014分类和检测挑战赛中通过实验得到了验证，它明显优于目前的最好水平。</p><h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><p>从LeNet-5开始，卷积神经网络（CNN）通常有一个标准结构——堆叠的卷积层（后面可以选择有对比归一化和最大池化）后面是一个或更多的全连接层。这个基本设计的变种在图像分类著作流行，并且目前为止在MNIST，CIFAR和更著名的ImageNet分类挑战赛中的已经取得了最佳结果。对于更大的数据集例如ImageNet来说，最近的趋势是增加层的数目和层的大小，同时使用丢弃来解决过拟合问题。</p><p>尽管担心最大池化层会引起准确空间信息的损失，但与相同的卷积网络结构也已经成功的应用于定位，目标检测和行人姿态估计。</p><p>受灵长类视觉皮层神经科学模型的启发，Serre等人使用了一系列固定的不同大小的Gabor滤波器来处理多尺度。我们使用一个了类似的策略。然而，与Thomas Serre的固定的2层深度模型相反，Inception结构中所有的滤波器是学习到的。此外，Inception层重复了很多次，在GoogleNet模型中得到了一个22层的深度模型。</p><p>Network-in-Network是Lin等人为了增加神经网络表现能力而提出的一种方法。在他们的模型中，网络中添加了额外的1 × 1卷积层，增加了网络的深度。我们的架构中大量的使用了这个方法。但是，在我们的设置中，1 × 1卷积有两个目的：最关键的是，它们主要是用来作为降维模块来移除卷积瓶颈，否则将会限制我们网络的大小。这不仅允许了深度的增加，而且允许我们网络的宽度增加但没有明显的性能损失。</p><p>最后，目前最好的目标检测是Girshick等人的基于区域的卷积神经网络（R-CNN）方法。R-CNN将整个检测问题分解为两个子问题：利用低层次的信号例如颜色，纹理以跨类别的方式来产生目标位置候选区域，然后用CNN分类器来识别那些位置上的对象类别。这样一种两个阶段的方法利用了低层特征分割边界框的准确性，也利用了目前的CNN非常强大的分类能力。我们在我们的检测提交中采用了类似的方式，但探索增强这两个阶段，例如对于更高的目标边界框召回使用多盒预测，并融合了更好的边界框候选区域分类方法。</p><h2 id="3-动机和高层思考"><a href="#3-动机和高层思考" class="headerlink" title="3 动机和高层思考"></a>3 动机和高层思考</h2><p>提高深度神经网络性能最直接的方式是增加它们的尺寸。这不仅包括增加深度——网络层次的数目——也包括它的宽度：每一层的单元数目。这是一种训练更高质量模型容易且安全的方法，尤其是在可获得大量标注的训练数据的情况下。但是这个简单方案有两个主要的缺点。更大的尺寸通常意味着更多的参数，这会使增大的网络更容易过拟合，尤其是在训练集的标注样本有限的情况下。这是一个主要的瓶颈，因为要获得强标注数据集费时费力且代价昂贵，经常需要专家评委在各种细粒度的视觉类别进行区分，例如图1中显示的ImageNet中的类别（甚至是1000类ILSVRC的子集）。</p><img width="300" height="300" src="https://img-blog.csdnimg.cn/20201217191517676.png"><p>统一增加网络尺寸的另一个缺点是计算资源使用的显著增加。例如，在一个深度视觉网络中，如果两个卷积层相连，它们的滤波器数目的任何统一增加都会引起计算量平方式的增加。如果增加的能力使用时效率低下（例如，如果大多数权重结束时接近于0），那么会浪费大量的计算能力。由于计算预算总是有限的，计算资源的有效分布更偏向于尺寸无差别的增加，即使主要目标是增加性能的质量。</p><p>解决这两个问题的一个基本的方式就是引入稀疏性并将全连接层替换为稀疏的全连接层，甚至是卷积层。除了模仿生物系统之外，由于Arora等人的开创性工作，这也具有更坚固的理论基础优势。他们的主要成果说明如果数据集的概率分布可以通过一个大型稀疏的深度神经网络表示，则最优的网络拓扑结构可以通过分析前一层激活的相关性统计和聚类高度相关的神经元来一层层的构建。虽然严格的数学证明需要在很强的条件下，但事实上这个声明与著名的赫布理论产生共鸣——神经元一起激发，一起连接——实践表明，基础概念甚至适用于不严格的条件下。</p><p>遗憾的是，当碰到在非均匀的稀疏数据结构上进行数值计算时，现在的计算架构效率非常低下。即使算法运算的数量减少100倍，查询和缓存丢失上的开销仍占主导地位：切换到稀疏矩阵可能是不可行的。随着稳定提升和高度调整的数值库的应用，差距仍在进一步扩大，数值库要求极度快速密集的矩阵乘法，利用底层的CPU或GPU硬件的微小细节。非均匀的稀疏模型也要求更多的复杂工程和计算基础结构。目前大多数面向视觉的机器学习系统通过采用卷积的优点来利用空域的稀疏性。然而，卷积被实现为对上一层块的密集连接的集合。为了打破对称性，提高学习水平，从论文开始，ConvNets习惯上在特征维度使用随机的稀疏连接表，然而为了进一步优化并行计算，论文中趋向于变回全连接。目前最新的计算机视觉架构有统一的结构。更多的滤波器和更大的批大小要求密集计算的有效使用。</p><p>这提出了下一个中间步骤是否有希望的问题：一个架构能利用滤波器水平的稀疏性，正如理论所建议的那样，但能通过利用密集矩阵计算来利用我们目前的硬件。稀疏矩阵乘法的大量文献认为对于稀疏矩阵乘法，将稀疏矩阵聚类为相对密集的子矩阵会有更佳的性能。在不久的将来会利用类似的方法来进行非均匀深度学习架构的自动构建，这样的想法似乎并不牵强。</p><p>Inception架构开始是作为案例研究，用于评估一个复杂网络拓扑构建算法的假设输出，该算法试图近似中所示的视觉网络的稀疏结构，并通过密集的、容易获得的组件来覆盖假设结果。尽管是一个非常投机的事情，但与基于的参考网络相比，早期可以观测到适度的收益。随着一点点调整加宽差距，作为基础网络，Inception被证明在定位上下文和目标检测中尤其有用。有趣的是，虽然大多数最初的架构选择已被质疑并分离开进行全面测试，但结果证明它们是局部最优的。然而必须谨慎：尽管Inception架构在计算机上领域取得成功，但这是否可以归因于构建其架构的指导原则仍是有疑问的。确保这一点将需要更彻底的分析和验证。</p><h2 id="4-架构细节"><a href="#4-架构细节" class="headerlink" title="4 架构细节"></a>4 架构细节</h2><p>Inception架构的主要想法是考虑怎样近似卷积视觉网络的最优稀疏结构并用容易获得的密集组件进行覆盖。注意假设转换不变性，这意味着我们的网络将以卷积构建块为基础。我们所需要做的是找到最优的局部构造并在空间上重复它。Arora等人提出了一个层次结构，其中应该分析最后一层的相关统计并将它们聚集成具有高相关性的单元组。这些聚类形成了下一层的单元并与前一层的单元连接。我们假设较早层的每个单元都对应输入层的某些区域，并且这些单元被分成滤波器组。在较低的层（接近输入的层）相关单元集中在局部区域。因此，我们最终会有许多聚类集中在单个区域，它们可以通过下一层的1×1卷积层覆盖。然而也可以预期，将存在更小数目的在更大空间上扩展的聚类，其可以被更大块上的卷积覆盖，在越来越大的区域上块的数量将会下降。为了避免块校正的问题，目前Inception架构形式的滤波器的尺寸仅限于1×1、3×3、5×5，这个决定更多的是基于便易性而不是必要性。这也意味着提出的架构是所有这些层的组合，其输出滤波器组连接成单个输出向量形成了下一阶段的输入。另外，由于池化操作对于目前卷积网络的成功至关重要，因此建议在每个这样的阶段添加一个替代的并行池化路径应该也应该具有额外的有益效果（看图2(a)）。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318152618.png"><p>由于这些“Inception模块”在彼此的顶部堆叠，其输出相关统计必然有变化：由于较高层会捕获较高的抽象特征，其空间集中度预计会减少。这表明随着转移到更高层，3×3和5×5卷积的比例应该会增加。</p><p>上述模块的一个大问题是在具有大量滤波器的卷积层之上，即使适量的5×5卷积也可能是非常昂贵的，至少在这种朴素形式中有这个问题。一旦池化单元添加到混合中，这个问题甚至会变得更明显：输出滤波器的数量等于前一阶段滤波器的数量。池化层输出和卷积层输出的合并会导致这一阶段到下一阶段输出数量不可避免的增加。虽然这种架构可能会覆盖最优稀疏结构，但它会非常低效，导致在几个阶段内计算量爆炸。</p><p>这导致了Inception架构的第二个想法：在计算要求会增加太多的地方，明智地减少维度。这是基于嵌入的成功：甚至低维嵌入可能包含大量关于较大图像块的信息。然而嵌入以密集、压缩形式表示信息并且压缩信息更难处理。这种表示应该在大多数地方保持稀疏（根据[2]中条件的要求】）并且仅在它们必须汇总时才压缩信号。也就是说，在昂贵的3×3和5×5卷积之前，1×1卷积用来计算降维。除了用来降维之外，它们也包括使用线性修正单元使其两用。最终的结果如图2(b)所示。</p><p>通常，Inception网络是一个由上述类型的模块互相堆叠组成的网络，偶尔会有步长为2的最大池化层将网络分辨率减半。出于技术原因（训练过程中内存效率），只在更高层开始使用Inception模块而在更低层仍保持传统的卷积形式似乎是有益的。这不是绝对必要的，只是反映了我们目前实现中的一些基础结构效率低下。</p><p>该架构的一个有用的方面是它允许显著增加每个阶段的单元数量，而不会在后面的阶段出现计算复杂度不受控制的爆炸。这是在尺寸较大的块进行昂贵的卷积之前通过普遍使用降维实现的。此外，设计遵循了实践直觉，即视觉信息应该在不同的尺度上处理然后聚合，为的是下一阶段可以从不同尺度同时抽象特征。</p><p>计算资源的改善使用允许增加每个阶段的宽度和阶段的数量，而不会陷入计算困境。可以利用Inception架构创建略差一些但计算成本更低的版本。我们发现所有可用的控制允许计算资源的受控平衡，导致网络比没有Inception结构的类似执行网络快3—10倍，但是在这一点上需要仔细的手动设计。</p><h2 id="5-GoogLeNet"><a href="#5-GoogLeNet" class="headerlink" title="5 GoogLeNet"></a>5 GoogLeNet</h2><p>通过“GoogLeNet”这个名字，我们提到了在ILSVRC 2014竞赛的提交中使用的Inception架构的特例。我们也使用了一个稍微优质的更深更宽的Inception网络，但将其加入到组合中似乎只稍微提高了结果。我们忽略了该网络的细节，因为经验证据表明确切架构的参数影响相对较小。表1说明了竞赛中使用的最常见的Inception实例。这个网络（用不同的图像块采样方法训练的）使用了我们组合中7个模型中的6个。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318152624.png"><p>所有的卷积都使用了修正线性激活，包括Inception模块内部的卷积。在我们的网络中感受野是在均值为0的RGB颜色空间中，大小是224×224。“#3×3 reduce”和“#5×5 reduce”表示在3×3和5×5卷积之前，降维层使用的1×1滤波器的数量。在pool proj列可以看到内置的最大池化之后，投影层中1×1滤波器的数量。所有的这些降维/投影层也都使用了线性修正激活。</p><p>网络的设计考虑了计算效率和实用性，因此推断可以单独的设备上运行，甚至包括那些计算资源有限的设备，尤其是低内存占用的设备。当只计算有参数的层时，网络有22层（如果我们也计算池化层是27层）。构建网络的全部层（独立构建块）的数目大约是100。确切的数量取决于机器学习基础设施对层的计算方式。分类器之前的平均池化是基于[12]的，尽管我们的实现有一个额外的线性层。线性层使我们的网络能很容易地适应其它的标签集，但它主要是为了方便使用，我们不期望它有重大的影响。我们发现从全连接层变为平均池化，提高了大约top-1 0.6%的准确率，然而即使在移除了全连接层之后，丢失的使用还是必不可少的。</p><p>给定深度相对较大的网络，有效传播梯度反向通过所有层的能力是一个问题。在这个任务上，更浅网络的强大性能表明网络中部层产生的特征应该是非常有识别力的。通过将辅助分类器添加到这些中间层，可以期望较低阶段分类器的判别力。这被认为是在提供正则化的同时克服梯度消失问题。这些分类器采用较小卷积网络的形式，放置在Inception (4a)和Inception (4b)模块的输出之上。在训练期间，它们的损失以折扣权重（辅助分类器损失的权重是0.3）加到网络的整个损失上。在推断时，这些辅助网络被丢弃。后面的控制实验表明辅助网络的影响相对较小（约0.5），只需要其中一个就能取得同样的效果。</p><p>包括辅助分类器在内的附加网络的具体结构如下：</p><ul><li>一个滤波器大小5×5，步长为3的平均池化层，导致(4a)阶段的输出为4×4×512，(4d)的输出为4×4×528。</li><li>具有128个滤波器的1×1卷积，用于降维和修正线性激活。</li><li>一个全连接层，具有1024个单元和修正线性激活。</li><li>丢弃70%输出的丢弃层。</li><li>使用带有softmax损失的线性层作为分类器（作为主分类器预测同样的1000类，但在推断时移除）。<br>最终的网络模型图如图3所示。</li></ul><img width="600" height="300" src="https://img-blog.csdnimg.cn/20201217192216720.jpg"><h2 id="6-训练方法"><a href="#6-训练方法" class="headerlink" title="6 训练方法"></a>6 训练方法</h2><p>GoogLeNet网络使用DistBelief分布式机器学习系统进行训练，该系统使用适量的模型和数据并行。尽管我们仅使用一个基于CPU的实现，但粗略的估计表明GoogLeNet网络可以用更少的高端GPU在一周之内训练到收敛，主要的限制是内存使用。我们的训练使用异步随机梯度下降，动量参数为0.9，固定的学习率计划（每8次遍历下降学习率4%）。Polyak平均在推断时用来创建最终的模型。</p><p>图像采样方法在过去几个月的竞赛中发生了重大变化，并且已收敛的模型在其他选项上进行了训练，有时还结合着超参数的改变，例如丢弃和学习率。因此，很难对训练这些网络的最有效的单一方式给出明确指导。让事情更复杂的是，受Andrew G的启发，一些模型主要是在相对较小的裁剪图像进行训练，其它模型主要是在相对较大的裁剪图像上进行训练。然而，一个经过验证的方案在竞赛后工作地很好，包括各种尺寸的图像块的采样，它的尺寸均匀分布在图像区域的8%–100%之间，方向角限制为$[\frac{3}{4},\frac{4}{3}]$之间。另外，我们发现Andrew Howard的光度扭曲对于克服训练数据成像条件的过拟合是有用的。</p><h2 id="7-ILSVRC-2014分类挑战赛设置和结果"><a href="#7-ILSVRC-2014分类挑战赛设置和结果" class="headerlink" title="7 ILSVRC 2014分类挑战赛设置和结果"></a>7 ILSVRC 2014分类挑战赛设置和结果</h2><p>ILSVRC 2014分类挑战赛包括将图像分类到ImageNet层级中1000个叶子结点类别的任务。训练图像大约有120万张，验证图像有5万张，测试图像有10万张。每一张图像与一个实际类别相关联，性能度量基于分类器预测的最高分。通常报告两个数字：top-1准确率，比较实际类别和第一个预测类别，top-5错误率，比较实际类别与前5个预测类别：如果图像实际类别在top-5中，则认为图像分类正确，不管它在top-5中的排名。挑战赛使用top-5错误率来进行排名。</p><p>我们参加竞赛时没有使用外部数据来训练。除了本文中前面提到的训练技术之外，我们在获得更高性能的测试中采用了一系列技巧，描述如下：</p><ol><li>我们独立训练了7个版本的相同的GoogLeNet模型（包括一个更广泛的版本），并用它们进行了整体预测。这些模型的训练具有相同的初始化（甚至具有相同的初始权重，由于监督）和学习率策略。它们仅在采样方法和随机输入图像顺序方面不同。</li><li>在测试中，我们采用比Krizhevsky等人更积极的裁剪方法。具体来说，我们将图像归一化为四个尺度，其中较短维度（高度或宽度）分别为256，288，320和352，取这些归一化的图像的左，中，右方块（在肖像图片中，我们采用顶部，中心和底部方块）。对于每个方块，我们将采用4个角以及中心224×224裁剪图像以及方块尺寸归一化为224×224，以及它们的镜像版本。这导致每张图像会得到4×3×6×2=144的裁剪图像。前一年的输入中，Andrew Howard采用了类似的方法，经过我们实证验证，其方法略差于我们提出的方案。我们注意到，在实际应用中，这种积极裁剪可能是不必要的，因为存在合理数量的裁剪图像后，更多裁剪图像的好处会变得很微小（正如我们后面展示的那样）。</li><li>softmax概率在多个裁剪图像上和所有单个分类器上进行平均，然后获得最终预测。在我们的实验中，我们分析了验证数据的替代方法，例如裁剪图像上的最大池化和分类器的平均，但是它们比简单平均的性能略逊。</li></ol><p>在本文的其余部分，我们分析了有助于最终提交整体性能的多个因素。</p><p>竞赛中我们的最终提交在验证集和测试集上得到了top-5 6.67%的错误率，在其它的参与者中排名第一。与2012年的SuperVision方法相比相对减少了56.5%，与前一年的最佳方法（Clarifai）相比相对减少了约40%，这两种方法都使用了外部数据训练分类器。表2显示了过去三年中一些表现最好的方法的统计。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318152639.png"><p>我们也分析报告了多种测试选择的性能，当预测图像时通过改变表3中使用的模型数目和裁剪图像数目。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318152645.png">## 8 ILSVRC 2014检测挑战赛设置和结果ILSVRC检测任务是为了在200个可能的类别中生成图像中目标的边界框。如果检测到的对象匹配的它们实际类别并且它们的边界框重叠至少50%（使用Jaccard索引），则将检测到的对象记为正确。无关的检测记为假阳性且被惩罚。与分类任务相反，每张图像可能包含多个对象或没有对象，并且它们的尺度可能是变化的。报告的结果使用平均精度均值（mAP）。GoogLeNet检测采用的方法类似于R-CNN，但用Inception模块作为区域分类器进行了增强。此外，为了更高的目标边界框召回率，通过选择搜索方法和多箱预测相结合改进了区域生成步骤。为了减少假阳性的数量，超分辨率的尺寸增加了2倍。这将选择搜索算法的区域生成减少了一半。我们总共补充了200个来自多盒结果的区域生成，大约使用60%的区域，同时将覆盖率从92%提高到93%。减少区域生成的数量，增加覆盖率的整体影响是对于单个模型的情况平均精度均值增加了1%。最后，等分类单个区域时，我们使用了6个GoogLeNets的组合。这导致准确率从40%提高到43.9%。注意，与R-CNN相反，由于缺少时间我们没有使用边界框回归。<p>我们首先报告了最好检测结果，并显示了从第一版检测任务以来的进展。与2013年的结果相比，准确率几乎翻了一倍。所有表现最好的团队都使用了卷积网络。我们在表4中报告了官方的分数和每个队伍的常见策略：使用外部数据、集成模型或上下文模型。外部数据通常是ILSVRC12的分类数据，用来预训练模型，后面在检测数据集上进行改善。一些团队也提到使用定位数据。由于定位任务的边界框很大一部分不在检测数据集中，所以可以用该数据预训练一般的边界框回归器，这与分类预训练的方式相同。GoogLeNet输入没有使用定位数据进行预训练。</p><img width="300" height="300" src="https://img-blog.csdnimg.cn/20201217193132998.png"><p>在表5中，我们仅比较了单个模型的结果。最好性能模型是Deep Insight的，令人惊讶的是3个模型的集合仅提高了0.3个点，而GoogLeNet在模型集成时明显获得了更好的结果。</p><img width="300" height="300" src="https://img-blog.csdnimg.cn/20201217193157865.png"><h2 id="9-总结"><a href="#9-总结" class="headerlink" title="9. 总结"></a>9. 总结</h2><p>我们的结果取得了坚实的证据，即通过易获得的密集构造块来近似期望的最优稀疏结果是改善计算机视觉神经网络的一种可行方法。相比于较浅且较窄的架构，这个方法的主要优势是在计算需求适度增加的情况下有显著的质量收益。</p><p>我们的目标检测工作虽然没有利用上下文，也没有执行边界框回归，但仍然具有竞争力，这进一步显示了Inception架构优势的证据。</p><p>对于分类和检测，预期通过更昂贵的类似深度和宽度的非Inception类型网络可以实现类似质量的结果。然而，我们的方法取得了可靠的证据，即转向更稀疏的结构一般来说是可行有用的想法。这表明未来的工作将在先前基础上以自动化方式创建更稀疏更精细的结构，以及将Inception架构的思考应用到其他领域。</p><hr><h1 id="二、论文解读"><a href="#二、论文解读" class="headerlink" title="二、论文解读"></a>二、论文解读</h1><h2 id="1-GoogLeNet"><a href="#1-GoogLeNet" class="headerlink" title="1 GoogLeNet"></a>1 GoogLeNet</h2><p>GoogLeNet的特点是提升了计算资源的利用率，可以在保持网络计算资源不变的前提下，通过工艺上的设计来增加网络的宽度和深度，基于Hebbian法则和多尺度处理来优化性能。 在深度学习中, 提升网络性能最直接的办法就是增加网络深度和宽度, 这也就意味着巨量的参数。但是, 巨量参数<strong>容易产生过拟合</strong>也会大大<strong>增加计算量</strong>。</p><blockquote><p>一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，深度指网络层次数量、宽度指神经元数量。但这种方式存在以下问题：<br>（1）参数太多，如果训练数据集有限，很容易产生过拟合；<br>（2）网络越大、参数越多，计算复杂度越大，难以应用；<br>（3）网络越深，容易出现梯度弥散问题（梯度越往后穿越容易消失），难以优化模型。 </p></blockquote><p>对于大规模稀疏的神经网络，可以通过分析激活值的统计特性和对高度相关的输出进行聚类来逐层构建出一个最优网络, 这点表明<strong>臃肿的稀疏网络可能被不失性能地简化</strong>。解决<strong>过拟合</strong>和<strong>计算成本</strong>的根本方法是将全连接甚至一般的卷积都转化为<strong>稀疏连接</strong>, 早在AlexNet中使用的Dropout就是将网络之间的连接转变为稀疏连接从而减少参数的数据以防止模型过拟合, 但是，计算机软硬件对非均匀稀疏数据的计算效率很差，所以在AlexNet中又重新启用了全连接层，目的是为了更好地优化并行运算。</p><p>GoogLeNet而非GoogleNet是为了向早期的LeNet致敬!</p><h3 id="1-1-Inception模块"><a href="#1-1-Inception模块" class="headerlink" title="1.1 Inception模块"></a>1.1 Inception模块</h3><blockquote><p>如何<strong>既能保持网络结构的稀疏性，又能利用密集矩阵的高计算性能</strong>呢? </p></blockquote><p>在GoogLeNet中提出了Inception结构来实现的, 采用将多个稀疏矩阵合并成相关的稠密子矩阵的方法来解决:</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318152705.png"><ul><li>采用不同大小的卷积核意味着不同大小的感受野，最后的Filter concatenation意味着不同尺度特征的融合</li><li>卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以直接拼接在一起了</li><li>网络越到后面(滤波器变大)，特征越抽象，而且每个特征所涉及的感受野也更大</li></ul><h3 id="1-2-特征聚合过程"><a href="#1-2-特征聚合过程" class="headerlink" title="1.2 特征聚合过程:"></a>1.2 特征聚合过程:</h3><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318152712.png"><ul><li>如上图所示, 我们在相同的一块区域中, 使用不同大小的滤波器进行特征提取, 然后将通过聚类算法将高相关性的区域聚集到一起, filter越来越大, 聚类的数目越来越少</li></ul><img width="300" height="300" src="https://img-blog.csdnimg.cn/20201211212029716.jpg"><ul><li>在pooling层添加一个额外的并行pooling路径用于提高效率<br>采用上面的模块有一个大问题是: 在卷积层顶端由于滤波器太多，即使是5x5的卷积都会让计算成本太高, 于是有了改进的版本:</li></ul><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318152723.png"><h2 id="2-采用1x1卷积核来进行降维"><a href="#2-采用1x1卷积核来进行降维" class="headerlink" title="2 采用1x1卷积核来进行降维:"></a>2 采用1x1卷积核来进行降维:</h2><ul><li>上一层的输出为100x100x128，经过具有256个输出的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256。其中，卷积层的参数为128x5x5x256。假如上一层输出先经过具有32个输出的1x1卷积层，再经过具有256个输出的5x5卷积层，那么最终的输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256，大约减少了4倍。</li></ul><h2 id="3-网络结构"><a href="#3-网络结构" class="headerlink" title="3 网络结构"></a>3 网络结构</h2><img width="600" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318152730.png"><blockquote><p>网络结构解析<br><strong>0、输入</strong><br>原始输入图像为224x224x3，且都进行了零均值化的预处理操作（图像每个像素减去均值）。<br>1、<strong>第一层（卷积层）</strong><br>　　使用7x7的卷积核（滑动步长2，padding为3），64通道，输出为112x112x64，卷积后进行ReLU操作<br>　　经过3x3的max pooling（步长为2），输出为((112 - 3+1)/2)+1=56，即56x56x64，再进行ReLU操作<br><strong>2、第二层（卷积层）</strong><br>　　使用3x3的卷积核（滑动步长为1，padding为1），192通道，输出为56x56x192，卷积后进行ReLU操作<br>　　经过3x3的max pooling（步长为2），输出为((56 - 3+1)/2)+1=28，即28x28x192，再进行ReLU操作<br><strong>3a、第三层（Inception 3a层）</strong><br>　　分为四个分支，采用不同尺度的卷积核来进行处理<br>　　（1）64个1x1的卷积核，然后RuLU，输出28x28x64<br>　　（2）96个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x96，然后进行ReLU计算，再进行128个3x3的卷积（padding为1），输出28x28x128<br>　　（3）16个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x16，进行ReLU计算后，再进行32个5x5的卷积（padding为2），输出28x28x32<br>　　（4）pool层，使用3x3的核（padding为1），输出28x28x192，然后进行32个1x1的卷积，输出28x28x32。<br>将四个结果进行连接，对这四部分输出结果的第三维并联，即64+128+32+32=256，最终输出28x28x256<br><strong>3b、第三层（Inception 3b层）</strong><br>　　（1）128个1x1的卷积核，然后RuLU，输出28x28x128<br>　　（2）128个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x128，进行ReLU，再进行192个3x3的卷积（padding为1），输出28x28x192<br>　　（3）32个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x32，进行ReLU计算后，再进行96个5x5的卷积（padding为2），输出28x28x96<br>　　（4）pool层，使用3x3的核（padding为1），输出28x28x256，然后进行64个1x1的卷积，输出28x28x64。<br>将四个结果进行连接，对这四部分输出结果的第三维并联，即128+192+96+64=480，最终输出输出为28x28x480<br><strong>第四层（4a,4b,4c,4d,4e）、第五层（5a,5b）……，与3a、3b类似，在此就不再重复。</strong><br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318152740.png"></p></blockquote><p><strong>结构</strong></p><ul><li>GoogLeNet采用了模块化的结构，方便增添和修改<br>网络最后采用了average pooling来代替全连接层, 实际在最后还是加了一个全连接层，主要是为了方便以后大家finetune</li><li>虽然移除了全连接，但是网络中依然使用了Dropout</li><li>为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度。文章中说这两个辅助的分类器的loss应该加一个衰减系数，但看caffe中的model也没有加任何衰减。此外，实际测试的时候，这两个额外的- - - softmax会被去掉。</li><li>线性层将softmax损失作为分类器</li><li>所有的reduction/projection层都利用了修正线性激活</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ConvBNReLU</span><span class="params">(in_channels,out_channels,kernel_size)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=<span class="number">1</span>,padding=kernel_size//<span class="number">2</span>),</span><br><span class="line">        nn.BatchNorm2d(out_channels),</span><br><span class="line">        nn.ReLU6(inplace=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InceptionV1Module</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels,out_channels1, out_channels2reduce,out_channels2, out_channels3reduce, out_channels3, out_channels4)</span>:</span></span><br><span class="line">        super(InceptionV1Module, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.branch1_conv = ConvBNReLU(in_channels=in_channels,out_channels=out_channels1,kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.branch2_conv1 = ConvBNReLU(in_channels=in_channels,out_channels=out_channels2reduce,kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch2_conv2 = ConvBNReLU(in_channels=out_channels2reduce,out_channels=out_channels2,kernel_size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        self.branch3_conv1 = ConvBNReLU(in_channels=in_channels, out_channels=out_channels3reduce, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch3_conv2 = ConvBNReLU(in_channels=out_channels3reduce, out_channels=out_channels3, kernel_size=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">        self.branch4_pool = nn.MaxPool2d(kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">        self.branch4_conv1 = ConvBNReLU(in_channels=in_channels, out_channels=out_channels4, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        out1 = self.branch1_conv(x)</span><br><span class="line">        out2 = self.branch2_conv2(self.branch2_conv1(x))</span><br><span class="line">        out3 = self.branch3_conv2(self.branch3_conv1(x))</span><br><span class="line">        out4 = self.branch4_conv1(self.branch4_pool(x))</span><br><span class="line">        out = torch.cat([out1, out2, out3, out4], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InceptionAux</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels,out_channels)</span>:</span></span><br><span class="line">        super(InceptionAux, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.auxiliary_avgpool = nn.AvgPool2d(kernel_size=<span class="number">5</span>, stride=<span class="number">3</span>)</span><br><span class="line">        self.auxiliary_conv1 = ConvBNReLU(in_channels=in_channels, out_channels=<span class="number">128</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.auxiliary_linear1 = nn.Linear(in_features=<span class="number">128</span> * <span class="number">4</span> * <span class="number">4</span>, out_features=<span class="number">1024</span>)</span><br><span class="line">        self.auxiliary_relu = nn.ReLU6(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.auxiliary_dropout = nn.Dropout(p=<span class="number">0.7</span>)</span><br><span class="line">        self.auxiliary_linear2 = nn.Linear(in_features=<span class="number">1024</span>, out_features=out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.auxiliary_conv1(self.auxiliary_avgpool(x))</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        x= self.auxiliary_relu(self.auxiliary_linear1(x))</span><br><span class="line">        out = self.auxiliary_linear2(self.auxiliary_dropout(x))</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InceptionV1</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes=<span class="number">1000</span>, stage=<span class="string">'train'</span>)</span>:</span></span><br><span class="line">        super(InceptionV1, self).__init__()</span><br><span class="line">        self.stage = stage</span><br><span class="line"></span><br><span class="line">        self.block1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">3</span>,out_channels=<span class="number">64</span>,kernel_size=<span class="number">7</span>,stride=<span class="number">2</span>,padding=<span class="number">3</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>,stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">        )</span><br><span class="line">        self.block2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">192</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">192</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.block3 = nn.Sequential(</span><br><span class="line">            InceptionV1Module(in_channels=<span class="number">192</span>,out_channels1=<span class="number">64</span>, out_channels2reduce=<span class="number">96</span>, out_channels2=<span class="number">128</span>, out_channels3reduce = <span class="number">16</span>, out_channels3=<span class="number">32</span>, out_channels4=<span class="number">32</span>),</span><br><span class="line">            InceptionV1Module(in_channels=<span class="number">256</span>, out_channels1=<span class="number">128</span>, out_channels2reduce=<span class="number">128</span>, out_channels2=<span class="number">192</span>,out_channels3reduce=<span class="number">32</span>, out_channels3=<span class="number">96</span>, out_channels4=<span class="number">64</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.block4_1 = InceptionV1Module(in_channels=<span class="number">480</span>, out_channels1=<span class="number">192</span>, out_channels2reduce=<span class="number">96</span>, out_channels2=<span class="number">208</span>,out_channels3reduce=<span class="number">16</span>, out_channels3=<span class="number">48</span>, out_channels4=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.stage == <span class="string">'train'</span>:</span><br><span class="line">            self.aux_logits1 = InceptionAux(in_channels=<span class="number">512</span>,out_channels=num_classes)</span><br><span class="line"></span><br><span class="line">        self.block4_2 = nn.Sequential(</span><br><span class="line">            InceptionV1Module(in_channels=<span class="number">512</span>, out_channels1=<span class="number">160</span>, out_channels2reduce=<span class="number">112</span>, out_channels2=<span class="number">224</span>,</span><br><span class="line">                              out_channels3reduce=<span class="number">24</span>, out_channels3=<span class="number">64</span>, out_channels4=<span class="number">64</span>),</span><br><span class="line">            InceptionV1Module(in_channels=<span class="number">512</span>, out_channels1=<span class="number">128</span>, out_channels2reduce=<span class="number">128</span>, out_channels2=<span class="number">256</span>,</span><br><span class="line">                              out_channels3reduce=<span class="number">24</span>, out_channels3=<span class="number">64</span>, out_channels4=<span class="number">64</span>),</span><br><span class="line">            InceptionV1Module(in_channels=<span class="number">512</span>, out_channels1=<span class="number">112</span>, out_channels2reduce=<span class="number">144</span>, out_channels2=<span class="number">288</span>,</span><br><span class="line">                              out_channels3reduce=<span class="number">32</span>, out_channels3=<span class="number">64</span>, out_channels4=<span class="number">64</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.stage == <span class="string">'train'</span>:</span><br><span class="line">            self.aux_logits2 = InceptionAux(in_channels=<span class="number">528</span>,out_channels=num_classes)</span><br><span class="line"></span><br><span class="line">        self.block4_3 = nn.Sequential(</span><br><span class="line">            InceptionV1Module(in_channels=<span class="number">528</span>, out_channels1=<span class="number">256</span>, out_channels2reduce=<span class="number">160</span>, out_channels2=<span class="number">320</span>,</span><br><span class="line">                              out_channels3reduce=<span class="number">32</span>, out_channels3=<span class="number">128</span>, out_channels4=<span class="number">128</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.block5 = nn.Sequential(</span><br><span class="line">            InceptionV1Module(in_channels=<span class="number">832</span>, out_channels1=<span class="number">256</span>, out_channels2reduce=<span class="number">160</span>, out_channels2=<span class="number">320</span>,out_channels3reduce=<span class="number">32</span>, out_channels3=<span class="number">128</span>, out_channels4=<span class="number">128</span>),</span><br><span class="line">            InceptionV1Module(in_channels=<span class="number">832</span>, out_channels1=<span class="number">384</span>, out_channels2reduce=<span class="number">192</span>, out_channels2=<span class="number">384</span>,out_channels3reduce=<span class="number">48</span>, out_channels3=<span class="number">128</span>, out_channels4=<span class="number">128</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.avgpool = nn.AvgPool2d(kernel_size=<span class="number">7</span>,stride=<span class="number">1</span>)</span><br><span class="line">        self.dropout = nn.Dropout(p=<span class="number">0.4</span>)</span><br><span class="line">        self.linear = nn.Linear(in_features=<span class="number">1024</span>,out_features=num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.block1(x)</span><br><span class="line">        x = self.block2(x)</span><br><span class="line">        x = self.block3(x)</span><br><span class="line">        aux1 = x = self.block4_1(x)</span><br><span class="line">        aux2 = x = self.block4_2(x)</span><br><span class="line">        x = self.block4_3(x)</span><br><span class="line">        out = self.block5(x)</span><br><span class="line">        out = self.avgpool(out)</span><br><span class="line">        out = self.dropout(out)</span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        out = self.linear(out)</span><br><span class="line">        <span class="keyword">if</span> self.stage == <span class="string">'train'</span>:</span><br><span class="line">            aux1 = self.aux_logits1(aux1)</span><br><span class="line">            aux2 = self.aux_logits2(aux2)</span><br><span class="line">            <span class="keyword">return</span> aux1, aux2, out</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    model = InceptionV1()</span><br><span class="line">    print(model)</span><br><span class="line"></span><br><span class="line">    input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">    aux1, aux2, out = model(input)</span><br><span class="line">    print(aux1.shape)</span><br><span class="line">    print(aux2.shape)</span><br><span class="line">    print(out.shape)</span><br></pre></td></tr></tbody></table></figure><h2 id="4-训练策略"><a href="#4-训练策略" class="headerlink" title="4 训练策略"></a>4 训练策略</h2><ul><li>利用分布式机器学习系统和数据并行来训练网络，虽然实现时只用了CPU，但是是可以用个别高端的GPU一周达到收敛的。采用异步随机梯度下降，动量为0.9，学习率每8个epoch下降4%。用Polyak平均来创建最后的模型。</li><li>图像采样的patch大小从图像的8%到100%，选取的长宽比在3/4到4/3之间，光度扭曲也有利于减少过拟合，还使用随机插值方法结合其他超参数的改变来调整图像大小。</li></ul><h2 id="5-稀疏结构和Hebbian原理的学习"><a href="#5-稀疏结构和Hebbian原理的学习" class="headerlink" title="5 稀疏结构和Hebbian原理的学习"></a>5 稀疏结构和Hebbian原理的学习</h2><p>　　人脑神经元的连接是稀疏的，因此研究者认为大型神经网络的合理连接方式应该也是稀疏的。稀疏结构是非常适合神经网络的一种结构，尤其是对非常大型，非常深的神经网络，可以减轻过拟合并降低计算量，例如卷积神经网络就是稀疏的连接。Inception Net的主要目标就是找到最优的稀疏结构单元（即Inception Module），论文中提到其稀疏结构基于 Hebbian原理，这里简单解释一下Hebbian原理：神经反射活动的持续与重复会导致神经元连接稳定性的持久提升，当两个神经元细胞 A 和B 距离很近，并且A 参与了对B重复，持续的兴奋，那么某些代谢会导致A将作为能使B兴奋的细胞。总结一下即“一起发射的神经元会连接一起”（Cells that fire together, were together），学习过程中的刺激会使神经元间的突触强度增加。受 Hebbian原理启发，另一篇文章 Provable Bounds for learning Some Deep Representations 提出，如果数据集的概率分布可以被一个很大很稀疏的神经网络所表达，那么构筑这个网络的最佳方法时逐层构筑网络：将上一层高度相关（correlated）的节点聚类，并将聚类出来的每一个小簇（cluster）连接到一起，如下图所示，这个相关性高的节点应该被连接在一起的结论，即使从神经网络的角度对 Hebbian 原理有效性的证明。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318152750.png"><p> 　　因此一个“好”的稀疏结构，应该是符合 Hebbian原理的，我们应该把相关性高的一簇神经元节点连接在一起。在普通的数据集中，这可能需要对神经元节点聚类，但是在图片数据中，天然的就是临近区域的数据相关性高，因此相邻的像素点被卷积操作连接在一起。而我们可能有多个卷积核，在同一空间位置但在不同通道的卷积核的输出结果相关性极高。因此，一个$1\times1$的卷积就可以很自然的把这些相关性很高的，在同一个空间位置但是不同通道的特征连接在一起，这就是为什么$1\times1$卷积这么频繁的被应用到 Inception Net 中的原因。$1\times1$ 卷积所连接的节点的相关性是最高的，而稍微大一点尺寸的卷积，比如$3\times3$，$5\times5$的卷积所连接的节点的相关性是最高的，而稍微大一点的卷积，比如$3\times3$，$5\times5$的卷积所连接的节点相关性也很高，因此也可以适当地使用一些大尺寸的卷积，增加多样性（diversity）。最后 Inception Module 通过4个分支中不同尺寸的 $1\times1$，$3\times3$，$5\times5$等小型卷积将相关性很高的节点连接在一起，就完成了其设计初衷，构建出了很高效的符合 Hebbian原理的稀疏结构。</p><ol><li><a href="http://noahsnail.com/2017/07/21/2017-07-21-GoogleNet%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E4%B8%AD%E6%96%87%E7%89%88/" target="_blank" rel="noopener">GoogLeNet论文翻译——中文版</a></li><li><a href="https://zhuanlan.zhihu.com/p/22817228" target="_blank" rel="noopener">机器学习进阶笔记之四 | 深入理解GoogLeNet</a></li><li><a href="https://www.cnblogs.com/wj-1314/p/11337807.html" target="_blank" rel="noopener">tensorflow学习笔记——GoogLeNet</a></li><li><a href="http://dgschwend.github.io/netscope/#/preset/googlenet" target="_blank" rel="noopener">GoogleNet</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文翻译 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GoogleNetV1 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【语义分割—FCN】Fully Convolutional Networks for Semantic Segmentation</title>
      <link href="/article/5.html"/>
      <url>/article/5.html</url>
      
        <content type="html"><![CDATA[<p>与经典的CNN在卷积层之后使用全连接层得到固定长度的特征向量进行分类（全连接层＋softmax输出）不同，FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的feature map进行上采样, 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类。</p><a id="more"></a><p><img src="https://img-blog.csdnimg.cn/20210224162304477.png?text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTgzOTAzOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><blockquote><p>论文：<a href="https://arxiv.org/abs/1411.4038v2" target="_blank" rel="noopener">Fully Convolutional Networks for Semantic Segmentation</a></p></blockquote><h1 id="一、论文翻译"><a href="#一、论文翻译" class="headerlink" title="一、论文翻译"></a>一、论文翻译</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>卷积网络在特征分层领域是非常强大的视觉模型。我们证明了经过端到端、像素到像素训练的卷积网络超过语义分割中最先进的技术。我们的核心观点是建立“全卷积”网络，输入任意尺寸，经过有效的推理和学习产生相应尺寸的输出。我们定义并指定全卷积网络的空间，解释它们在空间范围内dense prediction任务(预测每个像素所属的类别)和获取与先验模型联系的应用。我们改编当前的分类网络(AlexNet ,the VGG net, and GoogLeNet)到完全卷积网络和通过微调传递它们的学习表现到分割任务中。然后我们定义了一个跳跃式的架构，结合来自深、粗层的语义信息和来自浅、细层的表征信息来产生准确和精细的分割。我们的完全卷积网络成为了在PASCAL VOC最出色的分割方式（在2012年相对62.2%的平均IU提高了20%），NYUDv2，和SIFT Flow,对一个典型图像推理只需要花费不到0.2秒的时间。 </p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>卷积网络在识别领域前进势头很猛。卷积网不仅全图式的分类上有所提高 ,也在结构化输出的局部任务上取得了进步。包括在目标检测边界框 、部分和关键点预测和局部通信的进步。</p><p>在从粗糙到精细推理的进展中下一步自然是对每一个像素进行预测。早前的方法已经将卷积网络用于语义分割,其中每个像素被标记为其封闭对象或区域的类别，但是这项工作也有缺点。<br><img src="https://img-blog.csdnimg.cn/20201216205711829.png#pic_center" alt="在这里插入图片描述"></p><p>我们证明了经过 端到端 、像素到像素训练的的卷积网络超过语义分割中没有further machinery的最先进的技术。我们认为，这是第一次训练端到端(1)的FCN在像素级别的预测，而且来自监督式预处理(2)。全卷积在现有的网络基础上从任意尺寸的输入预测密集输出。学习和推理能在全图通过密集的前馈计算和反向传播一次执行。网内上采样层能在像素级别预测和通过下采样池化学习。</p><p>这种方法非常有效，无论是渐进地还是完全地，消除了在其他方法中的并发问题。Patchwise训练是常见的 ，但是缺少了全卷积训练的有效性。我们的方法不是利用预处理或者后期处理解决并发问题，包括超像素，proposals，或者对通过随机域事后细化或者局部分类。我们的模型通过重新解释分类网到全卷积网络和微调它们的学习表现将最近在分类上的成功 移植到dense prediction。与此相反，先前的工作应用的是小规模、没有超像素预处理的卷积网。</p><p>语义分割面临在语义和位置的内在张力问题：全局信息解决的“是什么”，而局部信息解决的是“在哪里”。深层特征通过非线性的局部到全局金字塔编码了位置和语义信息。我们在4.2节(见图3）定义了一种利用集合了深、粗层的语义信息和浅、细层的表征信息的特征谱的跨层架构。</p><p>在下一节，我们回顾深层分类网、FCNs和最近一些利用卷积网解决语义分割的相关工作。接下来的章节将解释FCN设计和密集预测权衡，介绍我们的网内上采样和多层结合架构，描述我们的实验框架。最后，我们展示了最先进技术在PASCAL VOC 2011-2, NYUDv2, 和SIFT Flow上的实验结果。</p><h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><p>我们的方法是基于最近深层网络在图像分类上的成功和转移学习。转移第一次被证明在各种视觉识别任务，然后是检测，不仅在实例还有融合proposal-classification模型的语义分割。我们现在重新构建和微调直接的、dense prediction语义分割的分类网。在这个框架里我们绘制FCNs的空间并将过去的或是最近的先验模型置于其中。</p><p>全卷积网络据我们所知，第一次将卷积网扩展到任意尺寸的输入的是Matan等人,它将经典的LeNet扩展到识别字符串的位数。因为他们的网络结构限制在一维的输入串，Matan等人利用译码器译码获得输出。Wolf和Platt将卷积网输出扩展到来检测邮政地址块的四角得分的二维图。这些先前工作做的是推理和用于检测的全卷积式学习。Ning等人定义了一种卷积网络用于秀丽线虫组织的粗糙的、多分类分割，基于全卷积推理。</p><p>全卷积计算也被用在现在的一些多层次的网络结构中。Sermanet等人的滑动窗口检测，Pinherio 和Collobert的语义分割，Eigen等人的图像修复都做了全卷积式推理。全卷积训练很少，但是被Tompson等人用来学习一种端到端的局部检测和姿态估计的空间模型非常有效，尽管他们没有解释或者分析这种方法。</p><p>此外，He等人在特征提取时丢弃了分类网的无卷积部分。他们结合proposals和空间金字塔池来产生一个局部的、固定长度的特征用于分类。尽管快速且有效，但是这种混合模型不能进行端到端的学习。</p><p>基于卷积网的dense prediction近期的一些工作已经将卷积网应用于dense prediction问题，包括Ning等人的语义分割,Farabet等人以及Pinheiro和Collobert；Ciresan等人的电子显微镜边界预测以及Ganin和Lempitsky的通过混合卷积网和最邻近模型的处理自然场景图像;还有Eigen等人的图像修复和深度估计。这些方法的相同点包括如下：</p><ul><li>限制容量和接收域的小模型</li><li>patchwise训练</li><li>超像素投影的预处理，随机场正则化、滤波或局部分类</li><li>输入移位和dense输出的隔行交错输出</li><li>多尺度金字塔处理</li><li>饱和双曲线正切非线性</li><li>集成<br>然而我们的方法确实没有这种机制。但是我们研究了patchwise训练 （3.4节）和从FCNs的角度出发的“shift-and-stitch”dense输出（3.2节）。我们也讨论了网内上采样（3.3节），其中Eigen等人的全连接预测是一个特例。</li></ul><p>和这些现有的方法不同的是，我们改编和扩展了深度分类架构，使用图像分类作为监督预处理，和从全部图像的输入和ground truths(用于有监督训练的训练集的分类准确性)通过全卷积微调进行简单且高效的学习。</p><p>Hariharan等人和Gupta等人也改编深度分类网到语义分割，但是也在混合proposal-classifier模型中这么做了。这些方法通过采样边界框和region proposal进行微调了R-CNN系统,用于检测、语义分割和实例分割。这两种办法都不能进行端到端的学习。他们分别在PASCAL VOC和NYUDv2实现了最好的分割效果，所以在第5节中我们直接将我们的独立的、端到端的FCN和他们的语义分割结果进行比较。</p><h2 id="3-全卷积网络"><a href="#3-全卷积网络" class="headerlink" title="3 全卷积网络"></a>3 全卷积网络</h2><p>卷积网的每层数据是一个$h\times w\times d$的三维数组，其中h和w是空间维度,d是特征或通道维数。第一层是像素尺寸为$h\times w$、颜色通道数为d的图像。高层中的locations和图像中它们连通的locations相对应，被称为接收域。</p><p>卷积网是以平移不变形作为基础的。其基本组成部分(卷积，池化和激励函数)作用在局部输入域，只依赖相对空间坐标。在特定层记$x_{ij}$为在坐标$(i,j)$的数据向量，在following layer有$y_{ij},y_{ij}$的计算公式如下:<br>$$y_{ij} = f_{ks}({x_{si+\delta i,sj+\delta j} }_{0\le \delta i,\delta j \le k})$$</p><p>其中k为卷积核尺寸，s是步长或下采样因素，$f_{ks}$决定了层的类型：一个卷积的矩阵乘或者是平均池化，用于最大池的最大空间值或者是一个激励函数的一个非线性elementwise，亦或是层的其他种类等等。</p><p>当卷积核尺寸和步长遵从转换规则，这个函数形式被表述为如下形式：<br>$$f_{ks} \circ g_{k^{\prime}s^{\prime}} = (f\circ g)_{k^{\prime}+(k-1)s,s^{\prime}}$$<br>当一个普通深度的网络计算一个普通的非线性函数，一个网络只有这种形式的层计算非线性滤波，我们称之为深度滤波或全卷积网络。FCN理应可以计算任意尺寸的输入并产生相应（或许重采样)空间维度的输出。</p><p>一个实值损失函数有FCN定义了task。如果损失函数是一个最后一层的空间维度总和,$\ell(x;\theta) = \sum_{ij} \ell^{\prime}(x_{ij};\theta)$，它的梯度将是它的每层空间组成梯度总和。所以在全部图像上的基于l的随机梯度下降计算将和基于$\ell^{\prime}$的梯度下降结果一样，将最后一层的所有接收域作为minibatch（分批处理）。在这些接收域重叠很大的情况下，前反馈计算和反向传播计算整图的叠层都比独立的patch-by-patch有效的多。</p><p>我们接下来将解释怎么将分类网络转换到能产生粗输出图的全卷积网络。对于像素级预测，我们需要连接这些粗略的输出结果到像素。3.2节描述了一种技巧，快速扫描因此被引入。我们通过将它解释为一个等价网络修正而获得了关于这个技巧的一些领悟。作为一个高效的替换，我们引入了去卷积层用于上采样见3.3节。在3.4节，我们考虑通过patchwise取样训练，便在4.3节证明我们的全图式训练更快且同样有效。</p><h3 id="3-1-改编分类用于dense-prediction"><a href="#3-1-改编分类用于dense-prediction" class="headerlink" title="3.1 改编分类用于dense prediction"></a>3.1 改编分类用于dense prediction</h3><p>典型的识别网络，包括LeNet, AlexNet, 和一些后续文章，表面上采用的是固定尺寸的输入产生了非空间的输出。这些网络的全连接层有确定的位数并丢弃空间坐标。然而，这些全连接层也被看做是覆盖全部输入域的核卷积。需要将它们加入到可以采用任何尺寸输入并输出分类图的全卷积网络中。这种转换如图2所示(相比之下，如Le等人的非卷积网，缺乏这种能力。)<br><img src="https://img-blog.csdnimg.cn/20201216205751863.png#pic_center" alt="在这里插入图片描述"><br>此外，当作为结果的图在特殊的输入patches上等同于原始网络的估计，计算是高度摊销的在那些patches的重叠域上。例如，当AlexNet花费了1.2ms（在标准的GPU上)推算一个227<em>227图像的分类得分，全卷积网络花费22ms从一张500</em>500的图像上产生一个10*10的输出网格，比朴素法快了5倍多。</p><p>这些卷积化模式的空间输出图可以作为一个很自然的选择对于dense问题，比如语义分割。每个输出单元ground truth可用，正推法和逆推法都是直截了当的，都利用了卷积的固有的计算效率(和可极大优化性)。对于AlexNet例子相应的逆推法的时间为单张图像时间2.4ms，全卷积的10*10输出图为37ms，结果是相对于顺推法速度加快了。</p><p>当我们将分类网络重新解释为任意输出尺寸的全卷积域输出图，输出维数也通过下采样显著的减少了。分类网络下采样使filter保持小规模同时计算要求合理。这使全卷积式网络的输出结果变得粗糙，通过输入尺寸因为一个和输出单元的接收域的像素步长等同的因素来降低它。</p><h3 id="3-2-Shift-and-stitch是滤波稀疏"><a href="#3-2-Shift-and-stitch是滤波稀疏" class="headerlink" title="3.2 Shift-and stitch是滤波稀疏"></a>3.2 Shift-and stitch是滤波稀疏</h3><p>dense prediction能从粗糙输出中通过从输入的平移版本中将输出拼接起来获得。如果输出是因为一个因子f降低采样，平移输入的x像素到左边，y像素到下面，一旦对于每个(x,y)满足$0\le x,y \le f-1$.处理$f^2$个输入，并将输出交错以便预测和它们接收域的中心像素一致。</p><p>考虑一个层（卷积或者池化）中的输入步长s,和后面的滤波权重为$f_{ij}$的卷积层（忽略不相关的特征维数）。设置更低层的输入步长到l上采样它的输出影响因子为s。然而，将原始的滤波和上采样的输出卷积并没有产生和shift-and-stitch相同的结果，因为原始的滤波只看得到（已经上采样）输入的简化的部分。为了重现这种技巧，通过扩大来稀疏滤波，如下:</p><p>$$<br>f_{i, j}^{\prime}=\begin{cases}<br>f_{i / s, j / s}, \quad \text { if } s \text { divides both } i \text { and } j \\<br>0, \quad \text { otherwise }<br>\end{cases}<br>$$</p><p>（$i$和$j$都是从0开始）。重现该技巧的全网输出需要重复一层一层放大这个filter知道所有的下采样被移除。（在练习中，处理上采样输入的下采样版本可能会更高效。）</p><p>在网内减少二次采样是一种折衷的做法：filter能看到更细节的信息，但是接受域更小而且需要花费很长时间计算。Shift-and -stitch技巧是另外一种折衷做法：输出更加密集且没有减小filter的接受域范围，但是相对于原始的设计filter不能感受更精细的信息。</p><p>尽管我们已经利用这个技巧做了初步的实验，但是我们没有在我们的模型中使用它。正如在下一节中描述的，我们发现从上采样中学习更有效和高效，特别是接下来要描述的结合了跨层融合。</p><h3 id="3-3-上采样是向后向卷积"><a href="#3-3-上采样是向后向卷积" class="headerlink" title="3.3 上采样是向后向卷积"></a>3.3 上采样是向后向卷积</h3><p>另一种连接粗糙输出到dense像素的方法就是插值法。比如，简单的双线性插值计算每个输出$y_{ij}$来自只依赖输入和输出单元的相对位置的线性图最近的四个输入。</p><p>从某种意义上，伴随因子f的上采样是对步长为1/f的分数式输入的卷积操作。只要f是整数，一种自然的方法进行上采样就是向后卷积（有时称为去卷积）伴随输出步长为f。这样的操作实现是不重要的，因为它只是简单的调换了卷积的顺推法和逆推法。所以上采样在网内通过计算像素级别的损失的反向传播用于端到端的学习。</p><p>需要注意的是去卷积滤波在这种层面上不需要被固定不变（比如双线性上采样）但是可以被学习。一堆反褶积层和激励函数甚至能学习一种非线性上采样。在我们的实验中，我们发现在网内的上采样对于学习dense prediction是快速且有效的。我们最好的分割架构利用了这些层来学习上采样用以微调预测，见4.2节。</p><h3 id="3-4-patchwise训练是一种损失采样"><a href="#3-4-patchwise训练是一种损失采样" class="headerlink" title="3.4 patchwise训练是一种损失采样"></a>3.4 patchwise训练是一种损失采样</h3><p>在随机优化中，梯度计算是由训练分布支配的。patchwise 训练和全卷积训练能被用来产生任意分布，尽管他们相对的计算效率依赖于重叠域和minibatch的大小。在每一个由所有的单元接受域组成的批次在图像的损失之下（或图像的集合）整张图像的全卷积训练等同于patchwise训练。当这种方式比patches的均匀取样更加高效的同时，它减少了可能的批次数量。然而在一张图片中随机选择patches可能更容易被重新找到。限制基于它的空间位置随机取样子集产生的损失（或者可以说应用输入和输出之间的DropConnect mask）排除来自梯度计算的patches。</p><p>如果保存下来的patches依然有重要的重叠，全卷积计算依然将加速训练。如果梯度在多重逆推法中被积累，batches能包含几张图的patches。patcheswise训练中的采样能纠正分类失调 和减轻密集空间相关性的影响。在全卷积训练中，分类平衡也能通过给损失赋权重实现，对损失采样能被用来标识空间相关。</p><p>我们研究了4.3节中的伴有采样的训练，没有发现对于dense prediction它有更快或是更好的收敛效果。全图式训练是有效且高效的。</p><h2 id="4-分割架构"><a href="#4-分割架构" class="headerlink" title="4 分割架构"></a>4 分割架构</h2><p>我们将ILSVRC分类应用到FCNs增大它们用于dense prediction结合网内上采样和像素级损失。我们通过微调为分割进行训练。接下来我们增加了跨层来融合粗的、语义的和局部的表征信息。这种跨层式架构能学习端到端来改善输出的语义和空间预测。</p><p>为此，我们训练和在PASCAL VOC 2011分割挑战赛中验证。我们训练逐像素的多项式逻辑损失和验证标准度量的在集合中平均像素交集还有基于所有分类上的平均接收，包括背景。这个训练忽略了那些在groud truth中被遮盖的像素（模糊不清或者很难辨认）。<br><img src="https://img-blog.csdnimg.cn/20201216211241841.png#pic_center" alt="在这里插入图片描述"></p><h3 id="4-1-从分类到dense-FCN"><a href="#4-1-从分类到dense-FCN" class="headerlink" title="4.1 从分类到dense FCN"></a>4.1 从分类到dense FCN</h3><p>我们在第3节中以卷积证明分类架构的。我们认为拿下了ILSVRC12的AlexNet架构和VGG nets 、GoogLeNet一样在ILSVRC14上表现的格外好。我们选择VGG 16层的网络，发现它和19层的网络在这个任务（分类）上相当。对于GoogLeNet,我们仅仅使用的最后的损失层，通过丢弃了最后的平均池化层提高了表现能力。我们通过丢弃最后的分类切去每层网络头，然后将全连接层转化成卷积层。我们附加了一个$1\times1$的、通道维数为21的卷积来预测每个PASCAL分类（包括背景）的得分在每个粗糙的输出位置，后面紧跟一个去卷积层用来双线性上采样粗糙输出到像素密集输出如3.3.节中描述。表1将初步验证结果和每层的基础特性比较。我们发现最好的结果在以一个固定的学习速率得到（最少175个epochs)。</p><p>从分类到分割的微调对每层网络有一个合理的预测。甚至最坏的模型也能达到大约75%的良好表现。内设分割的VGG网络（FCN-VGG16）已经在val上平均IU 达到了56.0取得了最好的成绩，相比于52.6。在额外数据上的训练将FCN-VGG16提高到59.4，将FCN-AlexNet提高到48.0。尽管相同的分类准确率，我们的用GoogLeNet并不能和VGG16的分割结果相比较。<br><img src="https://img-blog.csdnimg.cn/20201216211600272.png#pic_center" alt="在这里插入图片描述"></p><h3 id="4-2-结合“是什么”和“在哪里”"><a href="#4-2-结合“是什么”和“在哪里”" class="headerlink" title="4.2 结合“是什么”和“在哪里”"></a>4.2 结合“是什么”和“在哪里”</h3><p>我们定义了一个新的全卷积网用于结合了特征层级的分割并提高了输出的空间精度，见图3。当全卷积分类能被微调用于分割如4.1节所示，甚至在标准度量上得分更高，它们的输出不是很粗糙（见图4）。最后预测层的32像素步长限制了上采样输入的细节的尺寸。</p><p>我们提出增加结合了最后预测层和有更细小步长的更低层的跨层信息，将一个线划拓扑结构转变成DAG(有向无环图)，并且边界将从更底层向前跳跃到更高（图3）。因为它们只能获取更少的像素点，更精细的尺寸预测应该需要更少的层，所以从更浅的网中将它们输出是有道理的。结合了精细层和粗糙层让模型能做出遵从全局结构的局部预测。与Koenderick 和an Doorn的jet类似，我们把这种非线性特征层称之为deep jet。</p><p>我们首先将输出步长分为一半，通过一个16像素步长层预测。我们增加了一个1*1的卷积层在pool4的顶部来产生附加的类别预测。我们将输出和预测融合在conv7（fc7的卷积化）的顶部以步长32计算，通过增加一个2×的上采样层和预测求和（见图3）。我们初始化这个2×上采样到双线性插值，但是允许参数能被学习，如3.3节所描述、最后，步长为16的预测被上采样回图像，我们把这种网结构称为FCN-16s。FCN-16s用来学习端到端，能被最后的参数初始化。这种新的、在pool4上生效的参数是初始化为0 的，所以这种网结构是以未变性的预测开始的。这种学习速率是以100倍的下降的。</p><p>学习这种跨层网络能在3.0平均IU的有效集合上提高到62.4。图4展示了在精细结构输出上的提高。我们将这种融合学习和仅仅从pool4层上学习进行比较，结果表现糟糕，而且仅仅降低了学习速率而没有增加跨层，导致了没有提高输出质量的没有显著提高表现。</p><p>我们继续融合pool3和一个融合了pool4和conv7的2×上采样预测，建立了FCN-8s的网络结构。在平均IU上我们获得了一个较小的附加提升到62.7，然后发现了一个在平滑度和输出细节上的轻微提高。这时我们的融合提高已经得到了一个衰减回馈，既在强调了大规模正确的IU度量的层面上，也在提升显著度上得到反映，如图4所示，所以即使是更低层我们也不需要继续融合。</p><p>其他方式精炼化减少池层的步长是最直接的一种得到精细预测的方法。然而这么做对我们的基于VGG16的网络带来问题。设置pool5的步长到1，要求我们的卷积fc6核大小为14*14来维持它的接收域大小。另外它们的计算代价，通过如此大的滤波器学习非常困难。我们尝试用更小的滤波器重建pool5之上的层，但是并没有得到有可比性的结果；一个可能的解释是ILSVRC在更上层的初始化时非常重要的。</p><p>另一种获得精细预测的方法就是利用3.2节中描述的shift-and-stitch技巧。在有限的实验中，我们发现从这种方法的提升速率比融合层的方法花费的代价更高。</p><p><img src="https://img-blog.csdnimg.cn/20201216211840841.png#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20201216211904944.png#pic_center" alt="在这里插入图片描述"></p><h3 id="4-3-实验框架"><a href="#4-3-实验框架" class="headerlink" title="4.3 实验框架"></a>4.3 实验框架</h3><p><strong>优化</strong> 我们利用momentum训练了GSD。我们利用了一个minibatch大小的20张图片，然后固定学习速率为$10^{-3},10^{-4}$，和$5^{-5}$用于FCN-AlexNet, FCN-VGG16,和FCN-GoogLeNet，通过各自的线性搜索选择。我们利用了0.9的momentum,权值衰减在$5^{-4}$或是$2^{-4}$，而且对于偏差的学习速率加倍了，尽管我们发现训练对单独的学习速率敏感。我们零初始化类的得分层，随机初始化既不能产生更好的表现也没有更快的收敛。Dropout被包含在用于原始分类的网络中。</p><p><strong>微调</strong> 我们通过反向传播微调整个网络的所有层。经过表2的比较，微调单独的输出分类表现只有全微调的70%。考虑到学习基础分类网络所需的时间，从scratch中训练不是可行的。（注意VGG网络的训练是阶段性的，当我们从全16层初始化后）。对于粗糙的FCN-32s，在单GPU上，微调要花费三天的时间，而且大约每隔一天就要更新到FCN-16s和FCN-8s版本。</p><p><img src="https://img-blog.csdnimg.cn/20201216211947750.png#pic_center" alt="在这里插入图片描述"></p><p><strong>patch取样</strong> 正如3.4节中解释的，我们的全图有效地训练每张图片batches到常规的、大的、重叠的patches网格。相反的，先前工作随机样本patches在一整个数据集，可能导致更高的方差batches，可能加速收敛。我们通过空间采样之前方式描述的损失研究这种折中，以1-p的概率做出独立选择来忽略每个最后层单元。为了避免改变有效的批次尺寸，我们同时以因子1/p增加每批次图像的数量。注意的是因为卷积的效率，在足够大的p值下，这种拒绝采样的形式依旧比patchwose训练要快（比如，根据3.1节的数量，最起码p&gt;0.2）图5展示了这种收敛的采样的效果。我们发现采样在收敛速率上没有很显著的效果相对于全图式训练，但是由于每个每个批次都需要大量的图像，很明显的需要花费更多的时间。 </p><p><strong>分类平衡</strong> 全卷积训练能通过按权重或对损失采样平衡类别。尽管我们的标签有轻微的不平衡（大约3/4是背景），我们发现类别平衡不是必要的。</p><p><strong>dense prediction</strong> 分数是通过网内的去卷积层上采样到输出维度。最后层去卷积滤波被固定为双线性插值，当中间采样层是被初始化为双线性上采样，然后学习。</p><p><strong>增强</strong> 扩大我们尝试通过随机反射扩大训练数据，”jettering”图像通过将它们在每个方向上转化成32像素（最粗糙预测的尺寸）。这并没有明显的改善。</p><p><strong>更多的训练数据</strong> PASCAL VOC 2011分割训练设置1112张图片的标签。Hariharan等人为一个更大的8498的PASCAL训练图片集合收集标签，被用于训练先前的先进系统,SDS。训练数据将FCV-VGG16得分提高了3.4个百分点到59.4。</p><p><strong>实现</strong> 所有的模型都是在单NVIDIA Tesla K40c上用Caffe训练和学习。</p><h2 id="5-结果"><a href="#5-结果" class="headerlink" title="5 结果"></a>5 结果</h2><p>我们训练FCN在语义分割和场景解析，研究了PASCAL VOC, NYUDv2和 SIFT Flow。尽管这些任务在以前主要是用在物体和区域上，我们都一律将它们视为像素预测。我们在这些数据集中都进行测试用来评估我们的FCN跨层式架构，然后对于NYUDv2将它扩展成一个多模型的输出，对于SIFT Flow则扩展成多任务的语义和集合标签。</p><p><strong>度量</strong> 我们从常见的语义分割和场景解析评估中提出四种度量，它们在像素准确率和在联合的区域交叉上是不同的。令$n_{ij}$为类别i的被预测为类别j的像素数量，有$n_{ij}$个不同的类别，令$t_i = \sum_j n_{ij}$<br>为类别i的像素总的数量。我们将计算：</p><ul><li><p>像素精度：$\sum_i n_{ii}/\sum_it_i$</p></li><li><p>平均准确度：$(1/n_{cl}) \sum_i n_{ii}/t_i$</p></li><li><p>平均交并比：$(1/n_{cl}) \sum_i n_{ii}/(t_i+\sum_j n_{ji}-n_{ii})$</p></li><li><p>频率加权交并比：$(\sum_k t_k)^{-1} \sum_i t_i n_{ii}/(t_i +\sum_j n_{ji}-n_{ii})$</p><p><strong>PASCAL VOC</strong> 表3给出了我们的FCN-8s的在PASCAL VOC2011和2012测试集上的表现，然后将它和之前的先进方法SDS和著名的R-CNN进行比较。我们在平均IU上取得了最好的结果相对提升了20%。推理时间被降低了114×（只有卷积网，没有proposals和微调)或者286×（全部都有）。<br><img src="https://img-blog.csdnimg.cn/20201216212656280.png#pic_center" alt="在这里插入图片描述"></p></li></ul><p><strong>NVUDv2</strong> 是一种通过利用Microsoft Kinect收集到的RGB-D数据集，含有已经被合并进Gupt等人的40类别的语义分割任务的pixelwise标签。我们报告结果基于标准分离的795张图片和654张测试图片。（注意：所有的模型选择将展示在PASCAL 2011 val上)。表4给出了我们模型在一些变化上的表现。首先我们在RGB图片上训练我们的未经修改的粗糙模型（FCN-32s）。为了添加深度信息，我们训练模型升级到能采用4通道RGB-Ds的输入（早期融合）。这提供了一点便利，也许是由于模型一直要传播有意义的梯度的困难。紧随Gupta等人的成功，我们尝试3维的HHA编码深度，只在这个信息上（即深度）训练网络，和RGB与HHA的“后期融合”一样来自这两个网络中的预测将在最后一层进行总结，结果的双流网络将进行端到端的学习。最后我们将这种后期融合网络升级到16步长的版本。</p><p><img src="https://img-blog.csdnimg.cn/20201216212737440.png#pic_center" alt="在这里插入图片描述"><br><strong>SIFT Flow</strong>是一个带有33语义范畴（“桥”、“山”、“太阳”）的像素标签的2688张图片的数据集和3个几何分类（“水平”、“垂直”和“sky”)一样。一个FCN能自然学习共同代表权，即能同时预测标签的两种类别。我们学习FCN-16s的一种双向版本结合语义和几何预测层和损失。这种学习模型在这两种任务上作为独立的训练模型表现很好，同时它的学习和推理基本上和每个独立的模型一样快。表5的结果显示，计算在标准分离的2488张训练图片和200张测试图片上计算，在这两个任务上都表现的极好。</p><h2 id="6-结论"><a href="#6-结论" class="headerlink" title="6 结论"></a>6 结论</h2><p>全卷积网络是模型非常重要的部分，是现代化分类网络中一个特殊的例子。认识到这个，将这些分类网络扩展到分割并通过多分辨率的层结合显著提高先进的技术，同时简化和加速学习和推理。<br><img src="https://img-blog.csdnimg.cn/20201216212912662.png#pic_center" alt="在这里插入图片描述"></p><p><img src="https://img-blog.csdnimg.cn/20201216212847238.png#pic_center" alt="在这里插入图片描述"><br><strong>鸣谢</strong> 这项工作有以下部分支持DARPA’s MSEE和SMISC项目，NSF awards IIS-1427425, IIS-1212798, IIS-1116411, 还有NSF GRFP,Toyota, 还有 Berkeley Vision和Learning Center。我们非常感谢NVIDIA捐赠的GPU。我们感谢Bharath Hariharan 和Saurabh Gupta的建议和数据集工具;我们感谢Sergio Guadarrama 重构了Caffe里的GoogLeNet;我们感谢Jitendra Malik的有帮助性评论;感谢Wei Liu指出了我们SIFT Flow平均IU计算上的一个问题和频率权重平均IU公式的错误。</p><h2 id="附录A-IU上界"><a href="#附录A-IU上界" class="headerlink" title="附录A IU上界"></a>附录A IU上界</h2><p>在这篇论文中，我们已经在平均IU分割度量上取到了很好的效果，即使是粗糙的语义预测。为了更好的理解这种度量还有关于这种方法的限制，我们在计算不同的规模上预测的表现的大致上界。我们通过下采样ground truth图像，然后再次对它们进行上采样，来模拟可以获得最好的结果，其伴随着特定的下采样因子。下表给出了不同下采样因子在PASCAL2011 val的一个子集上的平均IU。<img src="https://img-blog.csdnimg.cn/20201217104755582.png#pic_center" alt="在这里插入图片描述"></p><p>pixel-perfect预测很显然在取得最最好效果上不是必须的，而且，相反的，平均IU不是一个好的精细准确度的测量标准。</p><h2 id="附录B-更多的结果"><a href="#附录B-更多的结果" class="headerlink" title="附录B 更多的结果"></a>附录B 更多的结果</h2><p>我们将我们的FCN用于语义分割进行了更进一步的评估。PASCAL-Context提供了PASCAL VOC 2011的全部场景注释。有超过400中不同的类别，我们遵循了定义的被引用最频繁的59种类任务。我们分别训练和评估了训练集和val集。在表6中，我们将联合对象和Convolutional Feature Masking的stuff variation进行比较，后者是之前这项任务中最好的方法。FCN-8s在平均IU上得分为37.8，相对提高了20%<br><img src="https://img-blog.csdnimg.cn/20201216213043826.png#pic_center" alt="在这里插入图片描述"></p><h2 id="变更记录"><a href="#变更记录" class="headerlink" title="变更记录"></a>变更记录</h2><p>论文的arXiv版本保持着最新的修正和其他的相关材料，接下来给出一份简短的变更历史。v2 添加了附录A和附录B。修正了PASCAL的有效数量（之前一些val图像被包含在训练中），SIFT Flow平均IU（用的不是很规范的度量），还有频率权重平均IU公式的一个错误。添加了模型和更新时间数字来反映改进的实现的链接（公开可用的）。</p><hr><h1 id="二、论文解读"><a href="#二、论文解读" class="headerlink" title="二、论文解读"></a>二、论文解读</h1><p>图像分割的分类<br><img src="https://img-blog.csdnimg.cn/20201212193122672.png?#pic_center" alt="在这里插入图片描述"></p><ul><li><strong>image classification</strong> - 在已知类别数量的情况下，通过输入一张图片，来判断图片所属类别</li><li><strong>object localization</strong> - 判断图像中的目标具体在图像的什么位置，通常是以包围盒的(bounding box)形式进行定位</li><li><strong>semantic segmentation</strong> - 只标记语义, 也就是说分割出bottle、cube、cup类来</li><li><strong>instance segmentation</strong> - 标记实例和语义, 不仅要分割出cube这个类, 而且要分割出这个cube在哪, 也就是具体的实例</li></ul><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h2><p>FCN对图像进行像素级的分类，解决了语义级别的图像分割（semantic segmentation）问题。与经典的CNN在卷积层之后使用全连接层得到固定长度的特征向量进行分类（全连接层＋softmax输出）不同，FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的feature map进行上采样, 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类。<br><img src="https://img-blog.csdnimg.cn/20201211161656386.png#pic_center" alt="在这里插入图片描述"></p><center>上图是语义分割所采用的全卷积网络(FCN)的结构示意图</center><h2 id="2-Fully-Convolutional-networks-amp-Architecture"><a href="#2-Fully-Convolutional-networks-amp-Architecture" class="headerlink" title="2.Fully Convolutional networks &amp; Architecture"></a>2.Fully Convolutional networks &amp; Architecture</h2><p><strong>核心思想</strong></p><ul><li><p>不含全连接层(fc)的全卷积(fully conv)网络。可适应任意尺寸输入。 </p></li><li><p>增大数据尺寸的反卷积(deconv)层。能够输出精细的结果。 </p></li><li><p>结合不同深度层结果的跳级(skip)结构。同时确保鲁棒性和精确性。</p><h3 id="2-1-卷积化-convolutionalization"><a href="#2-1-卷积化-convolutionalization" class="headerlink" title="2.1 卷积化(convolutionalization)"></a>2.1 卷积化(convolutionalization)</h3><p>通常CNN网络在卷积层之后会接上若干个全连接层, 将卷积层产生的特征图(feature map)映射成一个固定长度的特征向量。以AlexNet为代表的经典CNN结构适合于图像级的分类和回归任务，因为它们最后都得到整个输入图像的一个概率向量，比如AlexNet的ImageNet模型输出一个1000维的向量表示输入图像属于每一类的概率(softmax归一化)。<br><img src="https://img-blog.csdnimg.cn/2020121021242429.jpg#pic_center" alt="在这里插入图片描述"><br>如图所示：</p></li><li><p>在CNN中, 猫的图片输入到AlexNet, 得到一个长为1000的输出向量, 表示输入图像属于每一类的概率, 其中在“tabby cat”这一类统计概率最高, 用来做分类任务。</p></li><li><p><strong>FCN与CNN的区别</strong>在于把于CNN最后的全连接层转换成卷积层，输出的是一张已经Label好的图片, 而这个图片就可以做语义分割。</p></li></ul><p>CNN的强大之处在于它的<strong>多层结构能自动学习特征，并且可以学习到多个层次的特征</strong>：</p><ul><li><p>较浅的卷积层感知域较小，学习到一些局部区域的特征</p></li><li><p>较深的卷积层具有较大的感知域，能够学习到更加抽象一些的特征</p></li></ul><blockquote><p>为什么CNN对像素级别的分类很难?</p></blockquote><ul><li><strong>存储开销很大</strong>。例如对每个像素使用的图像块的大小为15x15，然后不断滑动窗口，每次滑动的窗口给CNN进行判别分类，因此则所需的存储空间根据滑动窗口的次数和大小急剧上升。</li><li><strong>计算效率低下</strong>。相邻的像素块基本上是重复的，针对每个像素块逐个计算卷积，这种计算也有很大程度上的重复。</li><li><strong>像素块大小的限制了感知区域的大小</strong>。通常像素块的大小比整幅图像的大小小很多，只能提取一些局部的特征，从而导致分类的性能受到限制。<blockquote><p>下面我们看一下是如何将<strong>全连接层</strong>和<strong>全卷积层</strong>的相互转化:</p></blockquote></li></ul><p>全连接层和卷积层之间唯一的不同就是<strong>卷积层中的神经元只与输入数据中的一个局部区域连接，并且在卷积列中的神经元共享参数</strong>。然而在两类层中，神经元都是计算点积，所以它们的函数形式是一样的。因此，将此两者相互转化是可能的：</p><ul><li><p><strong>对于任一个卷积层，都存在一个能实现和它一样的前向传播函数的全连接层</strong>。权重矩阵是一个巨大的矩阵，除了某些特定块，其余部分都是零。而在其中大部分块中，元素都是相等的。</p></li><li><p><strong>任何全连接层都可以被转化为卷积层</strong>。比如VGG16中第一个全连接层是25088∗4096的数据尺寸，将它转化为512∗7∗7∗4096的数据尺寸，即一个K=4096的全连接层，输入数据体的尺寸是7∗7∗512，这个全连接层可以被等效地看做一个F=7,P=0,S=1,K=4096的卷积层。<strong>换句话说，就是将滤波器的尺寸设置为和输入数据体的尺寸一致</strong>7∗7, 这样输出就变为1∗1∗4096, 本质上和全连接层的输出是一样的。</p></li><li><p>输出激活数据体深度是由卷积核的数目决定的(<strong>K=4096</strong>)</p></li></ul><p>在两种变换中，将全连接层转化为卷积层在实际运用中更加有用。假设一个卷积神经网络的输入是227x227x3的图像，一系列的卷积层和下采样层将图像数据变为尺寸为<strong>7x7x512</strong>的激活数据体, AlexNet的处理方式为使用了两个尺寸为4096的全连接层，最后一个有1000个神经元的全连接层用于计算分类评分。我们可以将这3个全连接层中的任意一个转化为卷积层：</p><ul><li>第一个连接区域是[7x7x512]的全连接层，令其滤波器尺寸为F=7,K=4096，这样输出数据体就为[1x1x4096]</li><li>第二个全连接层，令其滤波器尺寸为F=1,K=4096，这样输出数据体为[1x1x4096]</li><li>最后一个全连接层也做类似的，令其F=1,K=1000，最终输出为[1x1x1000]</li></ul><blockquote><p>fcn的输入图片为什么可以是任意大小呢？</p></blockquote><p>首先，我们来看传统CNN为什么需要固定输入图片大小。</p><p>对于CNN，一幅输入图片在经过卷积和pooling层时，这些层是不关心图片大小的。比如对于一个卷积层，$outputsize=(inputsize−kernelsize)/stride+1$，它并不关心inputsize多大，对于一个inputsize大小的输入feature map，滑窗卷积，输出outputsize大小的feature map即可。pooling层同理。但是在进入全连接层时，feature map（假设大小为n×n）要拉成一条向量，而向量中每个元素（共n×n个）作为一个结点都要与下一个层的所有结点（假设4096个）全连接，这里的权值个数是$4096×n×n$，而我们知道神经网络结构一旦确定，它的权值个数都是固定的，所以这个n不能变化，n是conv5的outputsize，所以层层向回看，每个outputsize都要固定，那每个inputsize都要固定，因此输入图片大小要固定。</p><blockquote><p>把全连接层的权重W重塑成卷积层的滤波器有什么好处呢?</p></blockquote><p>这样的转化可以在单个向前传播的过程中, 使得卷积网络在一张更大的输入图片上滑动，从而得到多个输出(可以理解为一个label map)</p><p>比如: 我们想让224×224尺寸的浮窗，以步长为32在384×384的图片上滑动，把每个经停的位置都带入卷积网络，最后得到6×6个位置的类别得分, 那么通过将全连接层转化为卷积层之后的运算过程为:</p><p>如果224×224的输入图片经过卷积层和下采样层之后得到了[7x7x512]的数组，那么，384×384的大图片直接经过同样的卷积层和下采样层之后会得到[12x12x512]的数组, 然后再经过上面由3个全连接层转化得到的3个卷积层，最终得到[6x6x1000]的输出((12 – 7)/1 + 1 = 6), 这个结果正是浮窗在原图经停的6×6个位置的得分。</p><p><strong>一个确定的CNN网络结构之所以要固定输入图片大小，是因为全连接层权值数固定，而该权值数和feature map大小有关</strong>, 但是FCN在CNN的基础上把1000个结点的全连接层改为含有1000个1×1卷积核的卷积层，经过这一层，还是得到二维的feature map，同样我们也不关心这个feature map大小, 所以对于输入图片的size并没有限制。</p><p>如下图所示，FCN将传统CNN中的全连接层转化成卷积层，对应CNN网络FCN把最后三层全连接层转换成为三层卷积层 :<br><img src="https://img-blog.csdnimg.cn/20201211164945519.png#pic_center" alt="在这里插入图片描述"></p><ol><li>全连接层转化为全卷积层 :在传统的CNN结构中，前5层是卷积层，第6层和第7层分别是一个长度为4096的一维向量，第8层是长度为1000的一维向量，分别对应1000个不同类别的概率。FCN将这3层表示为卷积层，卷积核的大小(通道数，宽，高) 分别为(4096,1,1)、(4096,1,1)、(1000,1,1)。看上去数字上并没有什么差别，但是卷积跟全连接是不一样的概念和计算过程，使用的是之前CNN已经训练好的权值和偏置，但是不一样的在于权值和偏置是有自己的范围，属于自己的一个卷积核</li><li>CNN中输入的图像大小是统一固定成<strong>227x227</strong>大小的图像，第一层pooling后为<strong>55x55</strong>，第二层pooling后图像大小为<strong>27x27</strong>，第五层pooling后的图像大小为<strong>13x13</strong>,而FCN输入的图像是H*W大小，第一层pooling后变为原图大小的1/2，第二层变为原图大小的1/4，第五层变为原图大小的1/8，第八层变为原图大小的1/16。</li><li>经过多次卷积和pooling以后，得到的图像越来越小，分辨率越来越低。其中图像到$H/32∗W/32$的时候图片是最小的一层时，所产生图叫做<strong>heatmap热图</strong>，热图就是我们最重要的高维特征图，得到高维特征的heatmap之后就是最重要的一步也是最后的一步对原图像进行<strong>upsampling</strong>，把图像进行放大几次到原图像的大小。<br><img src="https://img-blog.csdnimg.cn/20201211165028906.png#pic_center" alt="在这里插入图片描述"></li></ol><p>相较于使用被转化前的原始卷积神经网络对所有36个位置进行迭代计算优化模型，然后再对36个位置做预测，使用转化后的卷积神经网络进行一次前向传播计算要高效得多，因为36次计算都在共享计算资源。这一技巧在实践中经常使用，通常将一张图像尺寸变得更大，然后使用变换后的卷积神经网络来对空间上很多不同位置进行评价得到分类评分，然后在求这些分值的平均值。</p><h3 id="2-2-上采样-Upsampling"><a href="#2-2-上采样-Upsampling" class="headerlink" title="2.2 上采样(Upsampling)"></a>2.2 上采样(Upsampling)</h3><p>Upsampling的操作可以看成是反卷积(deconvolutional)，卷积运算的参数和CNN的参数一样是在训练FCN模型的过程中通过bp算法学习得到。反卷积层也是卷积层，不关心input大小，滑窗卷积后输出output。deconv并不是真正的deconvolution（卷积的逆变换），最近比较公认的叫法应该是transposed convolution，deconv的前向传播就是conv的反向传播。</p><ul><li>反卷积参数: 利用卷积过程filter的转置（实际上就是水平和竖直方向上翻转filter）作为计算卷积前的特征图</li><li>反卷积学习率为0</li></ul><p><a href="https://buptldy.github.io/2016/09/25/2016-09-25-cnn_vis/" target="_blank" rel="noopener">Ways for Visualizing Convolutional Networks</a></p><p>反卷积的运算如下所示:<br><strong>蓝色是反卷积层的input，绿色是反卷积层的output</strong></p><ol><li><strong>Full padding, transposed</strong><br><img src="https://img-blog.csdnimg.cn/20201211165500571.gif#pic_center" alt="在这里插入图片描述"></li></ol><ul><li>上图中$kernelsize=3,stride=1,padding=2$的反卷积，input是2×2, output是4×4</li></ul><ol start="2"><li><strong>Zero padding, non-unit strides, transposed</strong></li></ol><p><img src="https://img-blog.csdnimg.cn/20201211165623297.gif#pic_center" alt="在这里插入图片描述"></p><ul><li>图中$kernelsize=3,stride=2,padding=1$的反卷积，input feature map是3×3, 转化后是5×5, output是5×5<blockquote><p>怎么使反卷积的output大小和输入图片大小一致，从而得到pixel level prediction?</p></blockquote></li></ul><p>FCN里面全部都是卷积层（pooling也看成卷积），卷积层不关心input的大小，inputsize和outputsize之间存在线性关系。<br>假设图片输入为[n×n]大小，第一个卷积层输出map就为$conv1_{out}.size=(n−kernelsize)/stride+1$, 记做$conv1_{out}.size=f(n)$, 依次类推，$conv5_{out}.size=f(conv5_{in}.size)=f(…f(n))$, 反卷积是要使$n=f^{\prime}(conv5_{out}.size)$成立，要确定$f^{\prime}$，就需要设置deconvolution层的kernelsize，stride，padding，计算方法如下：</p><figure class="highlight coffeescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">layer {</span><br><span class="line"> name: <span class="string">"upsample"</span>, type: <span class="string">"Deconvolution"</span></span><br><span class="line"> bottom: <span class="string">"{{bottom_name}}"</span> top: <span class="string">"{{top_name}}"</span></span><br><span class="line"> convolution_param {</span><br><span class="line"> kernel_size: {{<span class="number">2</span> * factor - factor % <span class="number">2</span>}} stride: {{factor}}</span><br><span class="line"> num_output: {{C}} group: {{C}}</span><br><span class="line"> pad: {{ceil((factor - <span class="number">1</span>) / <span class="number">2.</span>)}}</span><br><span class="line"> weight_filler: { type: <span class="string">"bilinear"</span> } bias_term: <span class="literal">false</span></span><br><span class="line"> }</span><br><span class="line"> param { lr_mult: <span class="number">0</span> decay_mult: <span class="number">0</span> }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><strong>factor</strong>是指反卷积之前的所有卷积pooling层的累积采样步长，卷积层使feature map变小，是因为stride，卷积操作造成的影响一般通过padding来消除，因此，累积采样步长factor就等于反卷积之前所有层的stride的乘积</p><h3 id="2-3-跳跃结构-Skip-Architecture"><a href="#2-3-跳跃结构-Skip-Architecture" class="headerlink" title="2.3 跳跃结构(Skip Architecture)"></a>2.3 跳跃结构(Skip Architecture)</h3><p>对CNN的结果做处理，得到了dense prediction，而作者在试验中发现，得到的分割结果比较粗糙，所以考虑加入更多前层的细节信息，也就是把倒数第几层的输出和最后的输出做一个fusion，实际上也就是加和：</p><p><img src="https://img-blog.csdnimg.cn/20201211170423957.png#pic_center" alt="在这里插入图片描述"><br>实验表明，这样的分割结果更细致更准确。在逐层fusion的过程中，做到第三行再往下，结果又会变差，所以作者做到这里就停了。</p><p>而不同的结构产生的结果对比如下:</p><p><img src="https://img-blog.csdnimg.cn/2020121021273060.png#pic_center" alt="在这里插入图片描述"></p><h2 id="3-model-training"><a href="#3-model-training" class="headerlink" title="3. model training"></a>3. model training</h2><ul><li><p>用AlexNet，VGG16或者GoogleNet训练好的模型做初始化，在这个基础上做fine-tuning，全部都fine-tuning，只需在末尾加上upsampling，参数的学习还是利用CNN本身的反向传播原理</p></li><li><p>采用whole image做训练，不进行patchwise sampling。实验证明直接用全图已经很effective and efficient</p></li><li><p>对class score的卷积层做全零初始化。随机初始化在性能和收敛上没有优势</p></li></ul><p><strong>FCN例子</strong>: 输入可为任意尺寸图像彩色图像；输出与输入尺寸相同，深度为：20类目标+背景=21，模型基于AlexNet</p><ul><li>蓝色：卷积层</li><li>绿色：Max Pooling层</li><li>黄色: 求和运算, 使用逐数据相加，把三个不同深度的预测结果进行融合：<strong>较浅的结果更为精细，较深的结果更为鲁棒</strong></li><li>灰色: 裁剪, 在融合之前，使用裁剪层统一两者大小, 最后裁剪成和输入相同尺寸输出</li><li>对于不同尺寸的输入图像，各层数据的尺寸（height，width）相应变化，深度（channel）不变</li></ul><p><img src="https://img-blog.csdnimg.cn/20201211170850429.png#pic_center" alt="在这里插入图片描述"></p><ul><li><p>全卷积层部分进行特征提取, 提取卷积层（3个蓝色层）的输出来作为预测21个类别的特征</p></li><li><p>图中虚线内是反卷积层的运算, 反卷积层（3个橙色层）可以把输入数据尺寸放大。和卷积层一样，升采样的具体参数经过训练确定</p></li></ul><ol><li>以经典的AlexNet分类网络为初始化。最后两级是全连接（红色），参数弃去不用<br><img src="https://img-blog.csdnimg.cn/20201211171123951.png#pic_center" alt="在这里插入图片描述"></li><li>从特征小图（16∗16∗4096）预测分割小图（16∗16∗21），之后直接升采样为大图。<br><img src="https://img-blog.csdnimg.cn/20201211171202448.png#pic_center" alt="在这里插入图片描述"></li></ol><ul><li>反卷积（橙色）的步长为32，这个网络称为FCN-32s</li></ul><ol start="3"><li>升采样分为两次完成（橙色×2）, 在第二次升采样前，把第4个pooling层（绿色）的预测结果（蓝色）融合进来。使用跳级结构提升精确性<br><img src="https://img-blog.csdnimg.cn/20201211171306283.png#pic_center" alt="在这里插入图片描述"></li></ol><ul><li>第二次反卷积步长为16，这个网络称为FCN-16s</li></ul><ol start="4"><li>升采样分为三次完成（橙色×3）, 进一步融合了第3个pooling层的预测结果<br><img src="https://img-blog.csdnimg.cn/20201211171358229.png#pic_center" alt="在这里插入图片描述"></li></ol><ul><li>第三次反卷积步长为8，记为FCN-8s。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FCN8s</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes)</span>:</span></span><br><span class="line">        super(FCN8s, self).__init__()</span><br><span class="line">        vgg = torchvision.models.vgg16()</span><br><span class="line"></span><br><span class="line">        features = list(vgg.features.children())</span><br><span class="line"></span><br><span class="line">        self.padd = nn.ZeroPad2d([<span class="number">100</span>,<span class="number">100</span>,<span class="number">100</span>,<span class="number">100</span>])</span><br><span class="line"></span><br><span class="line">        self.pool3 = nn.Sequential(*features[:<span class="number">17</span>])</span><br><span class="line">        self.pool4 = nn.Sequential(*features[<span class="number">17</span>:<span class="number">24</span>])</span><br><span class="line">        self.pool5 = nn.Sequential(*features[<span class="number">24</span>:])</span><br><span class="line"></span><br><span class="line">        self.pool3_conv1x1 = nn.Conv2d(<span class="number">256</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.pool4_conv1x1 = nn.Conv2d(<span class="number">512</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.output5 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">4096</span>, kernel_size=<span class="number">7</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Conv2d(<span class="number">4096</span>, <span class="number">4096</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Conv2d(<span class="number">4096</span>, num_classes, kernel_size=<span class="number">1</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.up_pool3_out = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=<span class="number">16</span>, stride=<span class="number">8</span>)</span><br><span class="line">        self.up_pool4_out = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.up_pool5_out = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        _,_, w, h = x.size()</span><br><span class="line"></span><br><span class="line">        x = self.padd(x)</span><br><span class="line">        pool3 = self.pool3(x)</span><br><span class="line">        pool4 = self.pool4(pool3)</span><br><span class="line">        pool5 = self.pool5(pool4)</span><br><span class="line"></span><br><span class="line">        output5 = self.up_pool5_out(self.output5(pool5))</span><br><span class="line"></span><br><span class="line">        pool4_out = self.pool4_conv1x1(<span class="number">0.01</span> * pool4)</span><br><span class="line">        output4 = self.up_pool4_out(pool4_out[:,:,<span class="number">5</span>:(<span class="number">5</span> + output5.size()[<span class="number">2</span>]) ,<span class="number">5</span>:(<span class="number">5</span> + output5.size()[<span class="number">3</span>])]+output5)</span><br><span class="line"></span><br><span class="line">        pool3_out = self.pool3_conv1x1(<span class="number">0.0001</span> * pool3)</span><br><span class="line">        output3 = self.up_pool3_out(pool3_out[:, :, <span class="number">9</span>:(<span class="number">9</span> + output4.size()[<span class="number">2</span>]), <span class="number">9</span>:(<span class="number">9</span> + output4.size()[<span class="number">3</span>])] + output4)</span><br><span class="line"></span><br><span class="line">        out = self.up_pool3_out(output3)</span><br><span class="line"></span><br><span class="line">        out = out[:, :, <span class="number">31</span>: (<span class="number">31</span> + h), <span class="number">31</span>: (<span class="number">31</span> + w)].contiguous()</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    model = FCN8s(num_classes=<span class="number">20</span>)</span><br><span class="line">    print(model)</span><br><span class="line"></span><br><span class="line">    input = torch.randn(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">    output = model(input)</span><br><span class="line">    print(output.shape)</span><br></pre></td></tr></tbody></table></figure><p><strong>其他参数</strong></p><ul><li>minibatch：20张图片</li><li>learning rate：0.001</li><li>初始化：分类网络之外的卷积层参数初始化为0</li><li>反卷积参数初始化为bilinear插值。最后一层反卷积固定位bilinear插值不做学习</li></ul><p>总体来说，本文的逻辑如下：</p><ul><li>想要精确预测每个像素的分割结果</li><li>必须经历从大到小，再从小到大的两个过程</li><li>在升采样过程中，分阶段增大比一步到位效果更好</li><li>在升采样的每个阶段，使用降采样对应层的特征进行辅助</li></ul><p><strong>缺点:</strong></p><ul><li><p>得到的结果还是不够精细。进行8倍上采样虽然比32倍的效果好了很多，但是上采样的结果还是比较模糊和平滑，对图像中的细节不敏感</p></li><li><p>对各个像素进行分类，没有充分考虑像素与像素之间的关系。忽略了在通常的基于像素分类的分割方法中使用的空间规整（spatial regularization）步骤，缺乏空间一致性。</p></li></ul><p>参考</p><ol><li><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html" target="_blank" rel="noopener">《Fully convolutional networks for semantic segmentation》</a></li><li><a href="https://www.cnblogs.com/xuanxufeng/p/6249834.html" target="_blank" rel="noopener">Fully Convolutional Networks for semantic Segmentation（深度学习经典论文翻译）</a></li><li><a href="https://www.cnblogs.com/gujianhan/p/6030639.html" target="_blank" rel="noopener">全卷积网络 FCN 详解</a></li><li><a href="https://blog.csdn.net/happyer88/article/details/47205839" target="_blank" rel="noopener">论文笔记《Fully Convolutional Networks for Semantic Segmentation》</a></li><li><a href="https://blog.csdn.net/taigw/article/details/51401448" target="_blank" rel="noopener">全卷积网络（FCN）与图像分割</a></li><li><a href="http://dgschwend.github.io/netscope/#/preset/fcn-16s" target="_blank" rel="noopener">FCN 16s</a></li><li><a href="https://github.com/shelhamer/fcn.berkeleyvision.org" target="_blank" rel="noopener">FCN模型和代码</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文翻译 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FCN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【图像分类—VGG】 Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
      <link href="/article/2.html"/>
      <url>/article/2.html</url>
      
        <content type="html"><![CDATA[<p>VGG对于Alexnet来说，改进并不是很大，主要改进就在于使用了小卷积核，网络是分段卷积网络，通过max pooling过度，同时网络更深更宽。分别在定位和分类问题中获得了第一和第二名。我们还表明，我们的方法很好地推广到了其他数据集上，在那里他们实现了最好的结果。</p><a id="more"></a><img width="600" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104427.png"><h1 id="一、论文翻译"><a href="#一、论文翻译" class="headerlink" title="一、论文翻译"></a>一、论文翻译</h1><blockquote><p>论文：<a href="https://arxiv.org/abs/1409.1556" target="_blank" rel="noopener">Very deep convolutional networks for large-scale image recognition</a></p></blockquote><blockquote><p>VGG对于Alexnet来说，改进并不是很大，主要改进就在于使用了小卷积核，网络是分段卷积网络，通过max pooling过度，同时网络更深更宽。分别在定位和分类问题中获得了第一和第二名。我们还表明，我们的方法很好地推广到了其他数据集上，在那里他们实现了最好的结果。</p></blockquote><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在这项工作中，我们研究了卷积网络的深度对大规模图像识别任务精度的影响。我们的主要贡献是使用非常小（3×3）卷积滤波器架构来对加深的网络进行全面评估，这也表明通过将卷积层加深到16-19层可以让结果得到显著的提高。这些发现是基于我们在2014年ImageNet挑战赛中所提交结果的基础之上的，我们的团队分别获得了定位赛和分类赛的第一名和第二名。我们还发现，我们的网络可以很好地适用于其他数据集，并可以取得最先进的(state-of-the-art)结果。我们已经公开了两个性能最佳的ConvNet模型，以便进一步研究在计算机视觉中的深度视觉表示。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>卷积神经网络（ConvNets）最近在大规模图像和视频识别领域取得了巨大成功(Krizhevsky et al., 2012; Zeiler &amp; Fergus, 2013; Sermanet et al., 2014; Simonyan &amp; Zisserman, 2014)，很大的功劳来自于大规模图像数据集如ImageNet(Deng et al., 2009)，以及高性能计算系统（如GPU或者大规模分布式集群）。特别是，ImageNet打过视觉识别挑战赛（ILSVRC）(Russakovsky et al., 2014)在深度视觉识别框架的发展中发挥了重要的作用，它已经成为了几代大规模图像分类系统的试验台，从高维度浅层特征编码(Perronnin et al., 2010) (the winner of ILSVRC-2011)到深度卷积神经网络(Krizhevsky et al., 2012) (the winner of ILSVRC-2012)。</p><p>随着ConvNets在计算机视觉领域变得越来越常见，许多人尝试着去改进Krizhevsky et al.(2012)提出的原始网络框架，以取得更好的准确率。例如，ILSVRC-2013 (Zeiler &amp; Fergus, 2013; Sermanet et al., 2014)的最佳结果使用了更小的接收窗口以及在第一层的更小的步长。另一种改进方案是在整个图像和多尺度的图像上作训练和测试(Sermanet et al., 2014; Howard, 2014)。在本文中，我们处理的是ConvNet架构设计中的另一个重要因素——网络深度。为此，我们修改了框架的其他参数，并通过添加更多的卷积层来稳定地增加网络的深度，由于在所有的层里面都使用了较小的卷积核（3×3），所以这也是可行的。</p><p>因此，我们提出了更精确的ConvNet架构，它不仅实现了ILSVRC分类和定位任务的最优结果，而且还适用于其他的图像识别数据集，甚至在用作相对简单的流水线时（比如，使用一个不需要微调的线性SVM进行分类的深度特征）可以实现卓越的性能。我们已经开源了两个性能最好的模型，以便于进一步研究。</p><p>本文的剩余部分安排如下。在第二节，我们会描述我们的卷积神经网络框架结构。图像分类的训练和评估细节会在第三节中介绍。在第四节中会将在ILSVRC分类任务的实验结果进行比较。</p><h2 id="2-卷积神经网络配置"><a href="#2-卷积神经网络配置" class="headerlink" title="2 卷积神经网络配置"></a>2 卷积神经网络配置</h2><p>为了度量在近似条件下卷积神经网络深度增加带来的改进，我们所有的卷积层配置都采用了同样的准则（受Ciresan et al. (2011) ; Krizhevsky et al. (2012) 启发）。在这一节中，我们首先会描述卷积神经网络配置的一般布局（2.1节），然后会详细介绍评估时采用的特定配置（2.2节）。再接着讨论我们的设计选择，并将其与第2.3节中的现有算法进行比较。</p><h3 id="2-1-结构"><a href="#2-1-结构" class="headerlink" title="2.1 结构"></a>2.1 结构</h3><p>在训练过程中，我们的ConvNets的输入是固定尺寸的$224\times224$的RGB图像。我们所做的唯一预处理操作是从每个像素中减去训练集中所有图像的RGB均值。图像经过了一层层的接受视野非常小且卷积核大小为$3\times3$的卷积层（这是捕获左/右、上/下、中心信息的最小尺寸）。在其中一种配置中，我们也使用了$1\times1$的卷积核，也可以看做是对输入通道的一个线性变换（随后是非线性变换）。卷积步长（stride）被固定为1个像素；对卷积层输入的空间填充（padding）会在卷积操作后仍然保留之前的空间分辨率，比如：对于卷积核为$3\times3$的卷积层padding为1个像素。空间池化（pooling）是由5个最大池化层完成，通常会放在一些卷积层之后（不是所有的卷积层之后都会接上最大池化层）。最大池化（Max-pooling）是在一个$2\times2$的像素窗口中执行，步长为2。</p><p>一堆卷积层（在不同的架构中有不同的深度）之后是三个全连接层（FC）：前两个各有4096个通道，第三个会进行1000种ILSVRC分类，因此有1000个通道（每个对应一个类）。最后一层是soft-max层。全连接层的配置在所有网络中都是相同的。</p><p>所有的隐含层都配套放置了一个非线性校正单元（ReLU (Krizhevsky et al., 2012)）。我们注意到我们的网络（除了一个之外）都没有包含局部响应归一化（LRN）(Krizhevsky et al., 2012)。在第四节中会说明，这种归一化并不会提高网络在ILSRVC数据集上的性能，却会导致内存的消耗以及计算时间的增加。在适用的情况下，LRN层的参数都是(Krizhevsky et al., 2012)的参数。</p><h3 id="2-2-配置"><a href="#2-2-配置" class="headerlink" title="2.2 配置"></a>2.2 配置</h3><p>本文中评估的卷积神经网络（ConvNet）的配置在表1中列出了，每列一个。下面我们将用他们的名2.字（A-E）来代指网络。所有的配置都遵循2.1节中所提到的方法设计，仅仅在网络的深度上有所不同：从网络A的11个权重层（8个卷积层和3个全连接层）到网络E的19个权重层（16个卷积层和3个全连接层）。卷积层的宽度（通道数）相对较小，从第一层的64开始，随后在每个最大池化层（max-pooling）后都会增加2倍，知道最后达到512。</p><p>在表2中，我们报告了没种配置的参数数量。尽管深度很大，我们的网络的权重参数数量并不多于网络更浅卷积层和感受视野更大的网络(144M weights in (Sermanet et al., 2014))的参数。</p><h3 id="2-3-讨论"><a href="#2-3-讨论" class="headerlink" title="2.3 讨论"></a>2.3 讨论</h3><p>我们的ConvNet配置与ILSVRC-2012 (Krizhevsky et al., 2012)和ILSVRC-2013比赛(Zeiler &amp; Fergus, 2013; Sermanet et al., 2014)的最佳参赛作品中所使用的配置截然不同。我们在整个网络中使用了非常小的$3\times3$感受野，并会对输入的每个像素都做卷积操作（步长stride为1），而不是在第一个卷积层中使用相对更大的感受野（比如，在(Krizhevsky et al., 2012)中采用$11\times11$的卷积核，步长为4；在(Zeiler &amp; Fergus, 2013; Sermanet et al., 2014)中采用7*7的卷积核，步长为2）。很容易看出堆叠两个$3\times3$的卷积层（之间没有空间池化）的有效感受野为$5\times5$；三个这种层堆叠在一起的有效感受野为$7\times7$.那么，我们通过将三个$3\times3$的而不是$7\times7$的卷积层堆在一起能得到什么？首先，我们合并了三个非线性校正层而不是单独一个，这样可以使得决策函数更有区别性。其次，我们减少了参数的数量：假设一个三层$3\times3$卷积层组成的卷积块的输入和输出都有C个通道，那么这个块有$3(3^2 C^2 )=27C^2$个权重参数；同时，一个单独的$7\times7$卷积层，有$7^2 C^2=49C^2$个参数，多出了81%的参数。这一步可以看做对$7\times7$卷积核实行正则化，强迫他们通过$3\times3$的滤波器进行分解（且在各层之间还额外加入了非线性）。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104804.png"><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104815.png"><p>$1\times1$卷积层的加入（表1中的网络C）是增加决策函数的非线性程度并且不影响卷积层的感受野的一种不错的方法。尽管在我们这个情况下，$1\times1$卷积本质上是对相同维度空间的一个线性映射（输入和输出的通道数相同），但是非线性校正函数又引入了额外的非线性。应该注意的是，$1\times1$卷积最近被用于Lin (2014) 等人提出的“网络的网络”架构中。</p><p>Ciresan等人 (2011)曾使用了较小的卷积核，但是他们的网络明显不如我们的深，并且他们没有在大规模ILSVRC数据集行作评估。Goodfellow (2014)等人将深度卷积神经网络（11层）用于街道号识别任务，其结果表明增加网络深度有助于提高性能。GoogLeNet (Szegedy et al., 2014)，是ILSVRC-2014分类任务中表现最好的一个入门框架，它的开发与我们的工作无关，但是有一点很类似：他们的网络也有很深的卷积神经网络（22层）和较小的卷积核（除了$3\times3$卷积核之外，他们还是用了$1\times1$和$5\times5$卷积核）。他们的网络拓扑结构比我们的要复杂得多，并且特征谱（feature map）的空间分别率在第一层就减少了很多，以减少总体的计算开销。如4.5节中的结果表明，我们的模型在但网络分类准确性上超过了Szegedy等人(2014)的结果。</p><h2 id="3-分类结构"><a href="#3-分类结构" class="headerlink" title="3. 分类结构"></a>3. 分类结构</h2><p>在之前的章节中，我们介绍了所提出的网络的配置细节。在本节中，我们将介绍ConvNet的训练和评估细节。</p><h3 id="3-1-训练"><a href="#3-1-训练" class="headerlink" title="3.1 训练"></a>3.1 训练</h3><p>ConvNet的训练过程基本上参考自Krizhevsky et al. (2012)（除了从多尺度的训练图像中抽取样本作为输入，后面会详细介绍）。也就是说，训练是通过使用带动量的小批量梯度下降法（基于反向传播算法(LeCun et al., 1989)）来优化多项式逻辑回归目标。匹配大小设置为256，动量设置为0.9。训练时，通过权重衰减（L2惩罚乘数设置为$5\times10^{−4}$）和给前两个全连接层添加dropout（dropout丢失率设置为0.5）来实现正则化。学习率最初设置为$10^{−2}$，随后如果验证集的准确率停止提升就减少10倍。总体来说，学习率减少了3次，并且训练会在370k次迭代之后（74个epoch）停止。我们猜想，尽管与(Krizhevsky et al., 2012)相比，我们的网络的参数量更多也更深，但是我们的网络达到收敛所需的迭代次数更少，因为(a)由跟深和更小的卷积层会带来隐式的正则化；(b)某些特定层的与初始化。</p><p>网络权重的初始化很重要，因为如果初始化的参数不好，由于深度网络中的梯度稳定性下降，可能会导致训练停滞。为了避免这个问题，我们首先从训练配置A（如表1所示）开始，这个网络配置足够浅，可以随机初始化参数进行训练。然后，当训练更深的网络结构时，我们使用网络A的参数来初始化前4个卷积层和最后三个全连接层（多出的中间层随机初始化）。我们没有减少预初始化层的学习率，允许他们在训练过程中改变。对于随机初始化（如适用），我们从具有0均值和$10^{−2}$方差的正太分布中随机采样权重。偏差初始化为0。值得注意的是，在提交论文后，我们发现可以通过使用Glorot &amp; Bengio (2010)的随机初始化方法在没有预训练的情况下初始化权重。</p><p>为了获得固定尺寸的224*224的输入图像，他们从重新缩放的训练图像中随机裁剪得到（每次SGD迭代每个图像进行一次裁剪）。为了进一步增强训练集，裁剪时，还引入了随机水平翻转与随机的RGB颜色偏移(Krizhevsky et al., 2012)。下面将介绍训练图像的缩放。</p><p><strong>训练图像尺寸</strong>。设S是各向同性重新调整的训练图像的最小一侧，从中ConvNet的输入图像会被裁剪（我们也称S为训练尺度）。虽然裁剪尺寸被固定为$224\times224$，但原则上S可以取任何不小于224的值：对于S=224，裁剪时会获取整幅图像作为统计数据，完全跨越训练图像的最小侧；对于S≥224，裁剪后将对应与图像的一小部分，包含一个小物体或物体的一部分。</p><p>我们考虑了两种设置训练尺度S的方法。第一个是固定S，其对应于单一尺度训练（注意，从样本裁剪区域的图像内容仍然可以表示多尺度图像数据）。在我们的实验中，我们评估了两个固定尺度的模型：S=256（已被广泛用于现有技术中(Krizhevsky et al., 2012; Zeiler &amp; Fergus, 2013; Sermanet et al., 2014))）和S=384。给定一个ConvNe的配置，我们首先使用S=256来进行训练。为了加速S=384时的网络的训练速度，它的参数使用S=256预训练得到的参数来进行初始化，并且我们也采用较小的初始学习率$10^{−3}$。</p><p>设置S的第二种方法就是多尺度训练，其中每个训练图像都是通过从一个特定范围$[S_{min},S_{max}]$（我们令$S_{min}=256$，$S_{max}=512$）随机采样S来单独调整。由于图像中的物体可能具有不同的大小，因此在训练时把这一点也考虑进去是有好处的。这也可以看做是缩放比例波动来增强训练集，这样单个模型就可以被训练为可以识别多个尺寸下的物体。出于考虑到速度的原因，我们通过对具有相同配置的单尺度模型的所有层进行微调来训练多尺度模型，并使用固定的S=384作预训练。</p><h3 id="3-2-测试"><a href="#3-2-测试" class="headerlink" title="3.2 测试"></a>3.2 测试</h3><p>在测试的时候，给定一个训练好的ConvNet和一个输入图像，它会以以下方式进行分类。首先，将其各向同性地重新缩放为预定义的最小图像尺寸，表示为Q（我们也将其称为测试尺度）。我们可以注意到，Q不一定等于训练尺寸S（如我们在第四节所示，对每个S使用几个不同的Q值可以提升性能）。然后，使用类似于(Sermanet et al., 2014)的方法，将重新缩放的测试图像密集地送入网络。也就是说，全连接层首先被转换为卷积层（第一个全连接层转为$7\times7$的卷积层，后面两个转换为$1\times1$卷积层）。然后将所得的全卷积网络应用于整个未裁剪的图像。其结果是一个类别评分谱，其通道数等于类别数，并且一个可变的空间分辨率取决于输入输入图像的大小。最后，为了获得图像的类别评分的固定大小的矢量，类别评分谱要是空间上平均的（sum-pooled）。我们还通过水平翻转图像来增加测试集；对原始和翻转的图像的soft-max输出进行平均以得到图像的最终分数。</p><p>由于全连接网络被应用于整个图像，因此不需要再测试时对其进行多次裁剪采样(Krizhevsky et al., 2012)，如果在每次分割都需要网络重新计算这无疑是很低效的。与此同时，使用大量的裁剪图像数据集，如Szegedy等人(2014)所做，可以提升准确率，因为与全卷积网络相比它可以更精细地对图像进行采样。此外，由于卷积的边界条件不同，多尺度切割评估与密集评估是互补的：当应用ConvNet于切割图像时，卷积特征谱使用0来填充，然而在密集评估的情况下，同一个切割图像的填充（padding）自然会出现很多来自图像相邻区域的部分（由于卷积和空间池化），这也大大增加了整个网络的感受野，因此可以捕获到更多的图像信息。尽管我们认为在实际应用中这种会增加计算时间的多尺度图像切割操作不见得能带来准确率的提升，但我们也对 每个尺度做了50次图像切割（$5\times5$的常规栅格和2种翻转）来评估我们的网络，总共在3个不同尺度下做了150次图像切割，这与Szegedy等人(2014)的4个不同尺度下的144次图像切割相当。</p><h3 id="3-3-实现细节"><a href="#3-3-实现细节" class="headerlink" title="3.3 实现细节"></a>3.3 实现细节</h3><p>我们的实现是基于开源的C++ Caffe工具箱(Jia, 2013)（2013年12月推出），但是包含有很多重要的改动，允许我们使用安装在单个系统的多块GPU对多尺度下的全尺寸图像（未分割）进行训练和评估（如上所述）。多GPU训练利用数据并行性，并且通过将每批训练图像分成几个GPU批次并在各个GPU上并行处理。在GPU计算完批梯度之后，对他们求平均来获得整个批次的梯度。梯度计算在GPU中是同步的，因此结果与在单个GPU上进行训练时完全相同。</p><p>尽管最近又有人提出了更加复杂的加速ConvNet的训练的方法(Krizhevsky, 2014)，它们针对网络的不用层采用并行的模型与数据，但是我们发现我们的概念更简单的方案（在有4块的GPU系统上），相比于使用单个GPU已经有了3.75倍的加速。在配备了四个NVIDIA Titan Black GPU的系统上，根据架构的不同，训练单个网络需要花费2-3周。</p><h2 id="4-分类实验"><a href="#4-分类实验" class="headerlink" title="4 分类实验"></a>4 分类实验</h2><p><strong>数据集</strong>。在这节中，我们将会给出前面所描述的ConvNet架构的在ILSVRC-2012数据集上的图像分类结果（用于ILSVRC 2012-2014挑战赛）。该数据集包含了1000个类别的图像，并且被分为三组：训练集（1.3M张图像）、验证集（50K张图像）和测试集（不带类标签的100K张图像）。我们使用两种方法来评估分类性能：top-1误差和top-5误差。前者是多分类误差，即错误分类图像的比例；后者是ILSVRC中使用的主要评估标准，并且按照图像的比例计算，以使gound-truth类别超出top-5预测的类别。</p><p>对于大多数汇演，我们将验证集作为测试集。当然也在测试集上进行了一些实验，并将其作为ILSVRC-2014竞赛(Russakovsky et al., 2014)的一个“VGG”参赛队伍的作品提交给了ILSVRC官方服务器。</p><h3 id="4-1-单尺度评估"><a href="#4-1-单尺度评估" class="headerlink" title="4.1 单尺度评估"></a>4.1 单尺度评估</h3><p>我们首先使用2.2节中所描述的网络架构在单一尺度上对独立的ConvNet模型进行评估。测试图像的尺寸如下：对于固定的S，Q=S；对于$S\in [S_{min},S_{max}]，Q=0.5(S_{min}+S_{max})$。结果在表3中给出。</p><p>首先，我们注意到使用局部响应归一化（A-LRN网络）相比于不带归一化层的模型A没有带来性能上的提升。因此我们没有在更深的架构（B-E）中采用归一化。</p><p>第二，我们观察到，随着ConvNet深度的增加分类误差也在减小：从模型A的11层到模型E的19层。很明显，尽管模型C（包含了3个$1\times1$卷积层）有跟模型D相同的深度，模型C的性能不如模型D（在整个网络中都是用$3\times3$卷积层）。这也说明，尽管额外的非线性层可以起到作用（模型C比模型B好），使用卷积滤波器来捕获有用的感受野也是很重要的（模型D比模型C好）。当网络的深度达到了19层，网络的错误率开始饱和，但是可能使用更深的模型也许更适合更大的数据集。我们还较浅的网络B与5个$5\times5$卷积层的网络（由模型B衍生而来，将其中的一对$3\times3$卷积层替换为了单独的$5\times5$卷积层，这样可以保证有如2.3节中所述的相同的感受野）。浅层网络的top-1误差测出来，比B网络的高出了7%，这也说明一个更深滤波器更小的网络比一个浅层滤波器较大的网络更好。</p><p>最后，在训练时尺度波动（$S\in [256;512]$），相比于使用固定尺度时（S=256或者S=512）可以带来相当显著的性功能提升，尽管在测试时仅仅使用单一尺度进行评估。这也证实通过尺度波动进行图像分割的确对获取多尺度图像数据很有用。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104827.png"><h3 id="4-2-多尺度评估"><a href="#4-2-多尺度评估" class="headerlink" title="4.2 多尺度评估"></a>4.2 多尺度评估</h3><p>前面已经在单尺度下对ConvNet模型进行了评估，我们现在对测试时的尺度波动的影响作评估。先将几个不同的尺寸缩放的测试图像送入模型（对应于不同的Q值），随后再多输出的类别结果进行平均。考虑到训练和测试的尺度差距过大会导致准确率的下降，使用固定的尺度S进行训练的模型，在评估时使用较接近训练时图像尺寸的三个尺寸的测试图像进行测试：$Q={S−32,S,S+32}$。与此同时，训练时的尺度波动也让网络能在测试时应用于更宽范围的尺度，因此在训练模型时$S\in [S_{min},S_{max}]$，评估时使用更大范围的尺寸$Q={S_{min},0.5(S_{min}+S_{max}),S_{max}}$。</p><p>实验结果如表4所示，说明在测试时的尺度波动可以带来更好的效果（相比于表3中的使用单一尺度评估相同模型的结果）。跟前面一样，最深的网络（网络D和网络E）表现最出色，并且使用尺度波动也比使用一个固定的尺度S效果更好。我们的最好的单网络表现在验证集上达到了24.8%/7.5%的top-1/top-5错误率（在表4中加粗表示）。在测试集上，网络E实现了7.3%的top-5错误率。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104833.png"><h3 id="4-3-多重裁剪评估"><a href="#4-3-多重裁剪评估" class="headerlink" title="4.3 多重裁剪评估"></a>4.3 多重裁剪评估</h3><p>在表5中，我们密集卷积神经网络和多重裁剪评估进行了比较（详细见3.2节）。我们还通过对他们的soft-max输出做平均评估了两种评估技术的互补性。可以看出来，使用多重裁剪比密集平复稍微好一点，并且两种方法实际上是互补的，因为他们两者结合后比他们自身的结果要好。根据以上结果，我们猜想这可能是卷积边界条件的不同处理方法造成的。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104855.png"><h3 id="4-4-卷积神经网络融合"><a href="#4-4-卷积神经网络融合" class="headerlink" title="4.4 卷积神经网络融合"></a>4.4 卷积神经网络融合</h3><p>至此，我们已经评估了独立ConvNet模型的结果。在实验的这一部分中，我们通过求取其soft-max输出的均值来结合几个不同模型的输出。由于模型之间的互补性，这能进一步提升模型的性能，这也分别在2012年(Krizhevsky et al., 2012)和2013年(Zeiler &amp; Fergus, 2013; Sermanet et al., 2014)被用于ILSVRC的最好结果之中。</p><p>结果在表6中。在提交ILSVRC参赛模型时，我们只是训练了单尺度网络，还有一个多尺度模型D（只对全连接层进行微调而不是所有层）。7个网络的组合结果在ILSVRC上最终达到了7.3%的测试错误率。在提交模型之后，我们又考虑了仅使用两个表现最好的多尺度模型（网络D和网络E），使用密集评估时将测试错误率降低到了7.0%，而使用密集和多重裁剪评估融合时测试错误率降到了6.8%。作为参考，我们的性能最好的单网络模型错误率为7.1%（模型E，见表5）。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104902.png"><p>最后，我们还会将我们的结果与当前最好的技术相比较，见表7。在ILSVRC-2014挑战赛(Russakovsky et al., 2014)的分类任务中，我们“VGG”队融合7个模型的结果得到7.3%的测试错误率取得了第2名的成绩。在提交之后，我们又使用两个模型融合的结果将错误率降低到6.8%。</p><p>从表7中可以看出，我们的很深的ConvNet明显超过了此前的其他模型，它们分别在ILSVRC-2012和ILSVRC-2013比赛中取得了最佳结果。我们的结果与分类任务的冠军(GoogLeNet，错误率为6.7%)相比还是很有竞争性的，并且大体上都消耗过了ILVRC-2013的优胜团队提交的模型Clarifai，在使用了外部数据的情况下达到了11.2%，没有使用外部数据的情况下达到了11.7%。值得注意的是，我们的最佳结果是通过融合两个模型实现的，很明显比大多数在ILSVRC提交的模型少得多。在单网络性能上，我们的架构实现了最好的结果（7.0%的测试错误率），超过了单独的GoogLeNet模型0.9%。还要注意到，我们没有偏离ConvNet的经典结构（LeCun et al. (1989)），而是大大增加了网络的深度。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104909.png"><h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a>5 结论</h2><p>　　在这次工作中我们评估了非常深的卷积神经网络（达到19层）用于大规模的图像分类。证明了深度有益于分类准确度，在ImageNet挑战数据集上的最先进的表现可以使用一个ConvNet架构（LeCun et al., 1989; Krizhevsky et al., 2012）加上深度的增加来实现。在附录中，我们还显示我们的模型适用于各种各样的任务的数据集，匹配或超过了构建在较深图像表示上的更复杂的管道。我们的结果再次证实了在视觉表示中深度的重要性。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><hr><h1 id="二、论文解读"><a href="#二、论文解读" class="headerlink" title="二、论文解读"></a>二、论文解读</h1><blockquote><p>部分内容转载自<a href="https://blog.csdn.net/zziahgf/article/details/79614822" target="_blank" rel="noopener">VGGNet 阅读理解 - Very Deep Convolutional Networks for Large-Scale Image Recognition</a></p></blockquote><p><strong>这篇文章是以比赛为目的——解决ImageNet中的1000类图像分类和 localization</strong>（这里需要注意 localization 和 detection 的区别. localization是找到某个物体的检测框，而detection是找到所有物体的检测框）</p><blockquote><p>GoogLeNet和VGG的Classification模型从原理上并没有与传统的CNN模型有太大不同。大家所用的Pipeline也都是：训练时候：各种数据Augmentation（剪裁，不同大小，调亮度，饱和度，对比度，偏色），剪裁送入CNN模型，Softmax，Backprop。测试时候：尽量把测试数据又各种Augmenting（剪裁，不同大小），把测试数据各种Augmenting后在训练的不同模型上的结果再继续Averaging出最后的结果.</p></blockquote><p>需要注意的是，在VGGNet的6组实验中，后面的几个网络使用了pre-trained model A的某些层来做参数初始化。这点上虽然作者没有提该方法带来的性能增益，但其实是很大的（我会在下文中优秀的特征提取器和泛化能力具体说明.）</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104916.png"><p>上图来自CS231n课程blog的tiny-vggnet模型架构，可以看到有三组卷积后接一个全连接层，每组卷积（blog里称为pattern）的形式都是一样的（conv-relu-conv-relu-pool），实际的VGG16（只算卷积和全连接层的个数是16）与上图略有不同（前两组conv-relu-conv-relu-pool，中间三组conv-relu-conv-relu-conv-relu-pool，最后三个fc，前两个fc是fc-relu-dropout，最后一个fc仅有fc。后文ConvNet<br>Configurations部分我会具体说明），<strong>不过整体来说作者也承认是继承了AlexNet和OverFeat</strong>：</p><ol><li><strong>继承了AlexNet不少网络结构</strong>（基于它加深层数和修改所有卷积核为3×3的小卷积），最后三个fc层基本算是平移AlexNet的到VGGNet上；</li><li><strong>继承了OverFeat在Localization任务中的做法</strong>（we adopt the approach of Sermanet et al. (2014)，没记错的话OverFeat拿了2013年Localization任务的第一名.）</li></ol><p>VGGNet的两个特点：层数更深更宽、卷积核更小. <strong>因为卷积核变小全部改用3×3大小（性能最好的两个网络：实验D（VGG16）和实验E（VGG19）），小卷积核的使用带来参数量减少，可以更加steadily地增加层数得同时不会太过于担心计算量的暴增</strong>.因为这篇文章正文写的是分类，附录介绍了VGGNet在localization上的工作，我也会对localization任务的解决进行分析.</p><p>这篇文章的主要特别的地方是前两点（换句话说，抄的不是很明显）：</p><ol><li><strong>卷积核变小</strong>。作者做的6组实验中，卷积核全部替换为3×3（极少用了1×1），选用更小卷积核的motivation是作者受到这两篇文章（Zeiler &amp; Fergus, 2013; Sermanet et al., 2014）启发，使用更小的卷积核尺寸和stride得到性能提升；</li><li><strong>层数更深更宽（11层、13层、16层、19层）</strong>。我认为作者是觉得：既然小卷积核带来性能提升，那么不妨试试深度对性能的影响，反正参数量我的gpu可以cover住。作者的实验也发现层数越深，带来的分类结果也越好，但并没有提到channel变宽这一个因素：6组实验中channel数都是逐层加宽的，如果单说深度对性能的影响而忽略宽度（这里宽度不是feature map的width而是depth），我觉得并不够convincing，应该再加入一下对宽度（channel）数分析对比的实验；</li><li><strong>池化核变小且为偶数</strong>。AlexNet中的max-pool全是3×3的，但VGGNet中都是2×2的。作者没有说明选择这种size的考量（现在stride=2、以及2×2和3×3的pooling<br>kernel选择的主流），我认为主要是2×2带来的信息损失相比3×3的比较小，相比3×3更容易捕获细小的特征变化起伏，此外或许是发现2×2的实验效果确实比3×3的好吧（毕竟这也是直接原因）；</li><li><strong>网络测试阶段将训练阶段的三个全连接替换为三个卷积</strong>。对于训练和测试一样的输入维度下，网络参数量没有变化，计算量也没有变化，思想来自OverFeat，1×1的卷积思想则来自NIN。优点在于全卷积网络可以接收任意尺度的输入（这个任意也是有前提的，长和宽都要满足：a×2n，n是卷积与池化做stride=2的下采样的次数）；</li><li>刷比赛的小技巧。其实没什么意思，比方输入图片的尺寸对于训练和测试阶段的处理方式不同，single和multi-scale的问题（具体见后文）。</li></ol><h2 id="1-任务背景"><a href="#1-任务背景" class="headerlink" title="1 任务背景"></a>1 任务背景</h2><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104923.png"><p>因为VGGNet在AlexNet之后，有必要先说一下问题的背景：自从AlexNet将深度学习的方法应用到图像分类取得state of the art的惊人结果后，大家都竞相效仿并在此基础上做了大量尝试和改进，先从两个性能提升的例子说起：</p><ol><li><strong>小卷积核</strong>。在第一个卷积层用了更小的卷积核和卷积stride（Zeiler &amp; Fergus, 2013; Sermanet et<br>al., 2014）；</li><li><strong>多尺度</strong>。训练和测试使用整张图的不同尺度（Sermanet et al., 2014; Howard, 2014）。</li></ol><h3 id="1-1-优秀的特征提取器和泛化能力"><a href="#1-1-优秀的特征提取器和泛化能力" class="headerlink" title="1.1 优秀的特征提取器和泛化能力"></a>1.1 优秀的特征提取器和泛化能力</h3><h4 id="1-1-1-特征提取器"><a href="#1-1-1-特征提取器" class="headerlink" title="1.1.1 特征提取器"></a>1.1.1 特征提取器</h4><p>另外，作者发现训练出的卷积网络是一个天然的且十分优秀的特征提取器（在不对卷积网络进行fine-tuning而直接在其后接一个SVM分类器并训练该SVM，最终结果也很好），而且特征提取器在其他数据集上具有通用性。说到这点不得不提到RCNN这篇文章，因为该作者将CNN作为一个特征提取器，主要流程是前三个步骤（第四个检测框回归也只是在附录写到，<a href="https://blog.csdn.net/zziahgf/article/details/79614822" target="_blank" rel="noopener">下图</a>是基于作者修改的图，略有不同）：<br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104929.png"></p><ol><li>（Supervised pre-training）用12年的分类数据去pre-train模型，CNN后接1k-way softmax</li><li>（Domain-specific fine-tuning）用当年20类检测数据集生成分类数据（根据检测数据通过selective search生成小图，然后计算IOU大于0.5视为该类图像），去fine-tune模型，CNN后接20-way softmax；</li><li>（Object category classifier）CNN参数固定，训练SVM。输入SVM的数据是CNN处理后的feature map，如果是20类那么对应20个，即分类20类的二分类SVM。其中对于某一类的SVM来说，正样本是proposal和ground-truth的框IOU大于0.3的（交叉验证得到的），其余视为负样本；</li><li>（Bounding-box regression）这里原图没有画出，其实在检测这里既有对proposal进行分类，再有对proposal的中心点和宽和高这四个值进行回归的过程，当然这个regressor的参数是训练拿到的。</li></ol><blockquote><p>什么是 IoU？<br>IoU （intersection-over-union）是用于评价目标检测（Object Detection）的评价函数，模型简单来讲就是模型产生的目标窗口和原来标记窗口的交叠率。即检测结果(DetectionResult)与 Ground Truth 的交集比上它们的并集，即为检测的准确率 IoU :<br>$$IoU = \frac{DR\cap GT}{DR \cup GT}$$<br>其中DR=Detection Result ，GT = Ground Truth。<br>或者写成如下的公式：<br><img width="200" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104935.png"><br>可以看到 IoU 的值越大，表明模型的准确度越好，IoU = 1 的时候 DR 与 GT 重合。</p></blockquote><p>在此过程中，RCNN作者预训练CNN，之后又用任务数据去fine-tune网络，最后把CNN作为特征提取器给SVM。同样展示了CNN的强大特征提取能力。说到这里不得不提pre-train和fine-tune。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104942.png"><p>VGGNet 6组实验中的后面几组中用到了pre-train后的A模型的部分层作为网络初始化的参数。上图是AlexNet作者在16年的深度学习暑期学校时候课上的一页PPT。可以看出三种针对不同数据量级而选择的训练策略。之前做过的几次Kaggle比赛中，使用pre-trained model 和 train-from-scratch 拿到的性能结果差距不小. Alex讲到，对于在ImageNet上训练过的pre-trained model，其参数可以用来初始化别的任务：</p><ul><li>数据量小的新任务。可以把前面的大部分层参数freeze，保留前面的卷积层和部分卷积层，以获取在ImageNet上得到的提取特征的能力，作为特征提取器，而只训练最后一层的全连接层。</li><li>数据量中等的新任务。则需要更多的可变的层来拟合新任务的数据，freeze前面的层，留出更多的层去拟合新数据。</li></ul><p>但实际来说，什么是小和大往往没有定量的描述，我觉得还是需要根据pretrain模型时的数据和新问题的数据之间的多样性复杂程度来评估，只是说，可finetune的层数越多，可以拟合新数据的分布的参数越多，这一个观点。但若是认真去解决问题且时间充裕，需要把所有可能都尝试到。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104947.png"><p>“<strong>浅层学到的是纹理特征，而深层学到的是语义特征</strong>”，这句话是从某篇博文看到的，我认为网络层数在特征提取这里，单从可视化的角度来讲，如果是线性模型对学出的权重矩阵进行可视化，那么得到的是对应各类别图像的轮廓，这是CS231n课程有讲到的。然而上图是对GoogLeNet这一网络的特征图可视化的结果，可以看到浅层学到的是边缘（Edges）、纹理（Texture）等，深层学到的是更偏向语义的信息，相当于把原本线性模型的feature map拉长了。本质还是那么多信息，只是中间的过程更加清晰可见，看上图中最后一组6张图中第一列放大的图，有建筑物的特征，而且颜色偏蓝，应该是训练数据中该类的图像大多有云朵和天空作为建筑物的背景。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318104956.png"><p>不过可以发现，无论网络深浅，最后一层（或几层）总是对应类别的轮廓，即语义信息。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105002.png"><p>根据优化的目标不同，得到的可视化结果不同，如DeepDream就是对feature<br>map的结果backprop回去更新输入图像进行可视化（该过程的流程如下图，该图来自zhihu的一篇博客见参考部分。关于可视化这里我没有仔细看，需要结合Feature<br>Visualization这篇文章、Google Blog上关于DeepDream的两篇文章以及风格迁移学习那篇文章再深入分析）。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105030.png"><h4 id="1-1-2-在其它数据集上的泛化性"><a href="#1-1-2-在其它数据集上的泛化性" class="headerlink" title="1.1.2 在其它数据集上的泛化性"></a>1.1.2 在其它数据集上的泛化性</h4><p>作者通过在ImageNet预训练得到的模型，在其他小数据（VOC-2007、VOC-2012、Caltech-101、Caltech-256等图像分类任务）上发现优秀的泛化性能（这部分来自本篇文章附录 Localization 的 Generation of Very Deep Features），作者说到使用pre-trained模型，再在自己的小数据上训练不容易过拟合，关于这点我的理解是：</p><ul><li>一开始在量级大且多样性广的数据集（如ImageNet）上pre-train，不严谨地说，新问题的小数据只是当初pre-train时所用数据集的一个子集，换句话说，pre-trained模型的参数已经避开了用小数据train-from-scratch的一些局部最优；</li></ul><ul><li>一开始在足够大的数据上pre-train，模型已经见识过了广阔的样本空间，这会带来了更广阔和丰富的特征空间，因而模型在小数据上学习时不会太过纠结于比较片面或者偏斜的样本带来的影响（还是类似第一点，初始化足够好）。</li></ul><p>总而言之：事半功倍，pre-trained模型用于fine-tune前已经趟（略，或者说exploit）过了很多坑（局部最优），因而效果好。另外，作者还使用不同尺度跑网络的方式提取到多组特征，对它们做平均的方法来表示最终给分类器的特征，这样相比将特征直接concate，不会导致最终特征太多（inflating，或者说是膨胀）。另外，作者发现使用multi-scale训练模型时，如果尺度范围比较小（256，384，512，640，768和256，384，512 两种 multi-scale相比）提升的性能比较有限（0.3%）。<br>$$<br>x_{i, j}^{\prime}=\frac{x_{i, j}}{\sqrt{\sum_{i=0}^{\text {height }-1} \sum_{j=0}^{\text {width }-1} x_{i, j}^{2}}}<br>$$</p><blockquote><p>图像中的 L1-normalize 与 L2-normalize<br>论文的附录部分也提到了图像的 L2-normalize，此 L2 并不是 CNN 中提到的用于解决过拟合的正则化方法，那么图像中的L2-normalize 有指呢？<br>L1及其 L2的计算公式如下：</p></blockquote><p>$$<br>L 1 \rightarrow x_{i, j}^{\prime}=\frac{x_{i, j}}{\sum_{i=0}^{h e i g h t-1} \sum_{j=0}^{w i d t h-1} x_{i, j}^{2}} \\<br>L 2 \rightarrow x_{i, j}^{\prime}=\frac{x_{i, j}}{\sqrt{\sum_{i=0}^{h e i g h t-1} \sum_{j=0}^{w i d t h-1} x_{i, j}^{2}}}<br>$$</p><p>其中$x_{i, j}^{\prime}$表示经过 L1或者 L2的值，H 表示图片的高（Height），W 表示宽（Width），$x_{i,j}$表示图像第 i行 j 列的像素值。如一个 3×3 的图像，使用 L1与 L2的结果如下图：</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105037.png"><p>作者在使用pre-trained模型的时候，是把用于喂给softmax前、产生1000维的最后一层全连接层去掉，使用倒数第二个全连接层产生聚合了位置和尺度的4096维图像特征，将这个特征做L2-normalization（上面公式便是图像上位于第 i 行 j 列的像素点$x^{\prime}<em>{i,j}$经过L2-norm后的像素值 $x^{\prime}</em>{i,j}$，需要注意的是这里是图像处理中 L2-normalize）后给SVM分类器训练 1VsALL 模型，提取特征的CNN没有做fine-tune操作。作者用倒数第二层的4096维的特征的考量是这个维度一定程度聚合了multiple location 和 scale 的信息，我觉得这个说法还是有些道理，一是网络有三个全连接层，经过1个或者2个全连接，原本的带有位置的局部信息被聚合起来了，但是 4096 维度的数目这个超参数还可以进一步使用交叉验证来优化，此外作者使用的是第二个fc后的特征，也不妨试试第一个fc后的特征、或者最后一个卷积的特征、甚至是将这些拼起来，说不定效果会更好。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105043.png"><p>此外，作者在对CNN提取到的特征做了聚合和一些变换，作者对4096维的resulting feature map（也就是刚做过l2-normalize过程的）再做global average pooling 产生一样维度的输出，并将与之镜像的图片也做同样的过程，最后将二者的特征加和求平均。当然全局平均池化（global average pooling，Network In Network有介绍该方法和dropout在作用上都起到正则作用，但有两个特点：1. 让feature map与类别通过softmax时的计算更自然，feature map也即对应类别的置信度分数；2. 无参数的策略，避免了过拟合问题。更多的参考上图NIN的截图）是一种聚合方法，作者也说到还可以使用stacking到一起，我想应该类似concate。</p><blockquote><p>什么是 全局池化（Global Average Pooling）<br>此概念首先在 NIN（Network In Network） 中提出。<br>首先，需要知道什么是全局池化（global pooling），它其实指的滑动窗口的大小与整个 feature map 的大小一样，这样一整张feature map 只产生一个值。比如一个 4×4 的 feature map 使用传统的池化方法（2×2 + 2s），那么最终产生的 feature map 大小为 2×2 ，如下图：<br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105049.png"><br>而如果使用全局池化的话（4×4 + 1s，大小与 feature map 相同），一个feature map 只产生一个值，即输出为 1×1，如下图：<br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105054.png"><br>如果前一层有多个feature map 的话，只需要把经过全局池化的结果堆叠起来即可，如下图：<br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105100.png"><br>上图，如果使用 Average 池化方法，那么就成为 Global Average Pooling，即 GAP。<br>从而可以总结出，如果输入 feature map 为 W×H×C，那么经过全局池化之后的输出就为 1×1×C。</p></blockquote><h2 id="2-卷积网络配置"><a href="#2-卷积网络配置" class="headerlink" title="2 卷积网络配置"></a>2 卷积网络配置</h2><h3 id="2-1-VGG结构"><a href="#2-1-VGG结构" class="headerlink" title="2.1 VGG结构"></a>2.1 VGG结构</h3><p>VGG的网络结构图<br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105105.png"><br>由上图所知，VGG一共有五段卷积，每段卷积之后紧接着最大池化层，作者一共实验了6种网络结构。分别是VGG-11，VGG-13,VGG-16,VGG-19，网络的输入是$224\times 224$大小的图像，输出是图像分类结果（本文只针对网络在图像分类任务上，图像定位任务上暂不做分析）</p><p>A-LRN 增加了 LRN 层，但在评估的时候可以看到 LRN （Local Response Normalisation）层并没有起到多大的作用，文章认为 LRN 并没有提升模型在 ILSVRC 数据集上的表现，反而增加了内存消耗和计算时间。</p><p>模型 C 和 D 的层数一样，但 C 层使用了 1×1 的卷积核，用于对输入的线性转换，增加非线性决策函数，而不影响卷积层的接受视野。后面的评估阶段也有证明，使用增加的 1×1 卷积核不如添加 3×3 的卷积核。</p><p>池化层的核数变小且为偶数，AlexNet 使用的是3×3 stride 为 2，VGG 为2×2 stride 也是 2 。CS231n 课程也提到现在使用 pooling 越来越少了，而是使用 stride 不等于 1 的卷积层来替代。</p><p>全连接层形式上完全平移AlexNet的最后三层，超参数上只有最后一层fc有变化：bias的初始值，由AlexNet的0变为0.1，该层初始化高斯分布的标准差，由AlexNet的0.01变为0.005。</p><blockquote><p>超参数的变化，我的理解是，作者自己的感性理解指导认为，我以贡献bias来降低标准差，相当于标准差和bias间trade-off，或许作者实验validate发现这个值比之前AlexNet设置的（std=0.01，bias=0）要更好</p></blockquote><p>输入大小为 224×224 RGB 三通道，输入只做了减去 RGB 均值的操作。</p><p>VGG16网络结构<br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105112.png"></p><ol><li>VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，5x5），ZFNet中的较大卷积核（7x7）。对于给定的感受野（与输出有关的输入图片的局部大小），<strong>采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层ReLU可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）</strong>。</li></ol><blockquote><ul><li>AlexNet虽然也有用3×3的卷积核，而且是大规模用，但基本上都是在网络的中后期。一开始却用了11×11这样的大卷积核，需要注意该卷积核对应的stride为4。我的理解是，一开始原图的尺寸虽然很大很冗余，但最为原始的纹理细节的特征变化一开始就用大卷积核尽早捕捉到比较好，后面的更深的层数害怕会丢失掉较大局部范围内的特征相关性，因为后面更多是3×3这样的小卷积核（和一个5×5卷积）</li><li>对于11×11的kernel size而言，中间有很大的重叠，计算出的3×3区域每个值很过于受到周边像素的影响，每个位置卷积的结果会更多考虑周边局部的像素点，原始的特征多少有被平滑掉的感觉。换句话说，局部信息因为过大的重叠，会造成更多细节信息的丢失。那大卷积核，是否带来更大的参数和feature map大小呢？我计算了同样conv3x3、conv5x5、conv7x7、conv9x9和conv11x11，在224x224x3的RGB图上（设置pad=1，stride=4，output_channel=96）做卷积，卷积层的参数规模和得到的feature map的大小：<img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105121.png"></li><li>看来大卷积核带来的参数量并不大（卷积核参数+卷积后的feature map参数，不同kernel大小这二者加和都是30万的参数量），即使考虑AlexNet中有两种形式的卷机组（[conv-relu]-lrn-pool和[conv-relu]-[conv-relu]-[conv-relu]-pool）。实际增大的是计算量（上面我列出了计算量的公式，最后要乘以2，代表乘加操作）。为了尽可能证一致，我这里所有卷积核使用的stride均为4，可以看到，conv3x3、conv5x5、conv7x7、conv9x9、conv11x11的计算规模依次为：1600万，4500万，1.4亿、2亿，这种规模下的卷积，虽然参数量增长不大，但是计算量是恐怖的。</li></ul></blockquote><ol start="2"><li>简单来说，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5x5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。<blockquote><p>使得网络容量更大（关于model capacity，AlexNet的作者认为可以用模型的深度和宽度来控制capacity），对于不同类别的区分能力更强（此外，从模型压缩角度也是要摒弃7×7，用更少的参数获得更深更宽的网络，也一定程度代表着模型容量，后人也认为更深更宽比矮胖的网络好）</p></blockquote></li></ol><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105128.png"><ol start="3"><li><strong>conv filter的参数减少</strong>。比如，3个步长为1的3x3卷积核的一层层叠加作用可看成一个大小为7的感受野（其实就表示3个3x3连续卷积相当于一个7x7卷积），其参数总量为$3\times 9\times C^2$，如果直接使用7x7卷积核，其参数总量为 $49\times C^2$ ，这里 C指的是输入和输出的通道数。很明显，$27\times C^2$小于$49\times C^2$，即减少了参数；而且3x3卷积核有利于更好地保持图像性质。</li></ol><h3 id="2-2-网络参数"><a href="#2-2-网络参数" class="headerlink" title="2.2 网络参数"></a>2.2 网络参数</h3><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105140.png"><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">INPUT: [224x224x3]        memory:  224*224*3=150K   weights: 0</span><br><span class="line">CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*3)*64 = 1,728</span><br><span class="line">CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*64)*64 = 36,864</span><br><span class="line">POOL2: [112x112x64]  memory:  112*112*64=800K   weights: 0</span><br><span class="line">CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*64)*128 = 73,728</span><br><span class="line">CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*128)*128 = 147,456</span><br><span class="line">POOL2: [56x56x128]  memory:  56*56*128=400K   weights: 0</span><br><span class="line">CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*128)*256 = 294,912</span><br><span class="line">CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824</span><br><span class="line">CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824</span><br><span class="line">POOL2: [28x28x256]  memory:  28*28*256=200K   weights: 0</span><br><span class="line">CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*256)*512 = 1,179,648</span><br><span class="line">CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296</span><br><span class="line">CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296</span><br><span class="line">POOL2: [14x14x512]  memory:  14*14*512=100K   weights: 0</span><br><span class="line">CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296</span><br><span class="line">CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296</span><br><span class="line">CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296</span><br><span class="line">POOL2: [7x7x512]  memory:  7*7*512=25K  weights: 0</span><br><span class="line">FC: [1x1x4096]  memory:  4096  weights: 7*7*512*4096 = 102,760,448</span><br><span class="line">FC: [1x1x4096]  memory:  4096  weights: 4096*4096 = 16,777,216</span><br><span class="line">FC: [1x1x1000]  memory:  1000 weights: 4096*1000 = 4,096,000</span><br><span class="line"></span><br><span class="line">TOTAL memory: 24M * 4 bytes ~= 93MB / image (only forward! ~*2 for bwd)</span><br><span class="line"><span class="selector-tag">TOTAL</span> <span class="selector-tag">params</span>: 138<span class="selector-tag">M</span> <span class="selector-tag">parameters</span></span><br></pre></td></tr></tbody></table></figure><h2 id="3-分类框架"><a href="#3-分类框架" class="headerlink" title="3 分类框架"></a>3 分类框架</h2><h3 id="3-1-训练阶段"><a href="#3-1-训练阶段" class="headerlink" title="3.1 训练阶段"></a>3.1 训练阶段</h3><p>VGG采用了带动量的最小批梯度下降算法（min-batch gradient descent with momentum）去优化优化多项式逻辑回归（multinomial logistic regression objective），参数如下：</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105148.png"><p>VGG 训练之所以可以收敛的比 AlexNet 快，是因为：</p><p>a)正则化+小卷积核，</p><p>b)特定层的预初始化</p><ol><li>正则化方法：</li></ol><ul><li><p>增加了对权重的正则化$5\times 10^{-4}||w||_{L^2}$</p></li><li><p>对FC层进行Dropout正则化，dropout ratio=0.5</p><p>  说明：虽然模型的参数和深度相比AlexNet有了很大的增加，但是模型的训练迭代次数却要求更少。</p></li></ul><ol start="2"><li>初始化策略：</li></ol><ul><li>首先，随机初始化网络结构A（A的深度较浅），利用A的网络参数，给其他的模型进行初始化（初始化前4层卷积+全连接层，其他的层采用正态分布随机初始化，$mean=0，var=10^{−2}, biases = 0$）</li><li>最后证明，即使随机初始化所有的层，模型也能训练的很好</li></ul><p><strong>训练输入</strong>：</p><ul><li><p>采用随机裁剪的方式，获取固定大小224x224的输入图像。并且采用了随机水平镜像和随机平移图像通道来丰富数据。</p></li><li><p>Training image size: 令S是各向同性重新缩放的训练图像的最小侧，从中截取ConvNet的输入（我们也将S称为训练尺度）。当裁剪尺寸固定为224x224时，原则上S可以取不小于224的任何值：对于S=224来说，裁剪将会捕获整个的图像统计数据，将会完整横跨训练图像的最小边。对于S ≫ 224，裁剪将会对应于图像的一小部分，包括一个小对象，或者对象的一部分。</p><p><strong>训练尺寸S</strong><br>我们考虑两种方法来设置训练尺寸S。</p></li></ul><ol><li>第一种就是固定S，这对应于单一尺寸的训练。固定：S = 256（Krizhevsky et al., 2012; Zeiler &amp; Fergus, 2013; Sermanet et al., 2014）和S = 384。给定ConvNet配置，我们首先使用S = 256训练网络。为了加速S=384网络的训练，使用S=256预训练的权重初始化训练，并且我们使用了较小的初始学习率$10^{-3}$。</li><li>第二种是多尺度训练，其中通过从某个范围[Smin, Smax]（设置Smin=256，Smax=512）随机采样S来单独地重新缩放每个训练图像。出于速度上的考虑，我们通过微调具有相同配置的单尺度模型的所有层来训练多尺度模型，用固定的S = 384来预训练。</li></ol><h3 id="3-2-测试阶段"><a href="#3-2-测试阶段" class="headerlink" title="3.2 测试阶段"></a>3.2 测试阶段</h3><p>首先将图片同质化的缩放（ isotropically rescaled）为预定义的最小图片边长，记做 Q。Q 不一定要和训练时的尺寸 S 相等。</p><p>作者将三个全连接层在此阶段，转成了1个7×7，和 2 个 1×1 的卷积层。从图2 VGG16结构图中就可以看到，以第一个全连接层为例，要转卷积层，FC6的输入是 7×7×512，输出是4096（也可以看做 1×1×4096），那么就要对输入在尺寸上（宽高）降维（从7×7 讲到 1×1）和深度（channel 或者 depth）升维（从512 升到4096）。把7×7降到1×1，使用大小为 7×7的卷积核就好了，卷积核个数设置为4096，即卷积核为7×7×4096（下图中的[7×7×512]×4096 表示有 4096 个 [7×7×512] 这样的卷积核，7×7×4096 是简写形式忽略了输入的深度），经过对输入卷积就得到了最终的 1×1×4096 大小的 feature map。经过转换的网络就没有了全连接层，这样网络就可以接受任意尺寸的输入，而不是像之前之能输入固定大小的输入。转化如下图：</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105155.png"><h2 id="4-分类实验-1"><a href="#4-分类实验-1" class="headerlink" title="4 分类实验"></a>4 分类实验</h2><p><strong>单一尺度评估</strong><br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105200.png"></p><p>结论：</p><ol><li>使用局部响应归一化（A-LRN网络）在没有任何归一化层的模型A上没有提升；</li><li>分类误差随着ConvNet的深度的增加而减小：从A中的11层到E中的19层；</li><li>训练时候的尺度抖动（S∈[256,512]）比在具有固定最小边（S=256或S=384）的图像上训练产生明显的更好的结果；</li></ol><p><strong>多尺度评估</strong><br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105206.png"></p><p>结论：</p><ol><li>结果表明测试时候的尺度抖动会导致更好的性能</li><li>尺度抖动的训练比用固定最小边S训练效果要好</li></ol><p><strong>多尺度裁剪</strong><br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105211.png"></p><p>结论：</p><ol><li>使用多种剪裁表现要略好于密集评估；</li><li>并且这两种方法确实是互补的，因为它们的结合优于他们中的每一种；<blockquote><p>在VGG网络中dense evaluation 与multi-crop evaluation<br><strong>两种预测方法的区别以及效果</strong><br>方法1: multi-crop，即对图像进行多样本的随机裁剪，然后通过网络预测每一个样本的结构，最终对所有结果平均;<br>方法2: densely， 利用FCN的思想，将原图直接送到网络进行预测，将最后的全连接层改为1x1的卷积，这样最后可以得出一个预测的score map，再对结果求平均;<br><strong>上述两种方法分析</strong><br>Szegedy et al.在2014年得出multi-crops相对于FCN效果要好;<br>multi-crops相当于对于dense evaluatio的补充，原因在于，两者在边界的处理方式不同：multi-crop相当于padding补充0值，而dense evaluation相当于padding补充了相邻的像素值，并且增大了感受野;<br>multi-crop存在重复计算带来的效率的问题;</p></blockquote></li></ol><p><strong>ConvNet融合</strong><br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105217.png"></p><p>结论：多种模型进行融合，效果更好</p><p><strong>与现有技术的比较</strong><br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210318105223.png"></p><p>结论：与其它模型相比，VGG效果也很好</p><h2 id="5-Pytorch实现"><a href="#5-Pytorch实现" class="headerlink" title="5 Pytorch实现"></a>5 Pytorch实现</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Conv3x3BNReLU</span><span class="params">(in_channels,out_channels)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>),</span><br><span class="line">        nn.BatchNorm2d(out_channels),</span><br><span class="line">        nn.ReLU6(inplace=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGGNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, block_nums,num_classes=<span class="number">1000</span>)</span>:</span></span><br><span class="line">        super(VGGNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.stage1 = self._make_layers(in_channels=<span class="number">3</span>, out_channels=<span class="number">64</span>, block_num=block_nums[<span class="number">0</span>])</span><br><span class="line">        self.stage2 = self._make_layers(in_channels=<span class="number">64</span>, out_channels=<span class="number">128</span>, block_num=block_nums[<span class="number">1</span>])</span><br><span class="line">        self.stage3 = self._make_layers(in_channels=<span class="number">128</span>, out_channels=<span class="number">256</span>, block_num=block_nums[<span class="number">2</span>])</span><br><span class="line">        self.stage4 = self._make_layers(in_channels=<span class="number">256</span>, out_channels=<span class="number">512</span>, block_num=block_nums[<span class="number">3</span>])</span><br><span class="line">        self.stage5 = self._make_layers(in_channels=<span class="number">512</span>, out_channels=<span class="number">512</span>, block_num=block_nums[<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Linear(in_features=<span class="number">512</span>*<span class="number">7</span>*<span class="number">7</span>,out_features=<span class="number">4096</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">4096</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(in_features=<span class="number">4096</span>, out_features=num_classes)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self._init_params()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_layers</span><span class="params">(self, in_channels, out_channels, block_num)</span>:</span></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(Conv3x3BNReLU(in_channels,out_channels))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,block_num):</span><br><span class="line">            layers.append(Conv3x3BNReLU(out_channels,out_channels))</span><br><span class="line">        layers.append(nn.MaxPool2d(kernel_size=<span class="number">2</span>,stride=<span class="number">2</span>, ceil_mode=<span class="literal">False</span>))</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_params</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> isinstance(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">'fan_out'</span>, nonlinearity=<span class="string">'relu'</span>)</span><br><span class="line">            <span class="keyword">elif</span> isinstance(m, nn.BatchNorm2d):</span><br><span class="line">                nn.init.constant_(m.weight, <span class="number">1</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.stage1(x)</span><br><span class="line">        x = self.stage2(x)</span><br><span class="line">        x = self.stage3(x)</span><br><span class="line">        x = self.stage4(x)</span><br><span class="line">        x = self.stage5(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>),<span class="number">-1</span>)</span><br><span class="line">        out = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">VGG16</span><span class="params">()</span>:</span></span><br><span class="line">    block_nums = [<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">    model = VGGNet(block_nums)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">VGG19</span><span class="params">()</span>:</span></span><br><span class="line">    block_nums = [<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]</span><br><span class="line">    model = VGGNet(block_nums)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    model = VGG16()</span><br><span class="line">    print(model)</span><br><span class="line"></span><br><span class="line">    input = torch.randn(<span class="number">1</span>,<span class="number">3</span>,<span class="number">224</span>,<span class="number">224</span>)</span><br><span class="line">    out = model(input)</span><br><span class="line">    print(out.shape)</span><br></pre></td></tr></tbody></table></figure><p>参考：</p><ol><li><a href="https://blog.csdn.net/wangsidadehao/article/details/54311282" target="_blank" rel="noopener">2014-VGG-《Very deep convolutional networks for large-scale image recognition》翻译</a></li><li><a href="https://arxiv.org/abs/1409.1556" target="_blank" rel="noopener">《Very Deep Convolutional Networks for Large-Scale Image Recognition》</a></li><li><a href="https://blog.csdn.net/qq_25737169/article/details/79084205" target="_blank" rel="noopener">VGG网络结构分析</a></li><li><a href="https://blog.csdn.net/amusi1994/article/details/81461968" target="_blank" rel="noopener">一文读懂VGG网络</a> </li><li><a href="https://cs231n.github.io/convolutional-networks/#case" target="_blank" rel="noopener">CS231n Convolutional Neural Networks for Visual Recognition</a></li><li><a href="https://zhuanlan.zhihu.com/p/42233779" target="_blank" rel="noopener">VGG 论文阅读记录</a></li><li><a href="http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf" target="_blank" rel="noopener">ILSVRC-2014 presentation</a></li><li><a href="http://machinethink.net/blog/convolutional-neural-networks-on-the-iphone-with-vggnet/" target="_blank" rel="noopener">Convolutional neural networks on the iPhone with VGGNet</a></li><li><a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf" target="_blank" rel="noopener">Lecture 9:CNN Architectures</a></li><li><a href="https://www.zhihu.com/question/53420266" target="_blank" rel="noopener">VGG网络中测试时为什么全链接改成卷积？ – 知乎</a> </li><li><a href="https://mlnotebook.github.io/post/CNN1/" target="_blank" rel="noopener">Convolutional Neural Networks - Basics</a></li><li><a href="https://blog.csdn.net/C_chuxin/article/details/82832229" target="_blank" rel="noopener">在VGG网络中dense evaluation 与multi-crop evaluation两种预测方法的区别以及效果</a></li><li><a href="https://stackoverflow.com/questions/42070528/what-does-global-pooling-do" target="_blank" rel="noopener">StackOverflow - What does global pooling do?</a></li><li><a href="https://distill.pub/2017/feature-visualization/" target="_blank" rel="noopener">Feature Visualization</a></li><li><a href="http://dgschwend.github.io/netscope/#/preset/vgg-16" target="_blank" rel="noopener">VGG ILSVRC 16 layers</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文翻译 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VGG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【图像分类—AlexNet】ImageNet Classification With Deep Convolutional Neural Networks</title>
      <link href="/article/1.html"/>
      <url>/article/1.html</url>
      
        <content type="html"><![CDATA[<p>在ImageNet LSVRC-2010 2012表现突出，top-1误差率37.5%，以及top-5误差率17.0%；网络有6000万个参数和650,000个神经元；网络结构五个卷积层，以及某些卷积层后的池化层，以及最后的三个全连接层；引入正则化方法dropout；引入ReLU修正线性单元。</p><a id="more"></a><img width="600" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317102132.png"><h1 id="一、论文翻译"><a href="#一、论文翻译" class="headerlink" title="一、论文翻译"></a>一、论文翻译</h1><blockquote><p>论文：<a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></p></blockquote><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>我们训练了一个庞大的深层卷积神经网络，将ImageNet LSVRC-2010比赛中的120万张高分辨率图像分为1000个不同的类别。在测试数据上，我们取得了37.5％和17.0％的前1和前5的错误率，这比以前的先进水平要好得多。具有6000万个参数和650,000个神经元的神经网络由五个卷积层组成，其中一些随后是最大池化层，三个全连接层以及最后的1000个softmax输出。为了加快训练速度，我们使用非饱和神经元和能高效进行卷积运算的GPU实现。为了减少全连接层中的过拟合，我们采用了最近开发的称为“dropout”的正则化方法，该方法证明是非常有效的。我们还在ILSVRC-2012比赛中使用了这种模式的一个变种，取得了15.3％的前五名测试失误率，而第二名的成绩是26.2％。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>目前，机器学习方法对物体识别非常重要。为了改善他们的表现，我们可以收集更大的数据集，训练更强大的模型，并使用更好的技术来防止过拟合。直到最近，标记好图像的数据集相对还较小——大约上万的数量级（例如，NORB，Caltech-101/256 和CIFAR-10/100）。使用这种规模的数据集可以很好地解决简单的识别任务，特别是如果他们增加了保留标签转换（label-preserving transformations）。例如，目前MNIST数字识别任务的最低错误率（&lt;0.3％）基本达到了人类的识别水平。但是物体在现实环境中可能表现出相当大的变化性，所以要学会识别它们，就必须使用更大的训练集。事实上，小图像数据集的缺点已是众所周知（例如，Pinto），但直到最近才可以收集到数百万的标记数据集。新的大型数据集包括LabelMe ，其中包含数十万个完全分割的图像，以及ImageNet，其中包含超过15,000万个超过22,000个类别的高分辨率图像。</p><p>要从数百万图像中学习数千个类别，我们需要一个具有强大学习能力的模型。然而，物体识别任务的巨大复杂性意味着即使是像ImageNet这样大的数据集也不能完美地解决这个问题，所以我们的模型也需要使用很多先验知识来弥补我们数据集不足的问题。卷积神经网络（CNN）就构成了一类这样的模型。它们的容量可以通过改变它们的深度和宽度来控制，并且它们也对图像的性质（即统计量的定态假设以及像素局部依赖性假设）做出准确而且全面的假设。因此，与具有相同大小的层的标准前馈神经网络相比，CNN具有更少的连接和参数，因此它们更容易训练，而其理论最优性能可能稍微弱一些。</p><p>尽管CNN具有很好的质量，并且尽管其局部结构的效率相对较高，但将它们大规模应用于高分辨率图像时仍然显得非常昂贵。幸运的是，当前的GPU可以用于高度优化的二维卷积，能够加速许多大型CNN的训练，并且最近的数据集（如ImageNet）包含足够多的标记样本来训练此类模型，而不会出现严重的过度拟合。</p><p>本文的具体贡献如下：我们在ILSVRC-2010和ILSVRC-2012比赛中使用的ImageNet子集上训练了迄今为止最大的卷积神经网络之一，并在这些数据集上取得了迄今为止最好的结果。我们编写了一个高度优化的2D卷积的GPU实现以及其他训练卷积神经网络的固有操作，并将其公开。我们的网络包含许多新的和不同寻常的功能，这些功能可以提高网络的性能并缩短训练时间，详情请参阅第3节。我们的网络规模较大，即使有120万个带标签的训练样本，仍然存在过拟合的问题，所以我们采用了几个有效的技巧来阻止过拟合，在第4节中有详细的描述。我们最终的网络包含五个卷积层和三个全连接层，并且这个深度似乎很重要：我们发现去除任何卷积层（每个卷积层只包含不超过整个模型参数的1%的参数）都会使网络的性能变差。</p><p>最后，网络的规模主要受限于目前GPU上可用的内存量以及我们可接受的训练时间。我们的网络需要在两块GTX 580 3GB GPU上花费五到六天的时间来训练。我们所有的实验都表明，通过等待更快的GPU和更大的数据集出现，我们的结果可以进一步完善。</p><h2 id="2-数据集"><a href="#2-数据集" class="headerlink" title="2 数据集"></a>2 数据集</h2><p>ImageNet是一个拥有超过1500万个已标记高分辨率图像的数据集，大概有22,000个类别。图像都是从网上收集，并使用Amazon-Mechanical Turk群智工具人工标记。从2010年起，作为Pascal视觉对象挑战赛的一部分，这是每年举办一次的名为ImageNet大型视觉识别挑战赛（ILSVRC）的比赛。 ILSVRC使用的是ImageNet的一个子集，每1000个类别中大约有1000个图像。总共有大约120万张训练图像，50,000张验证图像和150,000张测试图像。</p><p>ILSVRC-2010是ILSVRC中的唯一可以使用测试集标签的版本，因此这也正是我们进行大部分实验的版本。由于我们也在ILSVRC-2012比赛中引入了我们的模型，因此在第6部分中，我们也会给出此版本数据集的结果，尽管这个版本的测试集标签不可用。在ImageNet上，习惯上使用两种错误率：top-1和top-5，其中top-5错误率是正确标签不在被模型认为最可能的五个标签之中的测试图像的百分率。</p><p>ImageNet由可变分辨率的图像组成，而我们的系统需要固定的输入尺寸。因此，我们将图像下采样到256×256的固定分辨率。给定一个矩形图像，我们首先重新缩放图像，使得短边长度为256，然后从结果中裁剪出中心的256×256的图片。除了将每个像素中减去训练集的像素均值之外，我们没有以任何其他方式对图像进行预处理。所以我们在像素的（中心）原始RGB值上训练了我们的网络。</p><h2 id="3-结构"><a href="#3-结构" class="headerlink" title="3  结构"></a>3  结构</h2><p>图2概括了我们所提出网络的结构。它包含八个学习层——五个卷积层和三个全连接层。下面，我们将描述一些所提出网络框架中新颖或不寻常的地方。 3.1-3.4节按照我们对它们重要性的估计进行排序，其中最重要的是第一个。</p><h3 id="3-1-ReLU非线性单元"><a href="#3-1-ReLU非线性单元" class="headerlink" title="3.1 ReLU非线性单元"></a>3.1 ReLU非线性单元</h3><p>对一个神经元模型的输出的常规方法是，给他接上一个激活函数：$f(x)=tanh(x)$或者$f(x)=(1+e^{−x})^{−1}$。就梯度下降法的训练时间而言，这些饱和非线性函数比非饱和非线性函数如$f(x)=max(0,x)$慢得多。根据Nair和Hinton的说法，我们将这种非线性单元称为——修正非线性单元（Rectified Linear Units (ReLUs)）。使用ReLUs做为激活函数的卷积神经网络比起使用tanh单元作为激活函数的训练起来快了好几倍。这个结果从图1中可以看出来，该图展示了对于一个特定的四层CNN，CIFAR-10数据集训练中的误差率达到25%所需要的迭代次数。从这张图的结果可以看出，如果我们使用传统的饱和神经元模型来训练CNN，那么我们将无法为这项工作训练如此大型的神经网络。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317103052.png"><p>我们并不是第一个考虑在CNN中替换掉传统神经元模型的。例如，Jarrett等人表示，非线性函数$f(x)=|tanh(x)|$在他们的对比度归一化问题上，再接上局部均值池化单元，在Caltech-101数据集上表现的非常好。然而，在这个数据集中，主要担心的还是防止过拟合，所以他们观察到的效果与我们在使用ReLU时观察到的训练集的加速能力还是不一样。加快训练速度对大型数据集上训练的大型模型的性能有很大的影响。</p><h3 id="3-2-在多个GPU上训练"><a href="#3-2-在多个GPU上训练" class="headerlink" title="3.2 在多个GPU上训练"></a>3.2 在多个GPU上训练</h3><p>单个GTX 580 GPU只有3GB内存，这限制了可以在其上训练的网络的最大尺寸。事实证明，120万个训练样本足以训练那些因规模太大而不适合使用一个GPU训练的网络。因此，我们将网络分布在两个GPU上。目前的GPU很适合于跨GPU并行化操作，因为它们能够直接读写对方的内存，而无需通过主机内存。我们采用的并行化方案基本上将半个内核（或神经元）放在各个GPU上，另外还有一个技巧：GPU只在某些层间进行通信。这意味着，例如，第3层的内核从第2层的所有内核映射（kernel maps）中获取输入。然而，第4层中的内核又仅从位于同一GPU上的第3层中的那些内核映射获取输入。选择连接模式对于交叉验证是一个不小的问题，但这使得我们能够精确调整通信量，直到它的计算量的达到可接受的程度。</p><p>由此产生的架构有点类似于Cire¸san等人使用的“柱状”CNN，除了我们的每列不是独立的之外（见图2）。与一个GPU上训练的每个卷积层只有一半的内核数量的网络相比，该方案分别将我们的top-1和top-5错误率分别降低了1.7％和1.2％。双GPU网络的训练时间比单GPU网络更少。</p><h3 id="3-3-局部响应归一化"><a href="#3-3-局部响应归一化" class="headerlink" title="3.3 局部响应归一化"></a>3.3 局部响应归一化</h3><p>ReLU具有理想的属性，它们不需要对输入进行归一化来防止它们饱和。如果至少有一些训练实例为ReLU产生了正的输入，那么这个神经元就会学习。然而，我们还是发现下面的这种归一化方法有助于泛化。设$a^i_{x,y}$ 表示第$i$个内核计算$(x,y)$位置的ReLU非线性单元的输出，而响应归一化（Local Response Normalization）的输出值定义为$b^{i}_{x,y}$：</p><p>$$<br>b_{x, y}^{i}=a_{x, y}^{i} /\left(k+\alpha \sum_{j=\max (0, i-n / 2)}^{\min (N-1, i+n / 2)}\left(a_{x, y}^{j}\right)^{2}\right)^{\beta}<br>$$</p><p>其中，求和部分公式中的$n$表示同一个位置下与该位置相邻的内核映射的数量，而$N$表示这一层所有的内核数（即通道数）。内核映射的顺序当然是任意的，并且在训练之前就已经定好了。这种响应归一化实现了一种模仿真实神经元的横向抑制，从而在使用不同内核计算的神经元输出之间产生较大的竞争。常数 k、$n$、$α$和$β$都是超参数（hyper-parameters），它们的值都由验证集决定。我们取 $k=2$、$n=5$、 $α=10^{−4}$、$β=0.75$。我们在某些层的应用ReLU后再使用这种归一化方法（参见第3.5节）。</p><p>这个方案与Jarrett等人的局部对比归一化方案有些相似之处，但我们的被更准确地称为“亮度归一化”，因为我们没有减去均值。响应归一化将我们的top-1和top-5的错误率分别降低了1.4％和1.2％。我们还验证了这种方案在CIFAR-10数据集上的有效性：没有进行归一化的四层CNN实现了13％的测试错误率，而进行了归一化的则为11％。</p><h3 id="3-4-重叠池化"><a href="#3-4-重叠池化" class="headerlink" title="3.4 重叠池化"></a>3.4 重叠池化</h3><p>CNN中的池化层汇集了相同内核映射中相邻神经元组的输出。在传统方法中，相邻池化单元之间互不重叠。更准确地说，一个池化层可以被认为是由一些间隔为$s$个像素的池化单元组成的网格，每个都表示了一个以池化单元的位置为中心的大小为$z×z$的邻域。如果我们令$s = z$，我们就可以得到CNN中常用的传统的局部池化。如果我们令$s\le z$，则获得重叠池。 这就是我们在整个过程中使用的网络，其中$s = 2$和$z =3$。该方案将top-1和top-5的错误率分别降低了0.4％和0.3％，并且与非重叠方案$s = 2,z=2$相比，产生相同维度尺寸的输出。 我们通常会在训练期间观察到重叠的模型汇集发现它可以轻微防止过拟合。</p><h3 id="3-5-整体结构"><a href="#3-5-整体结构" class="headerlink" title="3.5 整体结构"></a>3.5 整体结构</h3><p>现在我们已经准备好描述CNN的整体架构了。如图2所示，这个网络包含了八层权重;前五个是卷积层，其余三个为全连接层。最后的全连接层的输出被送到1000维的softmax函数，其产生1000个类的预测。我们的网络最大化多项逻辑回归目标，这相当于在预测的分布下最大化训练样本中正确标签对数概率的平均值。</p><p>第二，第四和第五个卷积层的内核仅与上一层存放在同一GPU上的内核映射相连（见图2）。第三个卷积层的内核连接到第二层中的所有内核映射。全连接层中的神经元连接到前一层中的所有神经元。响应归一化层紧接着第一个和第二个卷积层。 在3.4节中介绍的最大池化层，后面连接响应归一化层以及第五个卷积层。将ReLU应用于每个卷积层和全连接层的输出。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317112956.png"><p>第一个卷积层的输入为224×224×3的图像，对其使用96个大小为11×11×3、步长为4（步长表示内核映射中相邻神经元感受野中心之间的距离）的内核来处理输入图像。第二个卷积层将第一个卷积层的输出（响应归一化以及池化）作为输入，并使用256个内核处理图像，每个内核大小为5×5×48。第三个、第四个和第五个卷积层彼此连接而中间没有任何池化或归一化层。第三个卷积层有384个内核，每个的大小为3×3×256，其输入为第二个卷积层的输出。第四个卷积层有384个内核，每个内核大小为3×3×192。第五个卷积层有256个内核，每个内核大小为3×3×192。全连接层各有4096个神经元。</p><h2 id="4-减少过拟合"><a href="#4-减少过拟合" class="headerlink" title="4 减少过拟合"></a>4 减少过拟合</h2><p>我们的神经网络架构拥有6000万个参数。尽管ILSVRC的1000个类别使得每个训练样本从图像到标签的映射被限制在了10 bit之内，但这不足以保证训练这么多参数而不出现过拟合。下面，我们将介绍对付过度拟合的两个方法。</p><h3 id="4-1-数据增强（Data-Augmentation）"><a href="#4-1-数据增强（Data-Augmentation）" class="headerlink" title="4.1 数据增强（Data Augmentation）"></a>4.1 数据增强（Data Augmentation）</h3><p>减小过拟合的最简单且最常用的方法就是，使用标签保留转换（label-preserving transformations），人为地放大数据集。我们采用两种不同形式的数据增强方法，它们都允许通过很少的计算就能从原始图像中生成转换图像，所以转换后的图像不需要存储在硬盘上。在我们实现过程中，转换后的图像是使用CPU上的Python代码生成的，在生成这些转换图像的同时，GPU还在训练上一批图像数据。所以这些数据增强方案实际上是很高效的。</p><p>数据增强的第一种形式包括平移图像和水平映射。我们通过从256×256图像中随机提取224×224的图像块（及其水平映射）并在这些提取的图像块上训练我们的网络来做到这一点。这使我们的训练集的规模增加了2048倍，尽管由此产生的训练样本当然还是高度相互依赖的。如果没有这个方案，我们的网络就可能会遭受大量的的过拟合，可能会迫使我们不得不使用更小的网络。在测试时，网络通过提取5个224×224的图像块（四个角块和中心块）以及它们的水平映射（因此总共包括10个块）来进行预测，并求网络的softmax层的上的十个预测结果的均值。</p><p>第二种形式的数据增强包括改变训练图像中RGB通道的灰度。具体而言，我们在整个ImageNet训练集的图像的RGB像素值上使用PCA。对于每个训练图像，我们添加多个通过PCA找到的主成分，大小与相应的特征值成比例，乘以一个随机值，该随机值属于均值为0、标准差为0.1的高斯分布。因此，对于每个图像的RGB像素有：<br>$I_{xy}=[I^R_{xy} \quad I^G_{xy} \quad I^B_{xy}]^T$，我们加入如下的值：</p><p>$$<br>[p_1\quad p_2 \quad p_3][\alpha_1\lambda_1 \quad \alpha_2\lambda_2 \quad \alpha_3\lambda_3]^T<br>$$</p><p>其中， $p_i$和 $\lambda_i$分别是3x3的RGB协方差矩阵的第$i$个特征向量和第$i$个的特征值，而 $\lambda_i$是前面所说的随机值。对于一张特定图像中的所有像素，每个$\lambda_i$只会被抽取一次，知道这张图片再次用于训练时，才会重新提取随机变量。这个方案近似地捕捉原始图像的一些重要属性，对象的身份不受光照的强度和颜色变化影响。这个方案将top-1错误率降低了1％以上。</p><h3 id="4-2-Dropout"><a href="#4-2-Dropout" class="headerlink" title="4.2 Dropout"></a>4.2 Dropout</h3><p>结合许多不同模型的预测结果是减少测试错误率的一种非常成功的方法，但对于已经花费数天时间训练的大型神经网络来说，它似乎成本太高了。然而，有一种非常有效的模型组合方法，在训练期间，只需要消耗1/2的参数。这个新发现的技术叫做“Dropout”，它会以50%的概率将隐含层的神经元输出置为0。以这种方法被置0的神经元不参与网络的前馈和反向传播。因此，每次给网络提供了输入后，神经网络都会采用一个不同的结构，但是这些结构都共享权重。这种技术减少了神经元的复杂适应性，因为神经元无法依赖于其他特定的神经元而存在。因此，它被迫学习更强大更鲁棒的功能，使得这些神经元可以与其他神经元的许多不同的随机子集结合使用。在测试时，我们试着使用了所有的神经元，并将它们的输出乘以0.5。这与采用大量dropout的网络产生的预测结果分布的几何均值近似。</p><p>我们在图2中的前两个全连接层上使用了dropout。没有dropout，我们的网络会出现严重的过拟合。Dropout大概会使达到收敛的迭代次数翻倍。</p><h2 id="5-训练细节"><a href="#5-训练细节" class="headerlink" title="5 训练细节"></a>5 训练细节</h2><p>我们使用随机梯度下降法来训练我们的模型，每个batch有128个样本，动量（momentum）为0.9，权重衰减（weight decay）为0.0005。我们发现这种较小的权重衰减对于模型的训练很重要。换句话说，权重衰减在这里不仅仅是一个正则化方法：它减少了模型的训练误差。权重$\omega$的更新法则是：<br><img src="https://cdn.mathpix.com/snip/images/gQxpuzTKfKARjiMdflOasFN65mOZhwl1Ml3_262opmo.original.fullsize.png" alt=""></p><p>其中，$i$表示当前的迭代次数，$v$表示动量（momentum），$\epsilon$表示学习率， $\left\langle\left.\frac{\partial L}{\partial w}\right|{w_i}\right\rangle_{D_{i}}$是目标函数关于$\omega$ 的偏导数$\omega_i$的第 $i$批次的$D_i$的平均值。</p><p>我们使用标准差为0.01、均值为0的高斯分布来初始化各层的权重。我们使用常数1来初始化了网络中的第二个、第四个和第五个卷积层以及全连接层中的隐含层中的所有偏置参数。这种初始化权重的方法通过向ReLU提供了正的输入，来加速前期的训练。我们使用常数0来初始化剩余层中的偏置参数。</p><p>我们对所有层都使用相同的学习率，在训练过程中又手动进行了调整。我们遵循的启发式方法是：以当前的学习速率训练，验证集上的错误率停止降低时，将学习速率除以10.学习率初始时设为0.01，并且在终止前减少3次。我们使用120万张图像的训练集对网络进行了大约90次迭代的训练，这在两块NVIDIA GTX 580 3GB GPU上花费了大约5到6天的时间。</p><h2 id="6-结果"><a href="#6-结果" class="headerlink" title="6 结果"></a>6 结果</h2><p>我们在ILSVRC-2010上取得的结果如表1所示。我们的网络的top-1和top-5测试集错误率分别为37.5％和17.0％。在ILSVRC-2010比赛期间取得的最佳成绩是47.1％和28.2％，其方法是对六种不同的稀疏编码模型所产生的预测结果求平均。此后公布的最佳结果为45.7％、25.7％，其方法是对两种经过密集采样的特征计算出来的Fisher向量（FV）训练的两个分类器取平均值。</p><p>我们的网络实现了37.5％和17.0％的前1和前5个测试集错误率5。在ILSVRC-2010比赛期间取得的最佳成绩是47.1％和28.2％，其中一种方法是对六种针对不同特征进行训练的稀疏编码模型所产生的预测进行平均，此后最佳公布结果为45.7％， 25.7％，其中一种方法是：对两个在不同取样密度的Fisher向量上训练的分类器取平均。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317113117.png"><p>我们还在ILSVRC-2012竞赛中使用了我们的模型，并在表2中给出了我们的结果。由于ILSVRC-2012测试集标签未公开，因此我们无法给出我们测试过的所有模型在测试集上的错误率。在本节的其余部分中，我们将验证集和测试集的错误率互换，因为根据我们的经验，它们之间的差值不超过0.1％（见表2）。本文描述的CNN的top-5错误率达到了18.2％。对五个相似CNN的预测结果计算均值，得到的错误率为16.4％。单独一个CNN，在最后一个池化层之后，额外添加第六个卷积层，对整个ImageNet Fall 2011 release(15M images, 22K categories)进行分类，然后在ILSVRC-2012上“微调”（fine-tuning）网络，得到的错误率为16.6％。对整个ImageNet Fall 2011版本的数据集下预训练的两个CNN，求他们输出的预测值与前面提到的5个不同的CNN输出的预测值的均值，得到的错误率为15.3％。比赛的第二名达到了26.2％的top-5错误率，他们的方法是：对几个在特征取样密度不同的Fisher向量上训练的分类器的预测结果取平均的方法。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317113202.png"><p>最后，我们还在ImageNet Fall 2009版本的数据集上提交了错误率，总共有10,184个类别和890万张图像。在这个数据集中，我们遵循文献中的使用一半图像用于训练，一半图像用于测试的惯例。由于没有建立测试集，所以我们的拆分方法有必要与先前作者使用的拆分方法不同，但这并不会对结果产生显著的影响。我们在这个数据集上的top-1和top-5错误率分别是67.4％和40.9％，是通过前面描述的网络获得的，但是在最后的池化层上还有额外的第6个卷积层。该数据集此前公布的最佳结果是78.1％和60.9％。</p><h3 id="6-1-定性评估"><a href="#6-1-定性评估" class="headerlink" title="6.1 定性评估"></a>6.1 定性评估</h3><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317113300.png"><p>图3显示了由网络的两个数据连接层学习得到的卷积内核。该网络已经学习到许多频率和方向提取的内核，以及各种色块。请注意两个GPU所展现的不同特性，这也是3.5节中介绍的限制互连的结果。GPU1上的内核在很大程度上与颜色无关，然而GPU2上的内核在很大程度上都于颜色有关。这种特异性在每次迭代期间都会发生，并且独立于任何特定的随机权重初始化过程（以GPU的重新编号为模）。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317113315.png"><p>在图4的左边，我们通过计算8张测试图像的top-5预测来定性评估网络的训练结果。请注意，即使是偏离中心的物体，如左上角的螨虫，也可以被网络识别出来。大多数top-5的标签都显得比较合理。例如，只有其他类型的猫才被认为是豹子的可能标签。在某些情况下（栅栏、樱桃），照片的关注点存在模糊性，不知道到底该关注哪个。</p><p>另一个研究可视化的网络的方法是，考虑由最后一个4096维隐含层中的图像的特征的激活函数输出值。如果两幅图像产生有的欧氏距离，我们可以认为高层次的神经网络认为它们是相似的。图4显示了测试集中的5个图像和来袭训练集的6个图像，这些图像根据这种度量方法来比较它们中的哪一个与其最相似。请注意，在像素层次上，待检测的训练图像通常不会与第一列中的查询图像有较小的L2距离。例如，检索到的狗和大象有各种不同的姿势。我们在补充材料中提供了更多测试图像的结果。<br>通过使用欧式距离来计算两个4096维实值向量的相似性，效率不高，但是通过训练自编码器可以将这些向量压缩为较短的二进制码，能够使其更高效。与应用自编码器到原始像素[14]相比，这应该是更好的图像检索方法。它不使用图像标签，因此更秦翔宇检索具有相似图案边缘的图像，不管它们的图像语义是否相似。</p><h2 id="7-讨论"><a href="#7-讨论" class="headerlink" title="7 讨论"></a>7 讨论</h2><p>我们的研究结果表明，一个大的深层卷积神经网络能够在纯粹使用监督学习的情况下，在极具挑战性的数据集上实现破纪录的结果。值得注意的是，如果移除任何一个卷积层，网络的性能就会下降。例如，删除任何中间层的结果会导致网络性能的top-1错误率下降2%。因此网络的深度对于实现我们的结果真的很重要。</p><p>为了简化我们的实验，我们没有使用任何无监督的预训练方法，尽管这样可能会有所帮助，特别是如果我们获得了足够的计算能力来显著地增加网络的大小而不会相应地增加已标记数据的数量。到目前为止，我们的结果已经获得了足够的进步，因为我们已经使网络更大，并且训练了更长时间。但我们仍然有很大的空间去优化网络，使之能够像人类的视觉系统一样感知。最后，我们希望对视频序列使用非常大的深度卷积神经网路，其中时间结构提供了非常有用的信息，这些信息往往在静态图像中丢失了，或者说不太明显。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><hr><h1 id="二、论文解读"><a href="#二、论文解读" class="headerlink" title="二、论文解读"></a>二、论文解读</h1><h2 id="1-卷积层"><a href="#1-卷积层" class="headerlink" title="1 卷积层"></a>1 卷积层</h2><h3 id="1-1-CNN中卷积层的作用"><a href="#1-1-CNN中卷积层的作用" class="headerlink" title="1.1 CNN中卷积层的作用"></a>1.1 CNN中卷积层的作用</h3><p>CNN中的卷积层，在很多网络结构中会用conv来表示，也就是convolution的缩写。卷积层在CNN中扮演着很重要的角色——特征的抽象和提取。在传统机器学习算法中，需要人为的指定特征是什么，而在卷积神经网络中，大部分特征提取的工作在卷积层自动完成了，越深越宽的卷积层一般来说就会有更好的表达能力。</p><h4 id="1-1-1-卷积层如何操作"><a href="#1-1-1-卷积层如何操作" class="headerlink" title="1.1.1 卷积层如何操作"></a>1.1.1 卷积层如何操作</h4><p>CNN中的卷积层操作与图像处理中的卷积是一样的，都是一个卷积核对图像做自上而下，自左而右的加权和操作。</p><ul><li><strong>卷积核的厚度=被卷积的图像的通道数</strong></li><li><strong>卷积核的个数=卷积操作后输出的通道数</strong></li></ul><p>例如：输入图像尺寸$5\times5\times3$（宽/高/通道数）,卷积核尺寸：$3\times3\times3$（宽/高/厚度），步长：1，边界填充：0，卷积核数量：1。用这样的一个卷积核去卷积图像中某一个位置后，是将该位置上宽3，高3，通道3上27个像素值分别乘以卷积核上27个对应位置的参数，得到一个数，依次滑动，得到卷积后的图像，这个图像的通道数为1（与卷积核个数相同），图像的高宽尺寸如下公式：</p><p>$$<br>\lfloor \frac{5-3+2\times0 }{1} \rfloor+1=3<br>$$</p><p>所以，卷积后的图像尺寸为：$3\times3\times1$（宽/高/通道数）。</p><h3 id="1-2-AlexNet中的卷积层"><a href="#1-2-AlexNet中的卷积层" class="headerlink" title="1.2 AlexNet中的卷积层"></a>1.2 AlexNet中的卷积层</h3><p>论文原文中的图：<br><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317113330.png"></p><p>输入层：$227\times227\times3$<br>C1：$96\times11\times11\times3$ （卷积核个数/宽/高/厚度）<br>C2：$256\times5\times5\times48$（卷积核个数/宽/高/厚度）<br>C3：$384\times3\times3\times256$（卷积核个数/宽/高/厚度）<br>C4：$384\times3\times3\times192$（卷积核个数/宽/高/厚度）<br>C5：$256\times3\times3\times192$（卷积核个数/宽/高/厚度）</p><p>细化的图:</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317113339.png"><h4 id="1-2-1-conv1层"><a href="#1-2-1-conv1层" class="headerlink" title="1.2.1 conv1层"></a>1.2.1 conv1层</h4><ol><li>输入Input的图像规格：$224\times 224\times3$（RGB图像）,实际上会经过预处理变为$227\times 227\times3$。</li><li>使用的96个大小规格为$11\times 11$的过滤器filter，或者称为<strong>卷积核，进行特征提取</strong>，（ps:图上之所以看起来是48个是由于采用了2个GPU服务器处理，每一个服务器上承担了48个）.需要特别提一下的是，原始图片为RBG图像，也就是三个通道的，我们这96个过滤器也是三通道的，也就是我们使用的实际大小规格为$11\times 11\times3$，也就是原始图像是彩色的，我们提取到的特征也是彩色的，在卷积的时候，我们会依据这个公式来提取特征图： $\lfloor \frac{(img_{size} - filter_{size})}{stride} \rfloor+1 = newfeature_{size}$，所以这里我们得到的特征图大小为：</li></ol><ul><li>$\lfloor (227-11) / 4 + 1= 55 \rfloor$ 注意$\lfloor \rfloor$表示向下取整. 我们得到的新的特征图规格为$55\times55$，注意这里提取到的特征图是彩色的.这样得到了96个$55\times55$大小的特征图了，并且是RGB通道的.</li></ul><ol start="3"><li><strong>使用RELU激励函数</strong>，来确保特征图的值范围在合理范围之内，比如{0,1}，{0,255}, 最后还有一个LRN处理。</li><li><strong>降采样处理</strong>（pool层也称为池化）</li><li>使用LRN，中文翻译为局部区域归一化,对降采样的特征图数据进行</li></ol><h4 id="1-2-2-conv2层"><a href="#1-2-2-conv2层" class="headerlink" title="1.2.2 conv2层"></a>1.2.2 conv2层</h4><ul><li>conv2和conv1不同，conv2中使用256个$5\times5$大小的过滤器filter对$96\times27\times27$个特征图，进行进一步提取特征，但是处理的方式和conv1不同，<strong>过滤器是对96个特征图中的某几个特征图中相应的区域乘以相应的权重，然后加上偏置之后所得到区域进行卷积</strong>,经过这样卷积之后，然后在宽度高度两边都<strong>填充2像素</strong>，会的到一个新的256个特征图.</li><li>特征图的大小为：$\lfloor \frac{27+2\times2 - 5}{1}  \rfloor+1 = 27$，也就是会有256个$27\times27$大小的特征图.然后进行ReLU操作.再进行降采样pool处理<br>得到： $\lfloor \frac{27-3}{2} \rfloor+1 = 13$  也就是得到256个$13\times13$大小的特征图.</li></ul><h4 id="1-2-3-conv3层"><a href="#1-2-3-conv3层" class="headerlink" title="1.2.3 conv3层"></a>1.2.3 conv3层</h4><ul><li>$\lfloor \frac{13 + 2\times  1 - 3}{1} \rfloor+1 = 13$  也就是得到384个$13\times13$大小的特征图.</li><li><strong>conv3没有使用降采样层.</strong></li></ul><h4 id="1-2-4-conv4-层"><a href="#1-2-4-conv4-层" class="headerlink" title="1.2.4 conv4 层"></a>1.2.4 conv4 层</h4><ul><li>$\lfloor \frac{13 + 2\times  1 - 3}{1} \rfloor+1 = 13$，384个$13\times13$特征图。</li><li><strong>conv4没有使用降采样层.</strong></li></ul><h4 id="1-2-5-conv5层"><a href="#1-2-5-conv5层" class="headerlink" title="1.2.5 conv5层"></a>1.2.5 conv5层</h4><ul><li><strong>conv5有降采样层pool,防止过拟合</strong></li><li>$\lfloor \frac{13 - 3}{2} \rfloor+1 = 6$，384个$6\times6$特征图。</li></ul><h2 id="2-全连接层"><a href="#2-全连接层" class="headerlink" title="2 全连接层"></a>2 全连接层</h2><h3 id="2-1-全连接层的作用"><a href="#2-1-全连接层的作用" class="headerlink" title="2.1 全连接层的作用"></a>2.1 全连接层的作用</h3><p>CNN中的全连接层与浅层神经网络中的作用是一样的，负责逻辑推断，所有的参数都需要学习得到。有一点区别在于第一层的全连接层用于链接卷积层的输出，它还有一个作用是去除空间信息（通道数），是一种将三维矩阵变成向量的过程（一种全卷积操作），其操作如下：</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317113353.png"><p>输入图像是 $W\times H \times C$，那么卷积核的尺寸为 $W\times H\times C$，这样的话整个输入图像就变成了一个数，一共有 $k$ 个数（第一层全连接层后的神经元个数），就有$k$个这样的 $W\times H\times C$ 的卷积核。</p><h3 id="2-2-AlexNet中的全连接层"><a href="#2-2-AlexNet中的全连接层" class="headerlink" title="2.2 AlexNet中的全连接层"></a>2.2 AlexNet中的全连接层</h3><p>AlexNet结构，R1，R2，R3就是全连接层。R2，R3很好理解，在这里主要说明下R1输入层：</p><ul><li>输入图像：$13\times13\times256$</li><li>卷积核尺寸：$13\times13\times256$， 个数 $2048\times2$</li><li>输出尺寸：4096（列向量）<br>从最开始的结构中可以看到，R1中也有通道的交互：<br>所以串接后的通道数是256，全卷积的卷积核尺寸也就是$13\times13\times256$，一个有4096个这样尺寸的卷积核分别对输入图像做4096次的全卷积操作，最后的结果就是一个列向量，一共有4096个数。</li></ul><h5 id="2-2-1-fc6层"><a href="#2-2-1-fc6层" class="headerlink" title="2.2.1 fc6层"></a>2.2.1 fc6层</h5><p>描述一下：</p><ul><li>这里使用4096个神经元，对256个大小为$6\times6$特征图，进行一个全连接，也就是将$6\times6$大小的特征图，进行卷积变为一个特征点,</li><li>然后对于4096个神经元中的一个点，是由256个特征图中某些个特征图卷积之后得到的特征点乘以相应的权重之后，再加上一个偏置得到。</li><li>再进行一个dropout随机从4096个节点中丢掉一些节点信息（也就是值清0），然后就得到新的4096个神经元。</li></ul><h5 id="2-2-2-fc7层"><a href="#2-2-2-fc7层" class="headerlink" title="2.2.2 fc7层"></a>2.2.2 fc7层</h5><p>和fc6类似.</p><h5 id="2-2-3-fc8层"><a href="#2-2-3-fc8层" class="headerlink" title="2.2.3 fc8层"></a>2.2.3 fc8层</h5><ul><li>采用的是1000个神经元，然后对fc7中4096个神经元进行全链接，然后会通过高斯过滤器，得到1000个float型的值，也就是我们所看到的预测的可能性,</li><li>如果是训练模型的话，会通过标签label进行对比误差，然后求解出残差，再通过链式求导法则，将残差通过求解偏导数逐步向上传递，并将权重进行推倒更改，类似与BP网络思虑，然后会逐层逐层的调整权重以及偏置.</li></ul><h3 id="3-其它层"><a href="#3-其它层" class="headerlink" title="3 其它层"></a>3 其它层</h3><p>严格上说池化层与卷积层不属于CNN中的单独的层，也不记入CNN的层数内，所以我们一般直说AlexNet一共8层，有5层卷积层与3层全连接层。但是在这里为了逻辑上清晰，就把他们单独拿出来说明下：</p><h4 id="3-1-池化层"><a href="#3-1-池化层" class="headerlink" title="3.1 池化层"></a>3.1 池化层</h4><p>池化操作（Pooling）用于卷积操作之后，其作用在于特征融合和降维，其实也是一种类似卷积的操作，只是池化层的所有参数都是超参数，都是不用学习得到的。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317113402.png"><p>上面这张图解释了最大池化（Max Pooling）的操作过程，核的尺寸为 $2\times2$，步长为2，最大池化的过程是将 $2\times2$ 尺寸内的所有像素值取最大值，作为输出通道的像素值。除了最大池化外，还有平均池化（Average Pooling），也就是将取最大改为取平均。一个输入为 $224\times224\times64$ 的图像，经过最大池化后的尺寸变为$112\times112\times64$，可以看到池化操作的降维改变的是图像的宽高，而不改变通道数。</p><h4 id="3-2-激活层"><a href="#3-2-激活层" class="headerlink" title="3.2 激活层"></a>3.2 激活层</h4><p>池化操作用于卷积层内，而激活操作则在卷积层和全连接层都会用到。<strong>激活函数在神经网络中的功能即通过对加权的输入进行非线性组合产生非线性决策边界（non-linear decision boundary）</strong>。使用的是ReLu(Rectified Linear Units)函数，主要是为了解决Sigmoid函数带来的梯度消失问题。</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317113410.png"><p><strong>在全连接层中</strong>的激活过程就很好理解了，因为全连接层内所有的神经元的输出都是一个数，只要这个数$x&gt;0$，则$x=x$；$x&lt;0$，则$x=0$。<br><strong>在卷积层中</strong>的激活针对的是每一个像素值，比如某卷积层输出中某个通道中$i$行$j$列像素值为$x$，只要这个数$x&gt;0$，则$x=x$；$x&lt;0$，则$x=0$。</p><h4 id="3-3-Softmax层"><a href="#3-3-Softmax层" class="headerlink" title="3.3 Softmax层"></a>3.3 Softmax层</h4><h5 id="3-3-1-Softmax作用"><a href="#3-3-1-Softmax作用" class="headerlink" title="3.3.1 Softmax作用"></a>3.3.1 Softmax作用</h5><p>Softmax层也不属于CNN中单独的层，一般要用CNN做分类的话，Softmax 是将神经元的输出变成概率的形式：</p><p>$$<br>\sigma (z_j)=\frac{e^z_j}{\sum^K_{k=1} e^{z_{k}}}, j=1, \cdots, K<br>$$</p><p>Softmax层所有的输出相加为1，即</p><p>$$<br>\sum^k_{j=0} \sigma(z)_j = 1<br>$$</p><p>而某一个输出的就是概率，最后我们按照这个概率的大小确定到底属于哪一类。</p><h5 id="3-3-2-AlexNet中的Softmax"><a href="#3-3-2-AlexNet中的Softmax" class="headerlink" title="3.3.2 AlexNet中的Softmax"></a>3.3.2 AlexNet中的Softmax</h5><p>AlexNet最后的分类数目为1000，也就是最后的输出为1000，输入为4096，中间通过R3链接，R3就是最后一层了，全连接的第3层，所有层数的第8层。</p><h3 id="4-AlexNet与在其之前的神经网络相比改进"><a href="#4-AlexNet与在其之前的神经网络相比改进" class="headerlink" title="4 AlexNet与在其之前的神经网络相比改进"></a>4 AlexNet与在其之前的神经网络相比改进</h3><ol><li><strong>数据增广（Data Augmentation）</strong><br>常用的数据增强的方法有 水平翻转、随机裁剪、平移变换、颜色、光照、对比度变换</li><li><strong>Dropout</strong><br>有效防止过拟合。</li><li><strong>Relu激活函数</strong><br>用ReLU代替了传统的Sigmoid或者tanh激活函数。</li><li><strong>Local Response Normalization 局部响应归一化</strong><br>参考了生物学上神经网络的侧抑制的功能，做了临近数据归一化，提高来模型的泛化能力，这一功能的作用有争议(VGG)。</li><li><strong>Overlapping Pooling 重叠池化</strong><br>重叠池化减少了系统的过拟合，减少了top-5和top-1错误率的0.4%和0.3%。</li><li><strong>多GPU并行训练</strong><br>AlexNet将网络分成了上下两部分，两部分的结构完全一致，这两部分由两块不同的GPU来训练，提高了训练速度。AlexNet大约有6000万个参数。</li></ol><h3 id="5-AlexNet-中60M参数"><a href="#5-AlexNet-中60M参数" class="headerlink" title="5 AlexNet 中60M参数"></a>5 AlexNet 中60M参数</h3><p>AlexNet只有8层，但是它需要学习的参数有60000000个，相比如他的层数，这是一个很可怕的数字了，我们来计算下这些参数都是怎么来的：</p><ul><li>C1：$96\times11\times11\times3$(卷积核个数/宽/高/厚度) 34848个</li><li>C2：$256\times5\times5\times48$（卷积核个数/宽/高/厚度） 307200个</li><li>C3：$384\times3\times3\times256$（卷积核个数/宽/高/厚度） 884736个</li><li>C4：$384\times3\times3\times192$（卷积核个数/宽/高/厚度） 663552个</li><li>C5：$256\times3\times3\times192$（卷积核个数/宽/高/厚度） 442368个</li><li>R1：$4096\times6\times6\times256$（卷积核个数/宽/高/厚度） 37748736个</li><li>R2：$4096\times4096$ 16777216个</li><li>R3：$4096\times1000$  4096000个</li></ul><p>在R1中卷积核尺寸是 $6\times6\times256$ 而不是$13\times13\times256$是因为经过了最大池化。可以看到，全连接层（尤其是第一层）参数数量占了绝大部分。</p><h3 id="6-Pytorch实现"><a href="#6-Pytorch实现" class="headerlink" title="6 Pytorch实现"></a>6 Pytorch实现</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlexNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,num_classes=<span class="number">1000</span>)</span>:</span></span><br><span class="line">        super(AlexNet,self).__init__()</span><br><span class="line">        self.feature_extraction = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">3</span>,out_channels=<span class="number">96</span>,kernel_size=<span class="number">11</span>,stride=<span class="number">4</span>,padding=<span class="number">2</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>,stride=<span class="number">2</span>,padding=<span class="number">0</span>),</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">96</span>,out_channels=<span class="number">192</span>,kernel_size=<span class="number">5</span>,stride=<span class="number">1</span>,padding=<span class="number">2</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>,stride=<span class="number">2</span>,padding=<span class="number">0</span>),</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">192</span>,out_channels=<span class="number">384</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">384</span>,out_channels=<span class="number">256</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">256</span>,out_channels=<span class="number">256</span>,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>),</span><br><span class="line">        )</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(in_features=<span class="number">256</span>*<span class="number">6</span>*<span class="number">6</span>,out_features=<span class="number">4096</span>),</span><br><span class="line">            nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">4096</span>),</span><br><span class="line">            nn.Linear(in_features=<span class="number">4096</span>, out_features=num_classes),</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        x = self.feature_extraction(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>),<span class="number">256</span>*<span class="number">6</span>*<span class="number">6</span>)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">'__main__'</span>:</span><br><span class="line">    model = AlexNet()</span><br><span class="line">    print(model)</span><br></pre></td></tr></tbody></table></figure><h3 id="7-CNN的发展"><a href="#7-CNN的发展" class="headerlink" title="7 CNN的发展"></a>7 CNN的发展</h3><p>在AlexNet问世之后，CNN以一个很快的速度发展，截止到2017年，已经有了多代的网络结构问世，深度、宽度上也越来越大，效率和正确率上也越来越好：</p><img width="300" height="300" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20210317113420.png"><p>AlexNet—NiN—VGG—GoogLeNet—ResNet, 在这些结构中：</p><ul><li>NiN 引入$1\times1$卷积层（Bottleneck layer）和全局池化；</li><li>VGG将$7\times7$替换成三个$3\times3$；</li><li>GoogLeNet引入了Inception模块；</li><li>ResNet引入了直连思想；</li><li>DenseNet引入稠密链接，将当前的层与之后的所有层直连。</li></ul><p>其中的一些网络甚至替换了AlexNet中提出的一些思想，但是CNN大体上结构依旧遵循着AlexNet，甚至还有很多传统ANN的思想存在。</p><ul><li>收敛速度：$VGG&gt;Inception&gt;DenseNet&gt;ResNET$</li><li>泛化能力：$Inception\approx DenseNet \approx ResNet &gt;VGG$</li><li>运算量：$Inception&lt;Densenet &lt; ResNet&lt;VGG$</li><li>内存开销：$Inception&lt;Resnet &lt; DenseNet&lt;VGG$</li></ul><p>参考</p><ol><li><a href="https://blog.csdn.net/hongbin_xu/article/details/80271291" target="_blank" rel="noopener">AlexNet论文(ImageNet Classification with Deep Convolutional Neural Networks)(译)</a></li><li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">《ImageNet Classification with Deep Convolutional Neural Networks》</a></li><li><a href="https://www.cnblogs.com/gongxijun/p/6027747.html" target="_blank" rel="noopener">神经网络模型之AlexNet的一些总结</a></li><li><a href="https://blog.csdn.net/chaipp0607/article/details/72847422" target="_blank" rel="noopener">从AlexNet理解卷积神经网络的一般结构</a></li><li><a href="http://dgschwend.github.io/netscope/#/preset/alexnet" target="_blank" rel="noopener">AlexNet</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 论文翻译 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AlexNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DES数据加密标准</title>
      <link href="/article/cdea.html"/>
      <url>/article/cdea.html</url>
      
        <content type="html"><![CDATA[<p>一种对称公私钥加密算法</p><a id="more"></a><h2 id="1-加密算法的分类"><a href="#1-加密算法的分类" class="headerlink" title="1 加密算法的分类"></a>1 加密算法的分类</h2><ol><li><p>对称加解密算法<br>（1）通信双方同时掌握一个密钥，加密解密都是由一个密钥完成的（即加密密钥等于解密密钥，加解密密钥可以相互推倒出来）。<br>（2）双方通信前共同拟定一个密钥，不对第三方公开。<br>（3）不具有个体原子性，一个密钥被共享，泄漏几率增大</p></li><li><p>公私钥加解密算法<br>通信双方掌握不同的密钥，不同方向的加解密由不同的密钥完成。</p></li></ol><h2 id="2-DES加密算法"><a href="#2-DES加密算法" class="headerlink" title="2 DES加密算法"></a>2 DES加密算法</h2><blockquote><p>Data Encryption Standard<br>DES加密算法主要是通过先对密钥进行加密，再将加密后的密钥放入明文中再次加密，得到密文。加密过程要用到很多表格，这些表格是固定的。下先介绍这些表格的转换方法，再分别介绍密钥和明文的加密步骤。</p></blockquote><h3 id="2-1-转换方法"><a href="#2-1-转换方法" class="headerlink" title="2.1 转换方法"></a>2.1 转换方法</h3><ol><li>交换表：以交换表1为例，找到第57位的数字，将第1位数字置换成第57位上的数字，奇偶校验位直接省去不需要转换，位数就会减少8位</li><li>位移（位移轮数表）：1位即左移1位，2位即左移2位</li><li>E盒（扩展表）：表内有16个数字重复了，即位数增加了16位</li><li>S盒：$8\ast6$变成$8\ast4$，即将第1位和第6位看作行，中间4位看做列，在 盒找到对应的数据，转换为二进制（4位）</li><li>P盒：直接置换，没有位数减少</li></ol><h3 id="2-2-对密钥K（64位）"><a href="#2-2-对密钥K（64位）" class="headerlink" title="2.2 对密钥K（64位）"></a>2.2 对密钥K（64位）</h3><ol><li><p>密钥（明文）由16个数字组成，二进制转换为64位，0123456789ABCDEF表示0到16，二进制表示为0000到1111</p></li><li><p>先用64位转56位的交换表1（$8\ast7$）,将$K$置换为<br>（56位），第8,16,24,32,40,48,56,64位（8的倍数）称为奇偶校验位，直接省去不需要转换，结果就只有56位了</p></li><li><p>再经过位移轮数表将$c_0d_0$变为$c_1d_1，\cdots，c_{16}d_{16}$（56位）</p></li><li><p>再用56位转48位的交换表2（$8\ast6$）,分别将$c_1d_1 \to k_1，\cdots，c_{16}d_{16} \to k_{16}$（48位），奇偶校验位是7的倍数</p></li></ol><p>交换表1：</p><figure class="highlight basic"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">57 </span> <span class="number">49</span>  <span class="number">41</span>  <span class="number">33</span>  <span class="number">25</span>  <span class="number">17</span>  <span class="number">9</span></span><br><span class="line"><span class="symbol">1 </span>  <span class="number">58</span>  <span class="number">50</span>  <span class="number">42</span>  <span class="number">34</span>  <span class="number">26</span>  <span class="number">18</span></span><br><span class="line"><span class="symbol">10 </span> <span class="number">2</span>   <span class="number">59</span>  <span class="number">51</span>  <span class="number">43</span>  <span class="number">35</span>  <span class="number">27</span></span><br><span class="line"><span class="symbol">19 </span> <span class="number">11</span>  <span class="number">3</span>   <span class="number">60</span>  <span class="number">52</span>  <span class="number">44</span>  <span class="number">36</span></span><br><span class="line"><span class="symbol">63 </span> <span class="number">55</span>  <span class="number">47</span>  <span class="number">39</span>  <span class="number">31</span>  <span class="number">23</span>  <span class="number">15</span></span><br><span class="line"><span class="symbol">7 </span>  <span class="number">62</span>  <span class="number">54</span>  <span class="number">46</span>  <span class="number">38</span>  <span class="number">30</span>  <span class="number">22</span></span><br><span class="line"><span class="symbol">14 </span> <span class="number">6</span>   <span class="number">61</span>  <span class="number">53</span>  <span class="number">45</span>  <span class="number">37</span>  <span class="number">29</span></span><br><span class="line"><span class="symbol">21 </span> <span class="number">13</span>  <span class="number">5</span>   <span class="number">28</span>  <span class="number">20</span>  <span class="number">12</span>  <span class="number">4</span></span><br></pre></td></tr></tbody></table></figure><p>位移轮数表：</p><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20200416214604.png"><p>交换表2：</p><figure class="highlight basic"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">14 </span> <span class="number">17</span>  <span class="number">11</span>  <span class="number">24</span>  <span class="number">1</span>   <span class="number">5</span></span><br><span class="line"><span class="symbol">3 </span>  <span class="number">28</span>  <span class="number">15</span>  <span class="number">6</span>   <span class="number">21</span>  <span class="number">10</span></span><br><span class="line"><span class="symbol">23 </span> <span class="number">19</span>  <span class="number">12</span>  <span class="number">4</span>   <span class="number">26</span>  <span class="number">8</span></span><br><span class="line"><span class="symbol">16 </span> <span class="number">7</span>   <span class="number">27</span>  <span class="number">20</span>  <span class="number">13</span>  <span class="number">2</span></span><br><span class="line"><span class="symbol">41 </span> <span class="number">52</span>  <span class="number">31</span>  <span class="number">37</span>  <span class="number">47</span>  <span class="number">55</span></span><br><span class="line"><span class="symbol">30 </span> <span class="number">40</span>  <span class="number">51</span>  <span class="number">45</span>  <span class="number">33</span>  <span class="number">48</span></span><br><span class="line"><span class="symbol">44 </span> <span class="number">49</span>  <span class="number">39</span>  <span class="number">56</span>  <span class="number">34</span>  <span class="number">53</span></span><br><span class="line"><span class="symbol">46 </span> <span class="number">42</span>  <span class="number">50</span>  <span class="number">36</span>  <span class="number">29</span>  <span class="number">32</span></span><br></pre></td></tr></tbody></table></figure><h3 id="2-3-对明文（64位）加密："><a href="#2-3-对明文（64位）加密：" class="headerlink" title="2.3 对明文（64位）加密："></a>2.3 对明文（64位）加密：</h3><ol><li>先根据交换表$IP（8\ast8$） 将$M$转换为$L_0R_0$(各32位)</li><li>计算出$L_{16}R_{16}$：$L_n=R_{\left(n-1\right)}，R_n=L_{(n-1)}\oplus P\left(S\left(E\left(R_{(n-1)}\oplus k_n\right)\right)\right)$<br>（1）利用$E$盒将32位的 扩展为48位的$R_{(n-1)}（1,\cdots 16）$<br>（2）$R_{(n-1)}$（48位）与$k_n$（48位）做异或运算$R_{(n-1)}\oplus k_n$，即$E\left(R_{(n-1)}\oplus k_n\right)$（48位）<br>（3）通过$S$盒将其转换为32位,即$S\left(E\left(R_{(n-1)}\oplus k_n\right)\right)$（32位）<br>（4）再经过$P$盒进行置换，即$P\left(S\left(E\left(R_{(n-1)}\oplus k_n\right)\right)\right)$（32位）<br>（5）再与$L_{n-1}$（32位）做异或运算得到$R_n$</li><li>再将$L_{16}R_{16}$转换为$R_{16}L_{16}$（64位）</li><li>最后用交换表$IP-1（8\ast8）$对$R_{16}L_{16}$进行置换得到密文<br>交换表$IP$：<figure class="highlight basic"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">58 </span> <span class="number">50</span>  <span class="number">42</span>  <span class="number">34</span>  <span class="number">26</span>  <span class="number">18</span>  <span class="number">10</span>  <span class="number">2</span></span><br><span class="line"><span class="symbol">60 </span> <span class="number">52</span>  <span class="number">44</span>  <span class="number">36</span>  <span class="number">28</span>  <span class="number">20</span>  <span class="number">12</span>  <span class="number">4</span></span><br><span class="line"><span class="symbol">62 </span> <span class="number">54</span>  <span class="number">46</span>  <span class="number">38</span>  <span class="number">30</span>  <span class="number">22</span>  <span class="number">14</span>  <span class="number">6</span></span><br><span class="line"><span class="symbol">64 </span> <span class="number">56</span>  <span class="number">48</span>  <span class="number">40</span>  <span class="number">32</span>  <span class="number">24</span>  <span class="number">16</span>  <span class="number">8</span></span><br><span class="line"><span class="symbol">57 </span> <span class="number">49</span>  <span class="number">41</span>  <span class="number">33</span>  <span class="number">25</span>  <span class="number">17</span>  <span class="number">9</span>   <span class="number">1</span></span><br><span class="line"><span class="symbol">59 </span> <span class="number">51</span>  <span class="number">43</span>  <span class="number">35</span>  <span class="number">27</span>  <span class="number">19</span>  <span class="number">11</span>  <span class="number">3</span></span><br><span class="line"><span class="symbol">61 </span> <span class="number">53</span>  <span class="number">45</span>  <span class="number">37</span>  <span class="number">29</span>  <span class="number">21</span>  <span class="number">13</span>  <span class="number">5</span></span><br><span class="line"><span class="symbol">63 </span> <span class="number">55</span>  <span class="number">47</span>  <span class="number">39</span>  <span class="number">31</span>  <span class="number">23</span>  <span class="number">15</span>  <span class="number">7</span></span><br></pre></td></tr></tbody></table></figure></li></ol><p>$E$盒：<br><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20200417200233.png"></p><p> $S$盒：<br><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20200417200503.png"></p><p>$P$盒：<br><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20200417200612.png"><br>交换表$IP-1$：<br><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20200417200621.png"></p><h2 id="3-参考链接"><a href="#3-参考链接" class="headerlink" title="3 参考链接"></a>3 参考链接</h2><ol><li><a href="http://www.doc88.com/p-9909383710144.html" target="_blank" rel="noopener">道客巴巴</a></li><li><a href="https://blog.csdn.net/yxtxiaotian/article/details/52025653" target="_blank" rel="noopener">DES加解密算法</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 密码学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DES </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>偏微分方程</title>
      <link href="/article/d1b5.html"/>
      <url>/article/d1b5.html</url>
      
        <content type="html"><![CDATA[<p>偏微分的学习记录，持续更新中。。。</p><a id="more"></a><h2 id="3-热传导方程"><a href="#3-热传导方程" class="headerlink" title="3 热传导方程"></a>3 热传导方程</h2><h3 id="3-1-热传导方程的-Cauchy-问题"><a href="#3-1-热传导方程的-Cauchy-问题" class="headerlink" title="3.1 热传导方程的 Cauchy 问题"></a>3.1 热传导方程的 Cauchy 问题</h3><h4 id="3-1-1-齐次热传导方程的-Cauchy-问题"><a href="#3-1-1-齐次热传导方程的-Cauchy-问题" class="headerlink" title="3.1.1 齐次热传导方程的 Cauchy 问题"></a>3.1.1 齐次热传导方程的 Cauchy 问题</h4><p>一维齐次热传导方程的Cauchy问题是</p><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;u_{t}-a^{2} u_{x x}=0, \quad-\infty&lt;x&lt;\infty, t&gt;0  \\<br>&amp;\left.u\right|_{t=0}=\varphi(x), \quad-\infty&lt;x&lt;\infty<br>\end{aligned}<br>\tag{1} \label{eq:1}<br>\right.<br>\end{equation} $$</p><p>方程 （1）的解具有如下性质：</p><blockquote><p>性质 3.1 设$ u(x,t) $是（1）的解, 则对任意的$ y\in R$，$u(x-y, t)$ 也是（1）的解。<br>性质 3.2 设$ u(x,t) $是（1）的解, 则它的各阶导数也是（1）的解。<br>性质 3.3 设$ S(x,t) $是（1）的解，则对任意连续函数$ g(y) $<br>$$<br>v(x, t)=\int_{-\infty}^{\infty} S(x-y, t) g(y) \mathrm{d} y<br>$$<br>也是（1）的解。</p></blockquote><p>理由：<br>$$V_{\varepsilon}=\int_{-\infty}^{\infty} S_{\varepsilon}(x-y, t) g(y)\to g(x) \qquad \varepsilon\to 0 $$</p><blockquote><p>性质 3.4 设$ u(x,t) $是（1）的解，则对任意的$ \lambda&gt;0,$ $u\left(\lambda x, \lambda^{2} t\right)$ 也是（1）的解。</p></blockquote><p>理由：<br>$u$是（1）的解，寻找$v(x,t)=\lambda{\alpha}u(\lambda{\beta}x，\lambda{\gamma}t)$是（1）的解<br>$$v_t=\lambda{\alpha+\gamma}u_t,u_x=\lambda{\alpha+\beta}u_x，u_{xx}=\lambda{\alpha+2\beta}u_x$$<br>$$0=v_t-a^{2}v_{xx}=\lambda{\alpha+\gamma}u_t-a^{2}\lambda{\alpha+2\beta}u_{xx}$$<br>取$$\gamma=2\beta，\lambda=\frac{1}{\sqrt{t}}，v(x, t)=u(\lambda x，\lambda^{2}t)=u({\frac{x}{\sqrt{t}}})=u(\xi)，\xi={\frac{x}{\sqrt{t}}}$$<br>空间变量、时间变量做伸缩变换（尺度不一）<br>$$0=v_t-a^{2}v_{xx}=2xt^{-\frac{3}{2}}- a^2 u^{\prime \prime} t^{-1}$$<br>化简有<br>$$u^{\prime \prime}+\frac{1}{2 a^{2}} \xi u^{\prime}=0$$<br>$$u(\xi)=c_{1} \int_{0}^{\xi} \mathrm{e}^{-\frac{1}{4 a^{2}} \eta^{2}} d \eta+c_{2}$$<br>其中$ c_1 $, $ c_2 $是两个积分常数。<br>进而<br>$$u(x,t)=c_{1} \int_{0}^{\frac{x}{\sqrt{t}}} \mathrm{e}^{-\frac{1}{4 a^{2}} \eta^{2}} d \eta+c_{2}$$<br>$$S(x, t)=\frac{\partial}{\partial x} v(x, t)=\frac{c_{1}}{\sqrt{t}} e^{-\frac{x^{2}}{4 a^{2} t}}$$<br>由性质3.3知对任意连续函数$g(y)$,<br>$$v(x, t)=\int_{-\infty}^{\infty} S(x-y, t) g(y) \mathrm{d} y=\frac{c_{1}}{\sqrt{t}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2} t}} g(y) \mathrm{d} y$$<br>也是（1）的解<br>求出$c_1$使其满足初始条件，即<br>$$\lim_{t \rightarrow 0^{+}}\frac{c_{1}}{\sqrt{t}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2} t}} g(y) \mathrm{d} y = \varphi(y)$$<br>作变换$y-x=2a \sqrt{t} \xi$，有<br>$$\lim_{t \rightarrow 0^{+}}\frac{c_{1}}{\sqrt{t}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-\mu)^{2}}{4 a^{2} t}} g(x+2a \sqrt{t} \xi) 2a{\sqrt{t}} \mathrm{d} \xi = 2ac_1\lim_{t \rightarrow 0^{+}}\frac{c_{1}}{\sqrt{t}} \int_{-\infty}^{\infty} \mathrm{e}^{-\xi^{2}} g(x+2a \sqrt{t}\xi) \mathrm{d} \xi \\ =2ac_1g(x)\int_{-\infty}^{\infty}\mathrm{e}^{-\xi^{2}} \mathrm{d} \xi=2a{\sqrt{\pi}}c_1g(x)=\varphi(x)$$<br>第二个等号成立的条件：$g$连续且一致有界$\Rightarrow$一致收敛（反常积分）$\Rightarrow$t的连续函数<br>取$c_1=\frac{\varphi(x)}{2a{\sqrt{\pi}}g(x)}$，代入有<br>$$u(x,t)=\frac{1}{2a{\sqrt{\pi t}}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2} t}} \varphi(y) \mathrm{d} y$$<br>称上式为Cauchy问题的Possion公式<br>记<br>$$G(x, t)=\begin{cases}<br>\frac{1}{2 a \sqrt{\pi t}} \mathrm{e}^{-\frac{x^{2}}{4 a^{2} t}}  &amp; t&gt;0 \\<br>0  &amp; t&lt;0<br>\end{cases} $$<br>则有<br>$$u(x, t)=\int_{-\infty}^{\infty} G(x-y, t) \varphi(y) \mathrm{d} y$$<br>称由上式确定的函数称为热核函数</p><p>下证$u(x,t)=\int_{-\infty}^{\infty} G(x-y,t) \varphi(y) \mathrm{d} y$是如下Cauchy问题的解：</p><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;u_{t}-a^{2} u_{x x}=0, \quad-\infty&lt;x&lt;\infty, t&gt;0  \\<br>&amp;\left.u\right|_{t=0}=\varphi(x), \quad-\infty&lt;x&lt;\infty<br>\end{aligned}<br>\right.<br>\end{equation} $$</p><p>由<br>$$u(x,t)=\frac{1}{2a{\sqrt{\pi t}}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2} t}} \varphi(y) \mathrm{d} y$$<br>知<br>$$u(x,t)=-\frac{1}{2a{\sqrt{\pi}t^{\frac{3}{2}}}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} \varphi(y) \mathrm{d} y+\frac{1}{2a{\sqrt{\pi}}t} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} {\frac{(x-y)^{2}}{4 a^{2} t^2}} \varphi(y) \mathrm{d} y$$<br>$\forall t_0 \gt 0,t\ge t_0$时，上述积分都一致收敛<br>理由：<br>$$\begin{aligned}<br>| u(x, t) | \leq M \int_{-\infty}^{\infty} G(x-y, t) \mathrm{d} y=\frac{M}{2 a \sqrt{\pi t}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} \mathrm{d} y=M<br>\end{aligned}$$<br>其中$|\varphi(x)| \le M,\forall t \gt 0$<br>局部：$\forall (x_0,t_1)\in \mathrm{R}\times(0,{\infty}) $，取$t_0=\frac{t_1}{2}$，故在$[\frac{t_1}{2},{\infty}]$上一致收敛<br>$$u_t(x, t)=\int_{-\infty}^{\infty} G_t(x-y, t) \varphi(y) \mathrm{d} y$$<br>$$u_{xx}(x, t)=\int_{-\infty}^{\infty} G_{xx}(x-y, t) \varphi(y) \mathrm{d} y$$<br>$$u_t(x, t)-a^2u_{xx}=\int_{-\infty}^{\infty} (G_t-a^2G_xx)(x-y, t) \varphi(y) \mathrm{d} y=0$$<br>注1：$\varphi$ 为有界连续函数，则$u(x,t)$当$t \gt 0$关于$x,t$无穷次可微，即<br>$$\frac{\partial^{k+1} u}{\partial x^{k} \partial t^{l}}=\int_{-\infty}^{\infty} \frac{\partial^{k+l}}{\partial x^{k} \partial t^{l}} G(x-y, t) \varphi(y) \mathrm{d} y \sim P(\frac{1}{\sqrt{t}}) \int_{-\infty}^{\infty} Q(x,y) \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} \varphi(y) \mathrm{d} y$$<br>其中$\sim$为等价符号，$Q(x,y)$为只含$x,y$变量的二元函数。由$\forall \delta \gt 0$，上式右端在区域${-\infty&lt;x&lt;\infty, t \geq \delta}$上一致收敛。由于当$t \gt 0$，$G(x-y,t)$无穷次可微，故$u(x, t) \in C^{\infty}\left(\mathbb{R}_{+}^{2}\right)$</p><p>注2：初值 $\varphi $属于有界函数类的条件可放宽为$${|\varphi(x)| \leq M \mathrm{e}^{N x^{2}}, \quad-\infty&lt;x&lt;\infty}$$<br>理由:可证$u(x,t)$在区域$ {0 \lt t \lt \frac{1}{4 a^{2} N}，-\infty&lt;x&lt;\infty}$上仍是热传导方程Cauchy问题的解。</p><p>注3：若$|\varphi(x)| \le M$，由Possion公式知，$|u(x,t)| \le M，-\infty&lt;x&lt;\infty，t \geq 0$</p><p>注4：Possion公式给出的解在任意一点$(x,t)(t \gt 0)$的值，依赖于初始值在整个$x$轴的值，没有有限的依赖区域。<br>如果杆的初始温度只在某一小段$I_{\delta}=\left(x_{0}-\delta, x_{0}+\delta\right)$不为0，设$$\varphi(x)&gt;0, x \in I_{\delta}; \varphi(x) \equiv 0, x \notin I_{\delta}$$<br>当$ t \geq 0$时，$$u(x, t)=\int_{-\infty}^{\infty} G(x-y, t) \varphi(y) \mathrm{d} y&gt;0$$<br>说明热量瞬间传播到杆上的每一点，热的传播速度是无限的</p><h4 id="3-1-2-非齐次热传导方程的-Cauchy-问题"><a href="#3-1-2-非齐次热传导方程的-Cauchy-问题" class="headerlink" title="3.1.2 非齐次热传导方程的 Cauchy 问题"></a>3.1.2 非齐次热传导方程的 Cauchy 问题</h4><p>一维非齐次热传导方程的Cauchy问题是</p><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;u_{t}-a^{2} u_{x x}=f(x,t), \quad-\infty&lt;x&lt;\infty, t&gt;0  \\<br>&amp;\left.u\right|_{t=0}=\varphi(x), \quad-\infty&lt;x&lt;\infty<br>\end{aligned}<br>\tag{2} \label{eq:2}<br>\right.<br>\end{equation} $$<br>由叠加原理上式可分解为以下两个问题的求解：</p><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;u_{t}-a^{2} u_{x x}=0, \quad-\infty&lt;x&lt;\infty, t&gt;0  \\<br>&amp;\left.u\right|_{t=0}=\varphi(x), \quad-\infty&lt;x&lt;\infty<br>\end{aligned}<br>\right.<br>\end{equation} $$</p><p>解出<br>$$u(x, t)=\int_{-\infty}^{\infty} G(x-y, t) \varphi(y) \mathrm{d}=\frac{1}{2 a \sqrt{\pi t}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} \varphi(y) \mathrm{d} y $$</p><p>和</p><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;u_{t}-a^{2} u_{x x}=f(x,t), \quad-\infty&lt;x&lt;\infty, t&gt;0  \\<br>&amp;\left.u\right|_{t=0}=0, \quad-\infty&lt;x&lt;\infty<br>\end{aligned}<br>\tag{3} \label{eq:3}<br>\right.<br>\end{equation} $$</p><blockquote><p>引理3.1（齐次化原理）若函数$w(x,t,\tau)$是Cauchy问题<br>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;w_{t}-a^{2} w_{x x}=0, \quad-\infty&lt;x&lt;\infty, t&gt;0  \\<br>&amp;\left.w\right|_{t=0}=f(x,\tau), \quad-\infty&lt;x&lt;\infty<br>\end{aligned}<br>\tag{4} \label{eq:4}<br>\right.<br>\end{equation} $$</p></blockquote><p>的解，则函数 $u(x,t)=\int_{0}^{t} w(x,t,\tau) \mathrm{d} \tau$ 是Cauchy问题（4）的解<br>证：</p><ol><li>满足初始条件$\left.u\right|_{t=0}=0 $</li><li>满足方程$u_{t}-a^{2} u_{x x}=f(x,t)$<br>$$u_t=w(x,t,\tau)+\int_{0}^{t} w_t (x,t,\tau) \mathrm{d} \tau = f(x,t)+\int_{0}^{t} w_t(x,t,\tau) \mathrm{d} \tau$$<br>$$u_x=\int_{0}^{t} w_x (x,t,\tau) \mathrm{d} \tau，u_{xx}=\int_{0}^{t} w_{xx} (x,t,\tau) \mathrm{d} \tau$$<br>则<br>$$u_t-a^{2}u_{xx} = f(x,t)+ \int_{0}^{t} w_t (x,t,\tau) \mathrm{d} \tau - a^{2} \int_{0}^{t} w_{xx} (x,t,\tau) \mathrm{d} \tau \\ = f(x,t) + \int_{0}^{t} (w_t - a^{2}w_{xx}) (x,t,\tau) \mathrm{d} \tau = f(x,t)$$</li></ol><p>为了求解问题（4），令$t^{\prime}=t-\tau，x=x$（自变量变换）</p><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;w_{t^{\prime}}-a^{2} w_{x x}=0, \quad-\infty&lt;x&lt;\infty, t^{\prime}&gt;0  \\<br>&amp;\left.w\right|_{t^{\prime}=0}=f(x,\tau), \quad-\infty&lt;x&lt;\infty<br>\end{aligned}<br>\tag{5} \label{eq:5}<br>\right.<br>\end{equation} $$</p><p>解出<br>$$w(x,t^{\prime},\tau)=\int_{-\infty}^{\infty} G(x-y, t^{\prime}) f(y,\tau) \mathrm{d} y $$<br>则问题（4）的解<br>$$w(x,t,\tau)=\int_{-\infty}^{\infty} G(x-y, t-\tau) f(y,\tau) \mathrm{d} y $$<br>则问题（3）的解<br>$$u(x,t)=\int_{0}^{t}\int_{-\infty}^{\infty} G(x-y, t-\tau) f(y,\tau) \mathrm{d} y \mathrm{d} \tau$$<br>故由叠加原理,问题（2）的解为<br>$$u(x,t)=\int_{-\infty}^{\infty} G(x-y, t) \varphi(y)\mathrm{d} y + \int_{0}^{t}\int_{-\infty}^{\infty} G(x-y, t-\tau) f(y,\tau) \mathrm{d} y \mathrm{d} \tau $$<br>也记为$$u(x,t)=G \ast \varphi + \int_{0}^{t} G(\bullet,t-\tau)f(\bullet,t-\tau)$$<br>其中$\ast$为卷积符号，$\bullet$表示关于第一个空间变量作卷积</p><blockquote><p>定理3.1：若$\varphi(x) \in C(-\infty, \infty), f(x, t) \in C((-\infty, \infty) \times(0, \infty))$且均有界，则由Possion公式确定的函数$u(x,t)$是Cauchy问题（2）的解</p></blockquote><p>理由：根据上述推导证明可得。</p><h3 id="3-2-热传导方程的混合问题"><a href="#3-2-热传导方程的混合问题" class="headerlink" title="3.2 热传导方程的混合问题"></a>3.2 热传导方程的混合问题</h3><h4 id="3-2-1-半直线上热传导方程与热的反射"><a href="#3-2-1-半直线上热传导方程与热的反射" class="headerlink" title="3.2.1 半直线上热传导方程与热的反射"></a>3.2.1 半直线上热传导方程与热的反射</h4><p>考虑侧表面绝热的均匀细杆，一端固定，已知初始温度和细杆在固定端点的温度，则杆上的温度分布满足如下混合问题：</p><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;u_{t}-a^{2} u_{x x}=f(x, t),  &amp;0 \lt x \lt \infty, t&gt;0 \\<br>&amp;u(x, 0)=\varphi(x),  &amp;0 \leq x \lt \infty \\<br>&amp;u(0, t)=\mu(t), &amp;t \geq 0<br>\end{aligned}<br>\tag{6} \label{eq:6}<br>\right.<br>\end{equation} $$</p><p>考虑$f(x) \equiv 0，u(t) \equiv 0$的情形</p><ol><li>Dirlect边界</li></ol><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;u_{t}-a^{2} u_{x x}=0,  &amp;0 \lt x \lt \infty, t&gt;0 \\<br>&amp;u(x, 0)=\varphi(x),  &amp;0 \leq x \lt \infty \\<br>&amp;u(0, t)=0, &amp;t \geq 0<br>\end{aligned}<br>\tag{7} \label{eq:7}<br>\right.<br>\end{equation} $$</p><p>由</p><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;u_{t}-a^{2} u_{x x}=0, \quad-\infty&lt;x&lt;\infty, t&gt;0  \\<br>&amp;\left.u\right|_{t=0}=\varphi(x), \quad-\infty&lt;x&lt;\infty<br>\end{aligned}<br>\tag{8} \label{eq:8}<br>\right.<br>\end{equation} $$</p><p>解出：<br>$$u(x, t)=\frac{1}{2 a \sqrt{\pi t}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} \varphi(y) \mathrm{d} y $$</p><p>初始：<br>$$ \left.u\right|_{t=0}=\varphi(x)，-\infty&lt;x&lt;\infty$$</p><p>选取（连续奇函数）：<br>$$\Phi(x)=\begin{cases}<br>\varphi(x)  &amp; x \ge 0 \\<br>-\varphi(-x)  &amp; x \lt 0<br>\end{cases} $$<br>其中：<br>$$u(0, t)=\frac{1}{2 a \sqrt{\pi t}} \int_{-\infty}^{\infty} e^{-\frac{y^{2}}{4 a^{2}}} \Phi(y) d y=0$$<br>则有：<br>$$u(x, t)=\frac{1}{2 a \sqrt{\pi t}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} \varphi(y) \mathrm{d} y = \frac{1}{2 a \sqrt{\pi t}} \int_{-\infty}^{0} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} {-\varphi(-y)} \mathrm{d} y +\\ \frac{1}{2 a \sqrt{\pi t}} \int_{0}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} \varphi(y) \mathrm{d} y  =\frac{1}{2 a \sqrt{\pi t}} \int_{0}^{+\infty}\left(\mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}}}-e^{-\frac{(x+y)^{2}}{4 a^{2}}}\right) \varphi(y) \mathrm{d} y $$</p><ol start="2"><li>Newmann边界</li></ol><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;u_{t}-a^{2} u_{x x}=0,  &amp;0 \lt x \lt \infty, t&gt;0 \\<br>&amp;u(x, 0)=\varphi(x),  &amp;0 \leq x \lt \infty \\<br>&amp;u_x(0, t)=0, &amp;t \geq 0<br>\end{aligned}<br>\tag{9} \label{eq:9}<br>\right.<br>\end{equation} $$<br>选取（连续偶函数）：<br>$$\Phi(x)=\begin{cases}<br>\varphi(x)  &amp; x \ge 0 \\<br>\varphi(-x)  &amp; x \lt 0<br>\end{cases} $$<br>则有：<br>$$u(x, t)=\frac{1}{2 a \sqrt{\pi t}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} \varphi(y) \mathrm{d} y = -\frac{1}{ a \sqrt{\pi t}} \int_{-\infty}^{0} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} {-\varphi(-y)} \mathrm{d} y + \\ \frac{1}{2 a \sqrt{\pi t}} \int_{0}^{\infty} \mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}t}} \varphi(y) \mathrm{d} y  =\frac{1}{2 a \sqrt{\pi t}} \int_{0}^{+\infty}\left(\mathrm{e}^{-\frac{(x-y)^{2}}{4 a^{2}}}+e^{-\frac{(x+y)^{2}}{4 a^{2}}}\right) \varphi(y) \mathrm{d} y $$</p><p>为求解问题（6），将边界齐次化，令$v(x,t)=u(x,t)-\mu(t)$<br>则</p><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;v_{t}-a^{2} v_{x x}=f(x,t)-\mu^{\prime}(t)，\\<br>&amp;v(x,0)=\varphi(x)-\mu(0)，\\<br>&amp;v(0,t)=0.\\<br>\end{aligned}<br>\right.<br>\end{equation} $$</p><p>由叠加原理，上述问题可分解为</p><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;v_{t}-a^{2} v_{x x}=0，\\<br>&amp;v(x,0)=\varphi(x)-\mu(0)，\\<br>&amp;v(0,t)=0.\\<br>\end{aligned}<br>\right.<br>\end{equation} $$</p><p>和</p><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;v_{t}-a^{2} v_{x x}=f(x,t)-\mu^{\prime}(t)，\\<br>&amp;v(x,0)=0，\\<br>&amp;v(0,t)=0.\\<br>\end{aligned}<br>\right.<br>\end{equation} $$</p><p>若令$v(x,t)=u(x,t)-\mu(t)x$，则可将Newmann边界齐次化<br>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;u_{t}-a^{2} u_{x x}=f(x,t), \quad-\infty \lt x \lt \infty, t&gt;0  \\<br>&amp;u(x,0)=\varphi(x), \quad 0 \le x \lt \infty \\<br>&amp;u_x(0,t)=\mu(t), \quad 0 \le x \lt \infty \\<br>\end{aligned}<br>\right.<br>\end{equation} $$</p><h4 id="3-2-1-有限区间上的热传导方程与分离变量法"><a href="#3-2-1-有限区间上的热传导方程与分离变量法" class="headerlink" title="3.2.1 有限区间上的热传导方程与分离变量法"></a>3.2.1 有限区间上的热传导方程与分离变量法</h4><p>在矩形区域$\Omega = {0 \le x \le l，0 \lt t \le T}$上，考虑<br>$$u_t-a^{2}u_{xx}=f(x,t)，0 \le x \le l，0 \lt t \le T$$</p><p>及初始条件<br>$$ \left.u\right|_{t=0}=\varphi(x)，0 \le x \le l $$</p><p>和边界条件<br>$$ u(0,t)=\mu_1(t), u(l,t)=\mu_2(t)，0 \le x \le l $$</p><p>先考虑第二边值问题<br>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;u_{t}-a^{2} u_{x x}=f(x,t), \quad 0 \lt x \lt l, t&gt;0  \\<br>&amp;u(x,0)=\varphi(x), \quad 0 \le x \le l \\<br>&amp;u_x(0,t)=\mu(t), u_x(0,t)=\mu(t) \\<br>\end{aligned}<br>\right.<br>\end{equation} $$<br>寻找$u(x,t)=X(x)T(t)$形式解<br>$$X(x)T^{\prime}(t)-a^{2}X^{\prime \prime}(x)T(t)=0$$<br>从而<br>$$\frac{T^{\prime}(t)}{a^{2}T(t)}=\frac{X^{\prime \prime}(x)}{X(x)}=\lambda$$<br>有<br>$$T^{\prime}(t)+a^{2}\lambda X^{\prime \prime}(x)T(t)=0$$<br>联立<br>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp;X^{\prime}(x)+a^{2}\lambda X^{\prime \prime}(x)T(t)=0 \\<br>&amp;X^{\prime}(0)=0, X^{\prime}(l)=0 \\<br>\end{aligned}<br>\right.<br>\end{equation} $$<br>情形$1^{\prime}$ $\lambda \lt 0$<br>$$X(x)=c_1e^{-\sqrt{-\lambda}}+c_2e^{-\sqrt{-\lambda}}，X^{\prime}(x)=\left(-c_1e^{-\sqrt{-\lambda}}+c_2e^{-\sqrt{-\lambda}}\right){-\sqrt{-\lambda}}$$<br>代入得$$c_1=c_2=0$$</p><p>情形$2^{\prime}$ $\lambda = 0$<br>$$X(x)=c_1+c_2x$$<br>代入得$c_2 = 0$，$X_0(x) \equiv 1$是上述问题得一个非平凡解</p><p>情形$3^{\prime}$ $\lambda \gt 0$<br>$$X(x)=c_1cos{\sqrt{\lambda}}x+c_2sin{\sqrt{\lambda}}x，X^{\prime}(x)=\left(-c_1sin{\sqrt{\lambda}}x+c_2cos{\sqrt{\lambda}}x\right){\sqrt{\lambda}}$$<br>代入得$c_2 = 0$，$c_1 = {\sqrt{\lambda}}sin{\sqrt{\lambda}}l = 0$</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 偏微分方程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 热传导方程 </tag>
            
            <tag> Cauchy 问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown中LaTeX编写技巧</title>
      <link href="/article/fcf1.html"/>
      <url>/article/fcf1.html</url>
      
        <content type="html"><![CDATA[<p>Markdown中LaTeX使用方法</p><a id="more"></a><h1 id="Markdown中LaTeX常用语法"><a href="#Markdown中LaTeX常用语法" class="headerlink" title="Markdown中LaTeX常用语法"></a>Markdown中LaTeX常用语法</h1><h2 id="1-常用希腊字母表"><a href="#1-常用希腊字母表" class="headerlink" title="1 常用希腊字母表"></a>1 常用希腊字母表</h2><table><thead><tr><th>Name</th><th align="center">Display</th><th>Capital Case</th><th align="center">Display</th><th>Var Case</th><th align="center">Display</th></tr></thead><tbody><tr><td><code>\alpha</code></td><td align="center">$\alpha$</td><td></td><td align="center"></td><td></td><td align="center"></td></tr><tr><td><code>\beta</code></td><td align="center">$\beta$</td><td></td><td align="center"></td><td></td><td align="center"></td></tr><tr><td><code>\gamma</code></td><td align="center">$\gamma$</td><td><code>\Gamma</code></td><td align="center">$\Gamma$</td><td></td><td align="center"></td></tr><tr><td><code>\theta</code></td><td align="center">$\theta$</td><td><code>\Theta</code></td><td align="center">$\Theta$</td><td><code>\vartheta</code></td><td align="center">$\vartheta$</td></tr><tr><td><code>\mu</code></td><td align="center">$\mu$</td><td></td><td align="center"></td><td></td><td align="center"></td></tr><tr><td><code>\delta</code></td><td align="center">$\delta$</td><td><code>\Delta</code></td><td align="center">$\Delta$</td><td></td><td align="center"></td></tr><tr><td><code>\epsilon</code></td><td align="center">$\epsilon$</td><td></td><td align="center"></td><td><code>\varepsilon</code></td><td align="center">$\varepsilon$</td></tr><tr><td><code>\sigma</code></td><td align="center">$\sigma$</td><td><code>\Sigma</code></td><td align="center">$\Sigma$</td><td><code>\varsigma</code></td><td align="center">$\varsigma$</td></tr><tr><td><code>\pi</code></td><td align="center">$\pi$</td><td><code>\Pi</code></td><td align="center">$\Pi$</td><td><code>\varpi</code></td><td align="center">$\varpi$</td></tr><tr><td><code>\omega</code></td><td align="center">$\omega$</td><td><code>\Omega</code></td><td align="center">$\Omega$</td><td></td><td align="center"></td></tr><tr><td><code>\xi</code></td><td align="center">$\xi$</td><td><code>\Xi</code></td><td align="center">$\Xi$</td><td></td><td align="center"></td></tr><tr><td><code>\zeta</code></td><td align="center">$\zeta$</td><td></td><td align="center"></td><td></td><td align="center"></td></tr><tr><td><code>\chi</code></td><td align="center">$\chi$</td><td></td><td align="center"></td><td></td><td align="center"></td></tr><tr><td><code>\rho</code></td><td align="center">$\rho$</td><td></td><td align="center"></td><td><code>\varrho</code></td><td align="center">$\varrho$</td></tr><tr><td><code>\phi</code></td><td align="center">$\phi$</td><td><code>\Phi</code></td><td align="center">$\Phi$</td><td><code>\varphi</code></td><td align="center">$\varphi$</td></tr><tr><td><code>\eta</code></td><td align="center">$\eta$</td><td></td><td align="center"></td><td></td><td align="center"></td></tr><tr><td><code>\lambda</code></td><td align="center">$\lambda$</td><td><code>\Lambda</code></td><td align="center">$\Lambda$</td><td></td><td align="center"></td></tr><tr><td><code>\kappa</code></td><td align="center">$\kappa$</td><td></td><td align="center"></td><td></td><td align="center"></td></tr><tr><td><code>\nu</code></td><td align="center">$\nu$</td><td></td><td align="center"></td><td></td><td align="center"></td></tr><tr><td><code>\upsilon</code></td><td align="center">$\upsilon$</td><td><code>\Upsilon</code></td><td align="center">$\Upsilon$</td><td></td><td align="center"></td></tr><tr><td><code>\psi</code></td><td align="center">$\psi$</td><td><code>\Psi</code></td><td align="center">$\Psi$</td><td></td><td align="center"></td></tr><tr><td><code>\tau</code></td><td align="center">$\tau$</td><td></td><td align="center"></td><td></td><td align="center"></td></tr><tr><td><code>\iota</code></td><td align="center">$\iota$</td><td></td><td align="center"></td><td></td><td align="center"></td></tr><tr><td><code>o</code></td><td align="center">$o$</td><td></td><td align="center"></td><td></td><td align="center"></td></tr></tbody></table><h2 id="2-常用特殊字符表"><a href="#2-常用特殊字符表" class="headerlink" title="2 常用特殊字符表"></a>2 常用特殊字符表</h2><table><thead><tr><th>Name</th><th align="center">Display</th><th>Name</th><th align="center">Display</th><th>Name</th><th align="center">Display</th><th>Name</th><th align="center">Display</th></tr></thead><tbody><tr><td><code>\times</code></td><td align="center">$\times$</td><td><code>\div</code></td><td align="center">$\div$</td><td><code>\pm</code></td><td align="center">$\pm$</td><td><code>\mp</code></td><td align="center">$\mp$</td></tr><tr><td><code>\otimes</code></td><td align="center">$\otimes$</td><td><code>\ominus</code></td><td align="center">$\ominus$</td><td><code>\oplus</code></td><td align="center">$\oplus$</td><td><code>\odot</code></td><td align="center">$\odot$</td></tr><tr><td><code>\oslash</code></td><td align="center">$\oslash$</td><td><code>\triangleq</code></td><td align="center">$\triangleq$</td><td><code>\ne</code></td><td align="center">$\ne$</td><td><code>\equiv</code></td><td align="center">$\equiv$</td></tr><tr><td><code>\lt</code></td><td align="center">$\lt$</td><td><code>\gt</code></td><td align="center">$\gt$</td><td><code>\le</code></td><td align="center">$\le$</td><td><code>\ge</code></td><td align="center">$\ge$</td></tr><tr><td><code>\cup</code></td><td align="center">$\cup$</td><td><code>\cap</code></td><td align="center">$\cap$</td><td><code>\Cup</code></td><td align="center">$\Cup$</td><td><code>\Cap</code></td><td align="center">$\Cap$</td></tr><tr><td><code>\bigcup</code></td><td align="center">$\bigcup$</td><td><code>\bigcap</code></td><td align="center">$\bigcap$</td><td><code>\ast</code></td><td align="center">$\ast$</td><td><code>\star</code></td><td align="center">$\star$</td></tr><tr><td><code>\bigotimes</code></td><td align="center">$\bigotimes$</td><td><code>\bigoplus</code></td><td align="center">$\bigoplus$</td><td><code>\circ</code></td><td align="center">$\circ$</td><td><code>\bullet</code></td><td align="center">$\bullet$</td></tr><tr><td><code>\bigcirc</code></td><td align="center">$\bigcirc$</td><td><code>\amalg</code></td><td align="center">$\amalg$</td><td><code>\to</code></td><td align="center">$\to$</td><td><code>\infty</code></td><td align="center">$\infty$</td></tr><tr><td><code>\vee</code></td><td align="center">$\vee$</td><td><code>\wedge</code></td><td align="center">$\wedge$</td><td><code>\uplus</code></td><td align="center">$\uplus$</td><td><code>\biguplus</code></td><td align="center">$\biguplus$</td></tr><tr><td><code>\bigvee</code></td><td align="center">$\bigvee$</td><td><code>\bigwedge</code></td><td align="center">$\bigwedge$</td><td><code>\unlhd</code></td><td align="center">$\unlhd$</td><td><code>\unrhd</code></td><td align="center">$\unrhd$</td></tr><tr><td><code>\sqcap</code></td><td align="center">$\sqcap$</td><td><code>\sqcup</code></td><td align="center">$\sqcup$</td><td><code>\prec</code></td><td align="center">$\prec$</td><td><code>\succ</code></td><td align="center">$\succ$</td></tr><tr><td><code>\subset</code></td><td align="center">$\subset$</td><td><code>\supset</code></td><td align="center">$\supset$</td><td><code>\sim</code></td><td align="center">$\sim$</td><td><code>\approx</code></td><td align="center">$\approx$</td></tr><tr><td><code>\subseteq</code></td><td align="center">$\subseteq$</td><td><code>\supseteq</code></td><td align="center">$\supseteq$</td><td><code>\cong</code></td><td align="center">$\cong$</td><td><code>\doteq</code></td><td align="center">$\doteq$</td></tr><tr><td><code>\setminus</code></td><td align="center">$\setminus$</td><td><code>\mid</code></td><td align="center">$\mid$</td><td><code>\ll</code></td><td align="center">$\ll$</td><td><code>\gg</code></td><td align="center">$\gg$</td></tr><tr><td><code>\parallel</code></td><td align="center">$\parallel$</td><td><code>\Join</code></td><td align="center">$\Join$</td><td><code>\in</code></td><td align="center">$\in$</td><td><code>\notin</code></td><td align="center">$\notin$</td></tr><tr><td><code>\propto</code></td><td align="center">$\propto$</td><td><code>\neg</code></td><td align="center">$\neg$</td><td><code>\ldots</code></td><td align="center">$\ldots$</td><td><code>\cdots</code></td><td align="center">$\cdots$</td></tr><tr><td><code>\forall</code></td><td align="center">$\forall$</td><td><code>\exists</code></td><td align="center">$\exists$</td><td><code>\vdots</code></td><td align="center">$\vdots$</td><td><code>\ddots</code></td><td align="center">$\ddots$</td></tr><tr><td><code>\aleph</code></td><td align="center">$\aleph$</td><td><code>\nabla</code></td><td align="center">$\nabla$</td><td><code>\imath</code></td><td align="center">$\imath$</td><td><code>\jmath</code></td><td align="center">$\jmath$</td></tr><tr><td><code>\ell</code></td><td align="center">$\ell$</td><td><code>\partial</code></td><td align="center">$\partial$</td><td><code>\int</code></td><td align="center">$\int$</td><td><code>\oint</code></td><td align="center">$\oint$</td></tr></tbody></table><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><table><thead><tr><th>Name</th><th align="center">Display</th><th>Name</th><th align="center">Display</th></tr></thead><tbody><tr><td><code>\triangleleft</code></td><td align="center">$\triangleleft$</td><td><code>\triangleright</code></td><td align="center">$\triangleright$</td></tr><tr><td><code>\bigtriangleup</code></td><td align="center">$\bigtriangleup$</td><td><code>\bigtriangledown</code></td><td align="center">$\bigtriangledown$</td></tr><tr><td><code>\uparrow</code></td><td align="center">$\uparrow$</td><td><code>\downarrow</code></td><td align="center">$\downarrow$</td></tr><tr><td><code>\leftarrow</code></td><td align="center">$\leftarrow$</td><td><code>\rightarrow</code></td><td align="center">$\rightarrow$</td></tr><tr><td><code>\Leftarrow</code></td><td align="center">$\Leftarrow$</td><td><code>\Rightarrow</code></td><td align="center">$\Rightarrow$</td></tr><tr><td><code>\longleftarrow</code></td><td align="center">$\longleftarrow$</td><td><code>\longrightarrow</code></td><td align="center">$\longrightarrow$</td></tr><tr><td><code>\Longleftarrow</code></td><td align="center">$\Longleftarrow$</td><td><code>\Longrightarrow</code></td><td align="center">$\Longrightarrow$</td></tr><tr><td><code>\leftrightarrow</code></td><td align="center">$\leftrightarrow$</td><td><code>\longleftrightarrow</code></td><td align="center">$\longleftrightarrow$</td></tr><tr><td><code>\Leftrightarrow</code></td><td align="center">$\Leftrightarrow$</td><td><code>\Longleftrightarrow</code></td><td align="center">$\Longleftrightarrow$</td></tr><tr><td><code>\leftharpoonup</code></td><td align="center">$\leftharpoonup$</td><td><code>\rightharpoonup</code></td><td align="center">$\rightharpoonup$</td></tr><tr><td><code>\leftharpoondown</code></td><td align="center">$\leftharpoondown$</td><td><code>\rightharpoondown</code></td><td align="center">$\rightharpoondown$</td></tr><tr><td><code>\rightleftharpoons</code></td><td align="center">$\rightleftharpoons$</td><td><code>\S</code></td><td align="center">$\S$</td></tr><tr><td><code>\nwarrow</code></td><td align="center">$\nwarrow$</td><td><code>\nearrow</code></td><td align="center">$\nearrow$</td></tr><tr><td><code>\swarrow</code></td><td align="center">$\swarrow$</td><td><code>\searrow</code></td><td align="center">$\searrow$</td></tr><tr><td><code>\triangle</code></td><td align="center">$\triangle$</td><td><code>\box</code></td><td align="center">$\Box$</td></tr><tr><td><code>\diamond</code></td><td align="center">$\diamond$</td><td><code>\diamondsuit</code></td><td align="center">$\diamondsuit$</td></tr><tr><td><code>\heartsuit</code></td><td align="center">$\heartsuit$</td><td><code>\clubsuit</code></td><td align="center">$\clubsuit$</td></tr><tr><td><code>\spadesuit</code></td><td align="center">$\spadesuit$</td><td><code>\mapsto</code></td><td align="center">$\mapsto$</td></tr><tr><td><code>\longmapsto</code></td><td align="center">$\longmapsto$</td><td><code>\hookleftarrow</code></td><td align="center">$\hookleftarrow$</td></tr><tr><td><code>\hookleftarrow</code></td><td align="center">$\hookleftarrow$</td><td><code>\hookrightarrow</code></td><td align="center">$\hookrightarrow$</td></tr><tr><td><code>\leftharpoonup</code></td><td align="center">$\leftharpoonup$</td><td><code>\rightharpoonup</code></td><td align="center">$\rightharpoonup$</td></tr><tr><td><code>\leftharpoondown</code></td><td align="center">$\leftharpoondown$</td><td><code>\rightharpoondown</code></td><td align="center">$\rightharpoondown$</td></tr><tr><td><code>\rightleftharpoons</code></td><td align="center">$\rightleftharpoons$</td><td><code>\leadsto</code></td><td align="center">$\leadsto$</td></tr><tr><td><code>\nearrow</code></td><td align="center">$\nearrow$</td><td><code>\searrow</code></td><td align="center">$\searrow$</td></tr><tr><td><code>\swarrow</code></td><td align="center">$\swarrow$</td><td><code>\nwarrow</code></td><td align="center">$\nwarrow$</td></tr><tr><td><code>\nleftarrow</code></td><td align="center">$\nleftarrow$</td><td><code>\nrightarrow</code></td><td align="center">$\nrightarrow$</td></tr><tr><td><code>\nLeftarrow</code></td><td align="center">$\nLeftarrow$</td><td><code>\nRightarrow</code></td><td align="center">$\nRightarrow$</td></tr><tr><td><code>\nleftrightarrow</code></td><td align="center">$\nleftrightarrow$</td><td><code>\nLeftrightarrow</code></td><td align="center">$\nLeftrightarrow$</td></tr><tr><td><code>\dashrightarrow</code></td><td align="center">$\dashrightarrow$</td><td><code>\dashleftarrow</code></td><td align="center">$\dashleftarrow$</td></tr><tr><td><code>\leftleftarrows</code></td><td align="center">$\leftrightarrows$</td><td><code>\Lleftarrow</code></td><td align="center">$\Lleftarrow$</td></tr><tr><td><code>\twoheadleftarrow</code></td><td align="center">$\twoheadleftarrow$</td><td><code>\leftarrowtail</code></td><td align="center">$\leftarrowtail$</td></tr><tr><td><code>\looparrowleft</code></td><td align="center">$\looparrowleft$</td><td><code>\leftrightharpoons</code></td><td align="center">$\leftrightharpoons$</td></tr><tr><td><code>\curvearrowleft</code></td><td align="center">$\curvearrowleft$</td><td><code>\circlearrowleft</code></td><td align="center">$\circlearrowleft$</td></tr><tr><td><code>\Lsh</code></td><td align="center">$\Lsh$</td><td><code>\upuparrows</code></td><td align="center">$\upuparrows$</td></tr><tr><td><code>\upharpoonleft</code></td><td align="center">$\upharpoonleft$</td><td><code>\downharpoonleft</code></td><td align="center">$\downharpoonleft$</td></tr><tr><td><code>\multimap</code></td><td align="center">$\multimap$</td><td><code>\leftrightsquigarrow</code></td><td align="center">$\leftrightsquigarrow$</td></tr><tr><td><code>\rightrightarrows</code></td><td align="center">$\rightrightarrows$</td><td><code>\rightleftarrows</code></td><td align="center">$\rightleftarrows$</td></tr><tr><td><code>\rightrightarrows</code></td><td align="center">$\rightrightarrows$</td><td><code>\rightleftarrows</code></td><td align="center">$\rightleftarrows$</td></tr><tr><td><code>\twoheadrightarrow</code></td><td align="center">$\twoheadrightarrow$</td><td><code>\rightarrowtail</code></td><td align="center">$\rightarrowtail$</td></tr><tr><td><code>\looparrowright</code></td><td align="center">$\looparrowright$</td><td><code>\rightleftharpoons</code></td><td align="center">$\rightleftharpoons$</td></tr><tr><td><code>\curvearrowright</code></td><td align="center">$\curvearrowright$</td><td><code>\circlearrowright</code></td><td align="center">$\circlearrowright$</td></tr><tr><td><code>\Rsh</code></td><td align="center">$\Rsh$</td><td><code>\downdownarrows</code></td><td align="center">$\downdownarrows$</td></tr><tr><td><code>\upharpoonright</code></td><td align="center">$\upharpoonright$</td><td><code>\downharpoonright</code></td><td align="center">$\downharpoonright$</td></tr><tr><td><code>\rightsquigarrow</code></td><td align="center">$\rightsquigarrow$</td><td></td><td align="center"></td></tr></tbody></table><table><thead><tr><th>Name</th><th align="center">Display</th></tr></thead><tbody><tr><td><code>\left( \frac{a}{b} \right)</code></td><td align="center">$\left( \frac{a}{b} \right)$</td></tr><tr><td><code>\left[ \frac{a}{b} \right]</code></td><td align="center">$\left[ \frac{a}{b} \right]$</td></tr><tr><td><code>\left \langle \frac{a}{b} \right \rangle</code></td><td align="center">$\left \langle \frac{a}{b} \right \rangle$</td></tr><tr><td><code>\left | \frac{a}{b} \right |</code></td><td align="center">$\left | \frac{a}{b} \right |$</td></tr><tr><td><code>\left \lfloor \frac{a}{b} \right \rfloor</code></td><td align="center">$\left \lfloor \frac{a}{b} \right \rfloor$</td></tr><tr><td><code>\left \lceil \frac{c}{d} \right \rceil</code></td><td align="center">$\left \lceil \frac{c}{d} \right\rceil$</td></tr><tr><td><code>\left / \frac{a}{b} \right \backslash</code></td><td align="center">$\left / \frac{a}{b} \right \backslash$</td></tr><tr><td><code>\left \uparrow \frac{a}{b} \right \downarrow</code></td><td align="center">$\left \uparrow \frac{a}{b} \right \downarrow$</td></tr><tr><td><code>\left \Uparrow \frac{a}{b} \right \Downarrow</code></td><td align="center">$\left \Uparrow \frac{a}{b} \right \Downarrow$</td></tr><tr><td><code>\left \updownarrow \frac{a}{b} \right \Updownarrow</code></td><td align="center">$\left \updownarrow \frac{a}{b} \right \Updownarrow$</td></tr></tbody></table><h2 id="3-公式语法"><a href="#3-公式语法" class="headerlink" title="3 公式语法"></a>3 公式语法</h2><ul><li><p>上下标<code>_ ^ , _{}^{}</code>：<br>  $$ y = x_i^{a_1^2} $$</p></li><li><p>公式中插入文本<code>\mbox{}</code>：<br>  $$ y = x^2 ; \mbox{(二次函数)} $$</p></li><li><p>公式中插入空格<code>\,  \;  \quad  \qquad</code>间隔依次变宽：<br>  $$ ab $$ $$ a,b $$ $$ a;b $$ $$ a\quad b $$ $$ a\qquad b $$</p></li><li><p>字母上方横线<code>\overline{}, \bar{}</code>：<br>  $$ \overline{xyz} \mbox{ 或 } \bar{x} $$</p></li><li><p>字母下方横线<code>\underline{}</code>：<br>  $$ \underline{ABC} $$</p></li><li><p>字母上方波浪线<code>\tilde{}, \widetilde{}</code>：<br>  $$ \tilde{A} \mbox{ 或 } \widetilde{ABC} $$</p></li><li><p>字母上方尖号^<code>\hat{}, \widehat{}</code>：<br>  $$ \hat{A} \mbox{ 或 } \widehat{ABC} $$</p></li><li><p>字母上方箭头<code>\vec{}, \overleftarrow{}, \overrightarrow{}</code>：<br>  $$ \vec{ab} \mbox{ 或 } \overleftarrow{ab} \mbox{ 或 } \overrightarrow{ab} $$</p></li><li><p>字母上方花括号<code>\overbrace{}</code>，或下方花括号<code>\underbrace{}</code>：<br>  $$ \overbrace{1+2+3} \mbox{ 或 } \underbrace{1+2+3} $$</p></li><li><p>字母上方点号<code>\dot{}, \ddot{}</code>：<br>  $$ \dot{a} \mbox{ 或 } \ddot{a} $$</p></li><li><p>省略号<code>\dots, \cdots</code><br>  $$ 1,2,\dots  \qquad  1,2,\cdots $$</p></li><li><p>积分<code>\int_{}^{}</code>：<br>  $$ \int_{-\infty}^{+\infty} f(x) \mathrm{d}x $$</p><p>  双重积分<code>\iint</code>：$$ \iint_{-\infty}^{+\infty} f(x,y) \mathrm{d}x \mathrm{d}y $$<br>  行内积分：$\int_{-\infty}^{+\infty} f(x) \mathrm{d}x$<br>  行内积分limits模式<code>\int\limits_{}^{}</code>：$\int\limits_{-\infty}^{+\infty} f(x) \mathrm{d}x$<br>  行内积分display模式<code>\displaystyle \int_{}^{}</code>：$\displaystyle \int_{-\infty}^{+\infty} f(x) \mathrm{d}x$</p><p>  圆圈积分<code>\oint</code>：$$ \oint_{-\infty}^{+\infty} $$</p></li><li><p>求和<code>\sum_{}^{}</code>：<br>  $$ \sum_{i=1}^{n} i^2 $$</p><p>  行内求和：$\sum_{i=1}^{n} i^2$<br>  行内求和limits模式<code>\sum\limits_{}^{}</code>：$\sum\limits_{i=1}^{n} i^2$<br>  行内求和display模式<code>\displaystyle \sum_{}^{}</code>：$\displaystyle \sum_{i=1}^{n} i^2$</p></li><li><p>求乘积<code>\prod_{}^{}</code>：<br>  $$ \prod_{i=1}^{n} a_i $$</p></li><li><p>分数<code>\frac{up}{down}</code>：<br>  $$ x_1,x_2 = \frac{b^2 \pm 4ac}{2a} $$</p></li><li><p>根号<code>\sqrt</code>：<br>  $$ r = \sqrt{x^2+y^2} $$</p><p>  多次根号<code>\sqrt[n]</code>： $$ x^{2/3} = \sqrt[3]{x^2} $$</p></li></ul><h3 id="编号"><a href="#编号" class="headerlink" title="编号"></a>编号</h3><ul><li><p>插入编号：<br>  使用<code>\tag</code>指令指定公式的具体编号，并使用<code>\label</code>指令埋下锚点。如<code>y=x^2 \tag{1.5a} \label{eq:test}</code>：<br>  $$ y=x^2 \tag{1.5a}\label{eq:test} $$</p></li><li><p>引用编号：<br>  使用<code>\eqref</code>指令引用前面埋下的锚点，<code>\eqref{eq:test}</code>将显示为：<br>  $$ \eqref{eq:test} $$</p></li><li><p>带圆圈的数字：<br>  ① ② ③ ④ ⑤ ⑥ ⑦ ⑧ ⑨ ⑩<br>  ⑪ ⑫ ⑬ ⑭ ⑮ ⑯ ⑰ ⑱ ⑲ ⑳</p></li></ul><h2 id="4-方程组"><a href="#4-方程组" class="headerlink" title="4 方程组"></a>4 方程组</h2><ul><li>左侧花括号</li></ul><figure class="highlight tex"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">\<span class="name">begin</span><span class="string">{equation}</span></span></span><br><span class="line"><span class="comment">% \begin{equation*} 加'*'去掉公式编号</span></span><br><span class="line"><span class="tag">\<span class="name">left</span></span><span class="tag">\<span class="name">{</span></span></span><br><span class="line"><span class="tag">\<span class="name">begin</span><span class="string">{aligned}</span></span>     <span class="comment">%请使用'aligned'或'align*'</span></span><br><span class="line">2x + y &amp;= 1  <span class="tag">\<span class="name">\</span></span>     <span class="comment">%加'&amp;'指定对齐位置</span></span><br><span class="line">2x + 2y &amp;= 2</span><br><span class="line"><span class="tag">\<span class="name">end</span><span class="string">{aligned}</span></span></span><br><span class="line"><span class="tag">\<span class="name">right</span></span>.</span><br><span class="line"><span class="tag">\<span class="name">end</span><span class="string">{equation}</span></span></span><br><span class="line"><span class="comment">% \end{equation*}   加'*'去掉公式编号</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 注意：在 markdown 环境下，某些特殊字符，如'\', '*'等，会首先被 markdown 语法转义，然后再被 Latex 转义。</span></span><br><span class="line"><span class="comment">% 因此有时候 '\{'需要写作'\\{'，'*'需要写作'\*'，'\\'需要写作'\\\\'等，视不同的解释环境而定</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight tex"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="formula">$$ <span class="tag">\<span class="name">begin</span><span class="string">{equation}</span></span></span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">left</span></span><span class="tag">\<span class="name">\</span><span class="string">{</span></span></span></span><br><span class="line"><span class="formula"><span class="tag"><span class="string">\begin{aligned}</span></span></span></span><br><span class="line"><span class="formula">2x + y &amp;= 1 <span class="tag">\<span class="name">\</span></span><span class="tag">\<span class="name">\</span></span></span></span><br><span class="line"><span class="formula">2x + 2y &amp;= 2</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">end</span><span class="string">{aligned}</span></span></span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">right</span></span>.</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">end</span><span class="string">{equation}</span></span> $$</span></span><br></pre></td></tr></tbody></table></figure><p><strong>注</strong>：如果各个方程需要在某个字符处对齐（如等号对齐），只需在所有要对齐的字符前加上 <code>&amp;</code> 符号。如果不需要公式编号，只需在宏包名称后加上 <code>*</code> 号。</p><ul><li>分情况讨论方程式</li></ul><figure class="highlight tex"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">f(x) =</span><br><span class="line"><span class="tag">\<span class="name">begin</span><span class="string">{cases}</span></span></span><br><span class="line">x^2 <span class="tag">\<span class="name">qquad</span></span> &amp; a <span class="tag">\<span class="name">gt</span></span> 0 <span class="tag">\<span class="name">\</span></span></span><br><span class="line">e^x <span class="tag">\<span class="name">qquad</span></span> &amp; a <span class="tag">\<span class="name">le</span></span> 0</span><br><span class="line"><span class="tag">\<span class="name">end</span><span class="string">{cases}</span></span></span><br></pre></td></tr></tbody></table></figure><p>$$f(x) = \begin{cases}<br>    x^2 \qquad &amp; a \gt 0 \\<br>    e^x \qquad &amp; a \le 0<br>    \end{cases} $$</p><p>$$ \begin{aligned}<br>    a &amp;= 1 \\<br>    bcd &amp;= 2<br>    \end{aligned} $$</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 使用技巧 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> LaTeX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>扫描转换算法</title>
      <link href="/article/37ba.html"/>
      <url>/article/37ba.html</url>
      
        <content type="html"><![CDATA[<p>DDA、中点画线、Bresenham算法</p><a id="more"></a><h2 id="1-直线扫描转换算法"><a href="#1-直线扫描转换算法" class="headerlink" title="1 直线扫描转换算法"></a>1 直线扫描转换算法</h2><h3 id="1-1-DDA算法"><a href="#1-1-DDA算法" class="headerlink" title="1.1 DDA算法"></a>1.1 DDA算法</h3><blockquote><p>Digital Differential Analyer</p></blockquote><p>在计算机光栅显示器上绘制一条直线$ y=kx+b $的本质是用一些离散的像素点去逼近这条直线，需要确定这些像素点的$ x $，$ y $坐标。<br><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020033101.jpg"></p><p>给出确定的两个端点$ \bigl(x_0,y_0\bigr) $和$ \bigl(x_1,y_1\bigr) $，即斜率$ k=\frac{y_1-y_0}{x_1-x_0} $<br>现假定$ x $已知，即从起点$ x_0 $开始，沿$ x $方向前进一个像素（步长=1），可以计算相应的$ y $值</p><blockquote><p>注：因为像素的坐标是整数，而斜率$k$是浮点数，所以对于计算出的$ y $值需要进行取整处理</p></blockquote><ol><li>基本思想：</li></ol><ul><li>$ k\le1 $时，对$ x $值计算相应的$ y $值（对$ y $取整），从而确定需要给那些像素着色</li><li>$ k&gt;1 $时，对$ y $值计算相应的$ x $值（对$ x $取整），从而确定需要给那些像素着色</li></ul><img width="200" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020033102.jpg"><ol start="2"><li>优化计算思想：增量思想</li></ol><ul><li>$ k\le1 $时,对于 $ y_i=kx_i+b $，$ y_{i+1}=kx_{i+1}+b=k(x_i+1)+b=y_i+k $，那么斜率$ k $即可看为前进一步的增量，这样就把将乘法运算变成了加法</li><li>$ k&gt;1 $时，取$ x_{i+1}=x_i+\frac{1}{k} $即可</li></ul><h4 id="1-1-1-代码"><a href="#1-1-1-代码" class="headerlink" title="1.1.1 代码"></a>1.1.1 代码</h4><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;GL\glut.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    glClearColor(<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>);  <span class="comment">// Set display-window color to white.</span></span><br><span class="line">    glMatrixMode(GL_PROJECTION);       <span class="comment">// Set projection parameters.</span></span><br><span class="line">    gluOrtho2D(<span class="number">0.0</span>, <span class="number">200.0</span>, <span class="number">0.0</span>, <span class="number">150.0</span>);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    数值微分方法画线</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">LineDDA</span><span class="params">(<span class="keyword">int</span> x1, <span class="keyword">int</span> y1, <span class="keyword">int</span> x2, <span class="keyword">int</span> y2)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    glColor3f(<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>);       <span class="comment">// 红色</span></span><br><span class="line">    glPointSize(<span class="number">2.0f</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">        两点重合尚未判断</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">int</span> dm = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">abs</span>(x2 - x1) &gt;= <span class="built_in">abs</span>(y2 - y1))</span><br><span class="line">    {</span><br><span class="line">        dm = <span class="built_in">abs</span>(x2 - x1);              <span class="comment">// x 为计长方向</span></span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    {</span><br><span class="line">        dm = <span class="built_in">abs</span>(y2 - y1);              <span class="comment">// y 为计长方向</span></span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">float</span> dx = (<span class="keyword">float</span>)(x2 - x1) / dm;   <span class="comment">// 当 x 为计长方向，dx = 1</span></span><br><span class="line">    <span class="keyword">float</span> dy = (<span class="keyword">float</span>)(y2 - y1) / dm;   <span class="comment">// 当 y 为计长方向，dy = 1</span></span><br><span class="line">    <span class="keyword">float</span> x = x1;</span><br><span class="line">    <span class="keyword">float</span> y = y1;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; dm; ++i)</span><br><span class="line">    {</span><br><span class="line">        glBegin(GL_POINTS);</span><br><span class="line">        glVertex2f((<span class="keyword">int</span>)x, (<span class="keyword">int</span>)y);</span><br><span class="line">        glEnd();</span><br><span class="line">        glFlush();</span><br><span class="line">        x += dx;</span><br><span class="line">        y += dy;</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    交换两个int 类型的变量的值</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap_value</span><span class="params">(<span class="keyword">int</span>* a, <span class="keyword">int</span>* b)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">int</span> tmp = *a;</span><br><span class="line">    *a = *b;</span><br><span class="line">    *b = tmp;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 窗口大小改变时调用的登记函数</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ChangeSize</span><span class="params">(GLsizei w, GLsizei h)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (h == <span class="number">0</span>)     h = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置视区尺寸</span></span><br><span class="line">    glViewport(<span class="number">0</span>, <span class="number">0</span>, w, h);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重置坐标系统</span></span><br><span class="line">    glMatrixMode(GL_PROJECTION);</span><br><span class="line">    glLoadIdentity();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 建立修剪空间的范围</span></span><br><span class="line">    <span class="keyword">if</span> (w &lt;= h)</span><br><span class="line">        glOrtho(<span class="number">0.0f</span>, <span class="number">250.0f</span>, <span class="number">0.0f</span>, <span class="number">250.0f</span>*h / w, <span class="number">1.0</span>, <span class="number">-1.0</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        glOrtho(<span class="number">0.0f</span>, <span class="number">250.0f</span>*w / h, <span class="number">0.0f</span>, <span class="number">250.0f</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>);</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">display</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="comment">// 用当前背景色填充窗口，如果不写这句会残留之前的图像</span></span><br><span class="line">    glClear(GL_COLOR_BUFFER_BIT);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> x1 = <span class="number">20</span>, y1 = <span class="number">20</span>, x2 = <span class="number">160</span>, y2 = <span class="number">80</span>;</span><br><span class="line">    LineDDA(x1, y1, x2, y2);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    glutInit(&amp;argc, argv);</span><br><span class="line">    glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB);</span><br><span class="line">    glutInitWindowPosition(<span class="number">200</span>, <span class="number">200</span>);</span><br><span class="line">    glutInitWindowSize(<span class="number">400</span>, <span class="number">400</span>);</span><br><span class="line">    glutCreateWindow(<span class="string">"Line"</span>);</span><br><span class="line">    glutDisplayFunc(display);</span><br><span class="line">    glutReshapeFunc(ChangeSize);</span><br><span class="line">    init();</span><br><span class="line">    glutMainLoop();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h4 id="1-1-2-运行结果"><a href="#1-1-2-运行结果" class="headerlink" title="1.1.2 运行结果"></a>1.1.2 运行结果</h4><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040305.jpg"><h3 id="1-2-中点画线算法"><a href="#1-2-中点画线算法" class="headerlink" title="1.2 中点画线算法"></a>1.2 中点画线算法</h3><blockquote><p>效率上最快</p></blockquote><p>基本思想：采用直线的一般式方程$ F(x,y)=Ax+By+C=0 $<br>$ F(x,y)=Ax+By+C=0\le\left|k\right|\le1 $,$ x_i+1\rightarrow y_i \rightarrow \begin{cases}y_i \\y_i +1\end{cases}$，把浮点运算改成整数加法。</p><p>假定$ 0\le\left|k\right|\le1 $，沿$x$方向前进一个像素，$x_i \rightarrow x_i+1$，计算出$y_i \rightarrow \begin{cases}y_i \\y_i +1\end{cases} $.</p><ul><li>当中点$M$在$Q$下方时，则$P_u$离直线近一些，选择$P_u$作为下一个像素点</li><li>当中点$M$在$Q$上方时，则$P_d$离直线近一些，选择$P_d$作为下一个像素点</li></ul><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040301.jpg"><p>判断$M$与$Q$的位置关系：将$M$点坐标代入方程有$d_i=A(x_i+1)+B(y_i+0.5)+C$</p><ul><li>当$d_i\geq0$时选择$P_d$</li><li>当$d_i&lt;0$时选择$P_u$</li></ul><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040302.jpg"><p>优化计算：$p(x_i,y_i)$在直线上即$Ax_i+By_i+C=0$，初值$d_0=F\left(x_i+1,y_i+0.5\right)=A+0.5B$</p><ul><li><p>当选择了$P_u$作为像素点时，$d_0=F\left(x_i+1,y_i+0.5\right)$；$d_1=F\left(x_i+2,y_i+1.5\right)=d_0+A+B$</p></li><li><p>当选择了$P_d$作为像素点时，$d_0=F\left(x_i+1,y_i+0.5\right)$；$d_1=F\left(x_i+2,y_i+0.5\right)=d_0+A$</p></li></ul><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040303.jpg"><h2 id="Bresenham算法"><a href="#Bresenham算法" class="headerlink" title="Bresenham算法"></a>Bresenham算法</h2><blockquote><p>适用范围扩大，与方程无关不仅限于画直线</p></blockquote><h3 id="1-3-理论"><a href="#1-3-理论" class="headerlink" title="1.3 理论"></a>1.3 理论</h3><p>DDA算法在编码实现比较容易，但是每生成一个像素都要用到一次浮点加法运算，Bresenham的线段光栅化算法可以避免浮点运算。</p><ol><li>假设线段的起点$ \bigl(x_0,y_0\bigr) $和终点$ \bigl(x_1,y_1\bigr) $的坐标值都是整数，且斜率满足$ 0\leq m\leq 1 $</li><li>在线段扫描转换过程某一步中，假定已知$ (i+\frac{1}{2},j+\frac{1}{2}) $的像素。该线段所在的直线方程为$ y=mx+h $,当$ x=i+\frac{1}{2} $时，该直线与$ (i+\frac{1}{2},j+\frac{1}{2}) $处像素的垂直扫描线的实际交点是在垂直扫描线上位于该像素的半个像素内部的某一点（假定像素中心位置的坐标值位于两个整数之间），否则，对该实际交点进行四舍五入处理后不可能得到当前这个像素。</li></ol><img width="200" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020033103.jpg"><ol start="3"><li>可以引入判定变量$ d=b-a $来判断下一个像素点的坐标，其中，$ a $和$ b $<br>表示在$x=i+\frac{3}{2}$号处，该线段分别离上方候选像素和下方候选像素的距离，如果$ d&lt;0 $，那么线段靠近下方的像素，所以选择位于$ (x=i+\frac{3}{2},j+\frac{1}{2}) $处的下方像素；否则，应选择位于$ (i+\frac{3}{2},j+\frac{3}{2}) $处的上方像素.</li></ol><img width="200" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020033104.jpg"><h4 id="1-3-1-优化"><a href="#1-3-1-优化" class="headerlink" title="1.3.1 优化"></a>1.3.1 优化</h4><blockquote><p>定点运算代替浮点运算</p></blockquote><p>令$ d=(x_2-x_1)(b-a)=\Delta x(b-a) $，用线段的方程将$ a $和$ b $的值代入，结合$ m=\frac{y_2-y_1}{x_2-x_1} $，$ h=y_2-mx_2 $，运算得$ d $为一整数（用到多次定点运算）</p><blockquote><p>使该算法成为增量算法</p></blockquote><p>假定$ d_k $是$ x＝k+\frac{1}{2} $号时对应的$ d $值。我们希望计算$ d_k $的增量形$ d_k+1 $，它是$ x=k+\frac{3}{2} $号时对应的$ d $值。</p><p>通过观察上方候选像素与直线之间的距离$ a $的值，当$ x=k+\frac{1}{2} $处像素的 $ y $坐标相对于前一个像素增加1，$ a $值增加$ 1-m $，或者减少$ m $。同理，当增加$ x $的值时，$ b $值要么增加$ m $，要么减少$ 1-m $。</p><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020033107.jpg"><p>其中：<br>        $$d_{k+1}=\begin{cases}<br>    d_k+2\Delta y \qquad &amp; d_k&lt;0\\<br>    2(\Delta y-\Delta x)\qquad &amp; d_k\geq0<br>    \end{cases} $$</p><h4 id="1-3-2-代码"><a href="#1-3-2-代码" class="headerlink" title="1.3.2 代码"></a>1.3.2 代码</h4><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;windows.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;GL/glu.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;GL/gl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;GL\glut.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    glClearColor(<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>);  <span class="comment">// Set display-window color to white.</span></span><br><span class="line">    glMatrixMode(GL_PROJECTION);       <span class="comment">// Set projection parameters.</span></span><br><span class="line">    gluOrtho2D(<span class="number">0.0</span>, <span class="number">200.0</span>, <span class="number">0.0</span>, <span class="number">150.0</span>);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    交换两个int 类型的变量的值</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap_value</span><span class="params">(<span class="keyword">int</span>* a, <span class="keyword">int</span>* b)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">int</span> tmp = *a;</span><br><span class="line">    *a = *b;</span><br><span class="line">    *b = tmp;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    Bresenham 画线法</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">LineBres</span><span class="params">(<span class="keyword">int</span> x1, <span class="keyword">int</span> y1, <span class="keyword">int</span> x2, <span class="keyword">int</span> y2)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    glColor3f(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>);       <span class="comment">// 蓝色</span></span><br><span class="line">    glPointSize(<span class="number">2.0f</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> dx = <span class="built_in">abs</span>(x2 - x1);</span><br><span class="line">    <span class="keyword">int</span> dy = <span class="built_in">abs</span>(y2 - y1);</span><br><span class="line">    <span class="comment">// 两点重合</span></span><br><span class="line">    <span class="keyword">if</span> (dx == <span class="number">0</span> &amp;&amp; dy == <span class="number">0</span>)</span><br><span class="line">    {</span><br><span class="line">        glBegin(GL_POINTS);</span><br><span class="line">            glVertex2f(x1, y1);</span><br><span class="line">        glEnd();</span><br><span class="line">        glFlush();</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> flag = <span class="number">0</span>;       <span class="comment">// 将斜率变换到 0 &lt;= |k| &lt;= 1 区间</span></span><br><span class="line">    <span class="keyword">if</span> (dx &lt; dy)</span><br><span class="line">    {</span><br><span class="line">        flag = <span class="number">1</span>;</span><br><span class="line">        swap_value(&amp;x1, &amp;y1);</span><br><span class="line">        swap_value(&amp;x2, &amp;y2);</span><br><span class="line">        swap_value(&amp;dx, &amp;dy);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> tx = (x2 - x1) &gt; <span class="number">0</span> ? <span class="number">1</span> : <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> ty = (y2 - y1) &gt; <span class="number">0</span> ? <span class="number">1</span> : <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> curx = x1;</span><br><span class="line">    <span class="keyword">int</span> cury = y1;</span><br><span class="line">    <span class="keyword">int</span> dS = <span class="number">2</span> * dy;</span><br><span class="line">    <span class="keyword">int</span> dT = <span class="number">2</span> * (dy - dx);</span><br><span class="line">    <span class="keyword">int</span> d = dS - dx;</span><br><span class="line">    <span class="keyword">while</span> (curx != x2)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">if</span> (d &lt; <span class="number">0</span>)</span><br><span class="line">            d += dS;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        {</span><br><span class="line">            cury += ty;</span><br><span class="line">            d += dT;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (flag)</span><br><span class="line">        {</span><br><span class="line">            glBegin(GL_POINTS);</span><br><span class="line">                glVertex2f(cury, curx);</span><br><span class="line">            glEnd();</span><br><span class="line">            glFlush();</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        {</span><br><span class="line">            glBegin(GL_POINTS);</span><br><span class="line">                glVertex2f(curx, cury);</span><br><span class="line">            glEnd();</span><br><span class="line">            glFlush();</span><br><span class="line">        }</span><br><span class="line">        curx += tx;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 窗口大小改变时调用的登记函数</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ChangeSize</span><span class="params">(GLsizei w, GLsizei h)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (h == <span class="number">0</span>)     h = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置视区尺寸</span></span><br><span class="line">    glViewport(<span class="number">0</span>, <span class="number">0</span>, w, h);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重置坐标系统</span></span><br><span class="line">    glMatrixMode(GL_PROJECTION);</span><br><span class="line">    glLoadIdentity();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 建立修剪空间的范围</span></span><br><span class="line">    <span class="keyword">if</span> (w &lt;= h)</span><br><span class="line">        glOrtho(<span class="number">0.0f</span>, <span class="number">250.0f</span>, <span class="number">0.0f</span>, <span class="number">250.0f</span>*h / w, <span class="number">1.0</span>, <span class="number">-1.0</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        glOrtho(<span class="number">0.0f</span>, <span class="number">250.0f</span>*w / h, <span class="number">0.0f</span>, <span class="number">250.0f</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>);</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">display</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="comment">// 用当前背景色填充窗口，如果不写这句会残留之前的图像</span></span><br><span class="line">    glClear(GL_COLOR_BUFFER_BIT);</span><br><span class="line">    <span class="keyword">int</span> x12 = <span class="number">20</span>, y12 = <span class="number">40</span>, x22 = <span class="number">160</span>, y22 = <span class="number">100</span>;</span><br><span class="line">    LineBres(x12, y12, x22, y22);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    glutInit(&amp;argc, argv);</span><br><span class="line">    glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB);</span><br><span class="line">    glutInitWindowPosition(<span class="number">200</span>, <span class="number">200</span>);</span><br><span class="line">    glutInitWindowSize(<span class="number">400</span>, <span class="number">400</span>);</span><br><span class="line">    glutCreateWindow(<span class="string">"Line"</span>);</span><br><span class="line">    glutDisplayFunc(display);</span><br><span class="line">    glutReshapeFunc(ChangeSize);</span><br><span class="line">    init();</span><br><span class="line">    glutMainLoop();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>####1.3.3 运行结果<br><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040306.jpg"></p><h2 id="2-多边形扫描转化算法"><a href="#2-多边形扫描转化算法" class="headerlink" title="2 多边形扫描转化算法"></a>2 多边形扫描转化算法</h2><p>多边形分为凸多边形，凹多边形（任意两顶点间的连线有不在多边形内的部分）含内环的多边形</p><h3 id="2-1-X扫描线算法"><a href="#2-1-X扫描线算法" class="headerlink" title="2.1 X扫描线算法"></a>2.1 X扫描线算法</h3><blockquote><p>多边形扫描转换指的是把多边形的顶点表示转换为点阵表示</p></blockquote><ol><li>基本思想：按扫描线的顺序，计算扫描线与多边形的相交区间，再用要求的颜色显示这些区间的像素，完成填充工作。端点即为扫描线与多边形边界线的交点。</li><li>算法步骤：</li></ol><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20200416202043.png"><p>（1） 确定多边形所占有的最大扫描数，得到多边形顶点的最小和最大值<br>（2） 从 $y=y_{min}$ 到 $y=y_{max}$ 每次用一条扫描线进行填充<br>（3） 扫描线的填充过程：求交排序（交点按递增顺序排）$\to$交点配对（偶数个）$\to$区间填色</p><ol start="3"><li>当扫描线与某一顶点相交时，交点的取舍问题处理办法为：<br>共享顶点的两条边分别落在扫描线左右两边，交点只算1个<br>共享顶点的两条边的另外两个端点 值大于顶点 值，交点算2个，否则算0个<br>缺点：扫描线与多边形各边求交很麻烦</li></ol><h3 id="2-2-改进的X扫描线算法（不求交）"><a href="#2-2-改进的X扫描线算法（不求交）" class="headerlink" title="2.2 改进的X扫描线算法（不求交）"></a>2.2 改进的X扫描线算法（不求交）</h3><ol><li><p>改进求交方法：<br>（1）只与有效边求交；<br>（2）扫描线的连贯性——当前扫描线与各边交点顺序与下条扫描线与各边交点顺序雷同;<br>（3）多边形的连贯性——某条边与当前扫描线相交时很可能也与下一条扫描线相交.</p></li><li><p>引进数据结构：<br>（1）活性边表——与当前扫描线相交的边叫做活性边，并把他们按与扫描线交点，坐标递增的顺序存放在一个链表中<br>（2）结点内容——$x$（交点坐标）；$\delta{x}$（相邻扫描线的增量）；$y_{max}$（最高扫描线的坐标值）</p></li></ol><p>$$ x  \to \delta x \to y_{max} \to \text { Next } $$</p><p> 扫描线一次向上移动1，即$y_{i+1}-y_{i}=1$ ，相交直线边斜率为$k$，即$x_{i+1}=x_{i}+\frac{1}{k}$<br>其中$\delta=\frac{1}{k}$ ，而$y_{max}$可以确定何时抛弃该有效边</p><ol start="3"><li>构建新边表：构造纵向链表，链表长度为多边形所占有的最大扫描线数<br>对扫描线出现的位置构造</li></ol><p>$$ y_{max} \to x_{min} \to \frac{1}{k} \to \text { Next } $$</p><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20200416204239.png"><p>注：边是否被抛弃，未抛弃则要注意 ，还要看是否有新边进来</p><h3 id="2-3-区域填充算法"><a href="#2-3-区域填充算法" class="headerlink" title="2.3 区域填充算法"></a>2.3 区域填充算法</h3><blockquote><p>要求区域内连通</p></blockquote><p>区域可分4连通（左上右下）和8连通（斜方向）区域</p><ol><li><p>简单四连通种子填充算法（区域填充递归算法）：<br>使用栈结构来实现：栈顶像素出栈$\to$将出栈像素置成要填充色$\to$按左上右下顺序将不在边界且未填充的像素入栈填充$\to$对最后一个入栈的像素重复上述操作</p></li><li><p>多边形扫描转换算法与区域填充算法的区别<br>区域填充需要一个种子点，根据区域连通性进行颜色扩散<br>扫描线转换是从边界出发采用多种形式的连贯性进行填充</p></li></ol><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://www.icourse163.org/learn/CAU-45006?tid=1450413503#/learn/content?type=detail&amp;id=1215011255" target="_blank" rel="noopener">中国大学MOOC</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图形图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Liang-Barsky裁剪算法</title>
      <link href="/article/fa12.html"/>
      <url>/article/fa12.html</url>
      
        <content type="html"><![CDATA[<p>Liang-Barsky算法的原理与代码</p><a id="more"></a><h2 id="Liang-Barsky裁剪算法"><a href="#Liang-Barsky裁剪算法" class="headerlink" title="Liang-Barsky裁剪算法"></a>Liang-Barsky裁剪算法</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><ol><li>用参数方程表示一条直线，用方程表示直线$P_{1}P_{2}$，其中$t$就是直线的斜率，$\mathrm{t} \in[0,1]:$</li></ol><p>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>x(t)=x_{1}+\left(x_{2}-x_{1}\right) t&amp;=x_{1}+t \Delta x  \qquad 0&lt;t&lt;1 \\<br>y(t)=y_{1}+\left(y_{2}-y_{1}\right) t&amp;=y_{1}+t \Delta y  \qquad 0&lt;t&lt;1<br>\end{aligned}<br>\right.<br>\end{equation} $$</p><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/img/20200413160753.png">裁剪区域内部可以表达为两个不等式：<p>$$\begin{aligned}<br>&amp;x_{L}&lt;x&lt;x_{R}\<br>&amp;y_{B}&lt;y&lt;y_{T}<br>\end{aligned}$$<br>把直线方程代入得到不等式：<br>$$ \begin{equation}<br>\left\{<br>\begin{aligned}<br>&amp; -t \Delta x&lt;x_{1}-x_{L} &amp; t \Delta x&lt;x_{R}-x_{1} \\<br>&amp; -t \Delta y&lt;y_{1}-y_{B} &amp; t \Delta y&lt;y_{T}-y_{1}<br>\end{aligned}<br>\right.<br>\end{equation} $$</p><p>即<br>$$t d_{i}&lt;q_{i} \quad i=1,2,3,4$$</p><p>$$\begin{array}{llll}<br>d_{1}=-\Delta x &amp; d_{2}=\Delta x &amp; d_{3}=-\Delta y &amp; d_{4}=\Delta y \\<br>q_{1}=x_{1}-x_{L} &amp; q_{2}=x_{R}-x_{1} &amp; q_{3}=y_{1}-y_{B} &amp; q_{4}=y_{T}-y_{1}<br>\end{array}$$</p><ol start="2"><li>把被裁剪的红色直线段看成是一条有方向的线段，把窗口的四条边分成两类：<br>入边：左边界和下边界——从裁剪框外向裁剪框内<br>出边：右边界和上边界——从裁剪框内向裁剪框外<br><img src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020032905.png" alt="出边与入边"></li><li>分情况讨论</li></ol><ul><li>$ d=0 :$<br>$ q&lt;0 $,  说明直线与裁剪框平行，并且位于裁剪框的外面，直线为不可见，可抛弃，直接结束；<br>$ q\geq0 $，说明直线在它所平行的窗口边界的内部，还需进一步计算确定直线是否在窗口内、外、或者相交</li><li>$ d&lt;0 $，说明直线是从裁剪边界的外部延伸到内部</li><li>$ d&gt;0 $, 说明直线是从裁剪边界的内部延伸到外部<br>对于$ d\neq0 $，可以利用式子计算直线与边界k的交点的参数$ u $。对于每条直线，可以计算直线位于裁剪窗口内线段的参数$ d_1 $和$ d_2 $.<br>$ d_1 $的值是由那些使得直线是从外部延伸到内部的窗口边界决定。对于这些边计算$ r_i=q_i/d_i $，$ d_i= max(r_i,0) $.<br>$ d_2 $的值是由那些使得直线是从内部延伸到窗口边界决定，$ d_2=min(r_i,1) $.<br>如果$ d_1 $$ d_2 $这条直线完全在窗口的外面，不可见，可抛弃，否则，根据参数$ u $的两个值，计算出裁剪后线段的端点.</li></ul><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><blockquote><p>代码的思路：画一个矩形，来作为一个裁剪窗口，然后画一条黄色的直线。如果直线没有经过矩形区域，则为黄色，如果穿过矩形区域，则使用Liang-Barskey算法来进行裁剪，裁剪之后，再进行画一条黑色的直线来覆盖。</p></blockquote><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*liang-barsky.cpp*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;Windows.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ww 640   <span class="comment">//屏幕的宽度</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> wh 480   <span class="comment">//屏幕的高度</span></span></span><br><span class="line"><span class="keyword">int</span> xs, ys, xb, yb;</span><br><span class="line"><span class="keyword">int</span> rl = <span class="number">200</span>, rb = <span class="number">200</span>;</span><br><span class="line"><span class="keyword">int</span> rr = <span class="number">400</span>, rt = <span class="number">400</span>;</span><br><span class="line"><span class="keyword">bool</span> first;</span><br><span class="line"><span class="comment">//画线的方法</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lineNew</span><span class="params">(<span class="keyword">int</span> x0, <span class="keyword">int</span> y0, <span class="keyword">int</span> xEnd, <span class="keyword">int</span> yEnd)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">  glClear(GL_COLOR_BUFFER_BIT);</span><br><span class="line">  glColor3f(<span class="number">1.0f</span>, <span class="number">1.0f</span>, <span class="number">0.0f</span>);  <span class="comment">//画黄色</span></span><br><span class="line">  glLineWidth(<span class="number">3</span>);</span><br><span class="line">  glBegin(GL_LINES);</span><br><span class="line">  glVertex2f(x0, y0);</span><br><span class="line">  glVertex2f(xEnd, yEnd);</span><br><span class="line">  glEnd();</span><br><span class="line"></span><br><span class="line">  glFlush();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myDisplay</span><span class="params">()</span> </span>{</span><br><span class="line"></span><br><span class="line">  glClear(GL_COLOR_BUFFER_BIT); <span class="comment">//清空颜色缓冲池</span></span><br><span class="line">  glColor3f(<span class="number">1.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>); <span class="comment">//设置绘图颜色</span></span><br><span class="line">  glRectf(rl,rb,rr,rt); <span class="comment">//绘制矩形</span></span><br><span class="line">  glFlush(); <span class="comment">//执行OpenGL指令列表中的指令</span></span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">ClipT</span><span class="params">(<span class="keyword">float</span> p, <span class="keyword">float</span> q, <span class="keyword">float</span> *u1, <span class="keyword">float</span> *u2)</span> </span>{</span><br><span class="line">  <span class="keyword">float</span> r;</span><br><span class="line">  <span class="keyword">if</span> (p &lt; <span class="number">0</span>) {</span><br><span class="line">    r = q / p;</span><br><span class="line">    <span class="keyword">if</span> (r &gt; *u2) {</span><br><span class="line">      <span class="keyword">return</span> FALSE;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">if</span> (r &gt; *u1) {</span><br><span class="line">      *u1 = r;</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (p &gt; <span class="number">0</span>) {</span><br><span class="line">    r = q / p;</span><br><span class="line">    <span class="keyword">if</span> (r &lt; *u1) {</span><br><span class="line">      <span class="keyword">return</span> FALSE;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">if</span> (r &lt; *u2) {</span><br><span class="line">      *u2 = r;</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">  <span class="keyword">else</span> {</span><br><span class="line">        <span class="keyword">return</span> q &gt;= <span class="number">0</span>;</span><br><span class="line">  }</span><br><span class="line">  <span class="keyword">return</span> TRUE;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">LB_LineClip</span><span class="params">(<span class="keyword">float</span> x1, <span class="keyword">float</span> y1, <span class="keyword">float</span> x2, <span class="keyword">float</span> y2, <span class="keyword">float</span> XL, <span class="keyword">float</span> XR, <span class="keyword">float</span> YB, <span class="keyword">float</span> YT)</span> </span>{</span><br><span class="line">  <span class="keyword">float</span> dx, dy, u1, u2;</span><br><span class="line">  u1 = <span class="number">0</span>;</span><br><span class="line">  u2 = <span class="number">1</span>;</span><br><span class="line">  dx = x2 - x1;</span><br><span class="line">  dy = y2 - y1;</span><br><span class="line">  <span class="keyword">if</span> (ClipT(-dx,x1-XL,&amp;u1,&amp;u2)) {</span><br><span class="line">    <span class="keyword">if</span> (ClipT(dx, XR - x1, &amp;u1, &amp;u2)) {</span><br><span class="line">      <span class="keyword">if</span> (ClipT(-dy, y1 - YB, &amp;u1, &amp;u2)) {</span><br><span class="line">        <span class="keyword">if</span> (ClipT(dy, YT - y1, &amp;u1, &amp;u2)) {</span><br><span class="line">          glLineWidth(<span class="number">3</span>);</span><br><span class="line">          glColor3f(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>);<span class="comment">//黑色</span></span><br><span class="line">          glBegin(GL_LINES);</span><br><span class="line"></span><br><span class="line">          glVertex2f(x1 + u1 * dx, y1 + u1 * dy);</span><br><span class="line">          glVertex2f(x1 + u2 * dx, y1 + u2 * dy);</span><br><span class="line">          glEnd();</span><br><span class="line">          glFlush();</span><br><span class="line">        }</span><br><span class="line">      }</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Init</span><span class="params">()</span> </span>{</span><br><span class="line">  glClearColor(<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>); <span class="comment">//即窗口的背景色</span></span><br><span class="line">  glClear(GL_COLOR_BUFFER_BIT);      <span class="comment">//清除颜色缓冲区，即窗口的背景色</span></span><br><span class="line">  glMatrixMode(GL_MODELVIEW);</span><br><span class="line">  glLoadIdentity();</span><br><span class="line">  gluOrtho2D(<span class="number">0.0</span>,ww, <span class="number">0.0</span>, wh);</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myMouse0</span><span class="params">(<span class="keyword">int</span> button, <span class="keyword">int</span> state, <span class="keyword">int</span> x, <span class="keyword">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">  glBegin(GL_POINTS);</span><br><span class="line">  <span class="keyword">if</span> (button == GLUT_LEFT_BUTTON)</span><br><span class="line">  {</span><br><span class="line">    <span class="keyword">if</span> (state == GLUT_DOWN) {</span><br><span class="line">      xs = x;</span><br><span class="line">      ys = wh - y;</span><br><span class="line">      glVertex2i(xs, ys);</span><br><span class="line">      first = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span> {</span><br><span class="line">      xb = x;</span><br><span class="line">      yb = wh - y;</span><br><span class="line">      first = <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">if</span> (first) {</span><br><span class="line">      lineNew(xs, ys, xb, yb);</span><br><span class="line">      LB_LineClip(xs, ys, xb, yb, rl, rr, rb, rt);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">  }</span><br><span class="line">  glEnd();</span><br><span class="line">  glFlush(); <span class="comment">//glFlush()清空缓冲区，将指令送往缓硬件立即执行</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">  glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB);</span><br><span class="line">  glutInitWindowSize(ww, wh);</span><br><span class="line">  glutInitWindowPosition(<span class="number">100</span>, <span class="number">150</span>);</span><br><span class="line">  glutCreateWindow(<span class="string">"Liang-Barskey"</span>);</span><br><span class="line">  Init();</span><br><span class="line">  glutDisplayFunc(myDisplay);</span><br><span class="line">  glutMouseFunc(myMouse0);</span><br><span class="line"></span><br><span class="line">  glutMainLoop();  <span class="comment">//持续显示，当窗口改变会重新绘制图形</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040310.jpg"><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ol><li><a href="https://blog.csdn.net/weixin_34202952/article/details/94224985?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">Liang-Barsky算法</a></li><li><a href="https://blog.csdn.net/pleasecallmewhy/article/details/8393445" target="_blank" rel="noopener">[OpenGL]计算机图形学：直线裁剪算法中Cohen-Sutherland算法和Liang-Barsky算法</a></li><li><a href="https://blog.csdn.net/ding_programmer/article/details/90414243?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">Liang-Barskey算法以及代码实现</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图形图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Liang-Barsky </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Git批量上传图片</title>
      <link href="/article/bb97.html"/>
      <url>/article/bb97.html</url>
      
        <content type="html"><![CDATA[<p>使用Git，构建GitHub图床，批量上传图片</p><a id="more"></a><h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><ol><li>首先登录/注册GitHub，新建一个仓库，填写好仓库名，仓库描述，初始化一个 README.md 描述文件，如图所示：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020032701.jpg" alt=""><br><img src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020032702.jpg" alt=""></p><ol start="2"><li>提交对应版本</li></ol><p><img src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020032704.jpg" alt=""><br><img src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020032705.jpg" alt=""></p><ol start="3"><li>然后找到对应的SSH key</li></ol><p><img src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020032703.jpg" alt=""></p><ol start="4"><li>利用git本地推送，默认在c盘，修改到d盘，初始化，克隆</li></ol><p><img src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020032706.jpg" alt=""></p><ol start="5"><li>本地新建一个images文件夹，随便存入一张test.jpg，提交，上传，推送</li></ol><p><img src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020032707.jpg" alt=""></p><h2 id="加速方法"><a href="#加速方法" class="headerlink" title="加速方法"></a>加速方法</h2><ol><li>创建一个 GitHub 仓库作为图床仓库，上传提交图片到仓库中（就是刚刚那个CDN仓库）</li><li>在要使用 GitHub 图床图片的地方将链接换为 <a href="https://cdn.jsdelivr.net/gh/{user}/{repo}/图片路径，" target="_blank" rel="noopener">https://cdn.jsdelivr.net/gh/{user}/{repo}/图片路径，</a> 如：<a href="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/test.jpg" target="_blank" rel="noopener">https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/test.jpg</a> 享受 jsDelivr 提供的全球 CDN 加速</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cohen-Sutherland编码裁剪</title>
      <link href="/article/f4dd.html"/>
      <url>/article/f4dd.html</url>
      
        <content type="html"><![CDATA[<p>一类编码裁剪算法</p><a id="more"></a><h2 id="Cohen-Sutherland编码裁剪算法"><a href="#Cohen-Sutherland编码裁剪算法" class="headerlink" title="Cohen-Sutherland编码裁剪算法"></a>Cohen-Sutherland编码裁剪算法</h2><h3 id="二维剪裁"><a href="#二维剪裁" class="headerlink" title="二维剪裁"></a>二维剪裁</h3><p>二维剪裁是在三维线段投影到投影平面之后才进行的，并且剪裁窗口是投影平面的一部分，该投影片面投影到屏幕的视口中，所有的值都可用实数表示。AB整段显示，CD整段不显示，EF和GH裁剪后显示</p><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020032901.jpg"><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>为避免求交（所在直线与剪裁窗口各条边的交点）运算，Cohen-Sutherland算法使用浮点减法与位操作相结合的方式代替大量浮点乘法和除法的裁剪算法。<br>该算法把裁剪窗口的四条边延长，将二维空间分割成9个区域，并赋予每个区域一个唯一的四位二进制数（编码），编码的4位分别代表端点位于窗口的上、下、右、左。</p><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020032902.jpg"><p><strong>考虑线段$ o_1 $$ o_2 $,对两端点的编码情况进行讨论，有四种情况：</strong></p><ol><li>若点$ o_1 $和$ o_2 $完全在裁剪窗口内，则保留该直线，如线段AB，然后进行光栅化处理</li><li>若点$ o_1 $和$ o_2 $有一个端点在裁剪窗口内，如线段CD，非零的端点编码说明线段与剪裁窗口的哪条边或拿两条边相交判断是否要进行两次求交运算</li><li>若$ o_1 $和$ o_2 $均不为0，对两个端点编码按位与运算，判断是否在同一侧，若是舍弃，如线段EF</li><li>如果直线段既不满足保留的条件，也不满足舍弃的条件？那么需要对直线段按交点进行分段，分段后判断直线是保留还是舍弃。（如GH与IJ)</li></ol><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020032903.jpg"><blockquote><p>当要处理的线段很多，而实际显示的线段很少时，Cohen-Sutherland算法非常有效</p></blockquote><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;gl/glut.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> LEFT_EDGE 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> RIGHT_EDGE 2</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BOTTOM_EDGE 4</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TOP_EDGE 8</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">LineGL</span><span class="params">(<span class="keyword">int</span> x0, <span class="keyword">int</span> y0, <span class="keyword">int</span> x1, <span class="keyword">int</span> y1)</span></span>{</span><br><span class="line">  glBegin(GL_LINES);</span><br><span class="line">  glColor3f(<span class="number">1.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>); glVertex2f(x0, y0);</span><br><span class="line">  glColor3f(<span class="number">0.0f</span>, <span class="number">1.0f</span>, <span class="number">0.0f</span>); glVertex2f(x1, y1);</span><br><span class="line">  glEnd();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Rectangle</span>{</span></span><br><span class="line">  <span class="keyword">float</span> xmin, xmax, ymin, ymax;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line">Rectangle rect;</span><br><span class="line"><span class="keyword">int</span> x0, y0, x1, y1;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">CompCode</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y, Rectangle rect)</span></span>{</span><br><span class="line">  <span class="keyword">int</span> code = <span class="number">0x00</span>;</span><br><span class="line">  <span class="keyword">if</span> (y &lt; rect.ymin)</span><br><span class="line">    code = code | <span class="number">4</span>;</span><br><span class="line">  <span class="keyword">if</span> (y&gt;rect.ymax)</span><br><span class="line">    code = code | <span class="number">8</span>;</span><br><span class="line">  <span class="keyword">if</span> (x&gt;rect.xmax)</span><br><span class="line">    code = code | <span class="number">2</span>;</span><br><span class="line">  <span class="keyword">if</span> (x&lt;rect.xmin)</span><br><span class="line">    code = code | <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">return</span> code;</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">cohensutherlandlineclip</span><span class="params">(Rectangle rect, <span class="keyword">int</span> &amp;x0, <span class="keyword">int</span> &amp;y0, <span class="keyword">int</span> &amp;x1, <span class="keyword">int</span> &amp;y1)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">  <span class="keyword">int</span> accept, done;</span><br><span class="line">  <span class="keyword">float</span> x, y;</span><br><span class="line">  accept = <span class="number">0</span>;</span><br><span class="line">  done = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> code0, code1, codeout;</span><br><span class="line">  code0 = CompCode(x0, y0, rect);</span><br><span class="line">  code1 = CompCode(x1, y1, rect);</span><br><span class="line">  <span class="keyword">do</span>{</span><br><span class="line">    <span class="keyword">if</span> (!(code0 | code1)){<span class="comment">//整条线段在窗口内</span></span><br><span class="line">      accept = <span class="number">1</span>;<span class="comment">//取之</span></span><br><span class="line">      done = <span class="number">1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (code0 &amp; code1)<span class="comment">//两个端点同在窗口一侧，弃之</span></span><br><span class="line">      done = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span>{<span class="comment">//线段与窗口存在交点</span></span><br><span class="line">      <span class="keyword">if</span> (code0 != <span class="number">0</span>)</span><br><span class="line">        codeout = code0;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        codeout = code1;</span><br><span class="line">            <span class="comment">//求交点</span></span><br><span class="line">      <span class="keyword">if</span> (codeout&amp;LEFT_EDGE){</span><br><span class="line">        y = y0 + (y1 - y0)*(rect.xmin - x0) / (x1 - x0);</span><br><span class="line">        x = (<span class="keyword">float</span>)rect.xmin;</span><br><span class="line">      }</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (codeout&amp;RIGHT_EDGE){</span><br><span class="line">        y = y0 + (y1 - y0)*(rect.xmax - x0) / (x1 - x0);</span><br><span class="line">        x = (<span class="keyword">float</span>)rect.xmax;</span><br><span class="line">      }</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (codeout&amp;BOTTOM_EDGE){</span><br><span class="line">        x = x0 + (x1 - x0)*(rect.ymin - y0) / (y1 - y0);</span><br><span class="line">        y = (<span class="keyword">float</span>)rect.ymin;</span><br><span class="line">      }</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (codeout&amp;TOP_EDGE){</span><br><span class="line">        x = x0 + (x1 - x0)*(rect.ymax - y0) / (y1 - y0);</span><br><span class="line">        y = (<span class="keyword">float</span>)rect.ymax;</span><br><span class="line">      }</span><br><span class="line">      <span class="comment">//舍弃在窗口外的部分线段</span></span><br><span class="line">      <span class="keyword">if</span> (codeout == code0){</span><br><span class="line">        x0 = x; y0 = y;</span><br><span class="line">        code0 = CompCode(x0, y0, rect);</span><br><span class="line">      }</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">      {</span><br><span class="line">        x1 = x; y1 = y;</span><br><span class="line">        code1 = CompCode(x1, y1, rect);</span><br><span class="line">      }</span><br><span class="line">    }</span><br><span class="line">  } <span class="keyword">while</span> (!done);</span><br><span class="line">    <span class="keyword">if</span> (accept)</span><br><span class="line">    LineGL(x0, y0, x1, y1);</span><br><span class="line">  <span class="keyword">else</span>{</span><br><span class="line">    x0 = <span class="number">0</span>; y = <span class="number">0</span>; x1 = <span class="number">0</span>; y1 = <span class="number">0</span>;</span><br><span class="line">    LineGL(x0, y0, x1, y1);</span><br><span class="line">  }</span><br><span class="line">  <span class="keyword">return</span> accept;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myDisplay</span><span class="params">()</span></span>{</span><br><span class="line">  glClear(GL_COLOR_BUFFER_BIT);</span><br><span class="line">  glColor3f(<span class="number">1.0f</span>, <span class="number">0.0f</span>, <span class="number">0.0f</span>);</span><br><span class="line">  glRectf(rect.xmin, rect.ymin, rect.xmax, rect.ymax);</span><br><span class="line"></span><br><span class="line">  LineGL(x0, y0, x1, y1);</span><br><span class="line"></span><br><span class="line">  glFlush();</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Init</span><span class="params">()</span></span>{</span><br><span class="line">  glClearColor(<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>);</span><br><span class="line">  glShadeModel(GL_FLAT);</span><br><span class="line"></span><br><span class="line">  rect.xmin = <span class="number">100</span>;</span><br><span class="line">  rect.xmax = <span class="number">300</span>;</span><br><span class="line">  rect.ymin = <span class="number">100</span>;</span><br><span class="line">  rect.ymax = <span class="number">300</span>;</span><br><span class="line"></span><br><span class="line">  x0 = <span class="number">450</span>, y0 = <span class="number">0</span>, x1 = <span class="number">0</span>, y1 = <span class="number">450</span>;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Press key 'c' to Clip!\nPress key 'r' to Restore!\n"</span>);</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Reshape</span><span class="params">(<span class="keyword">int</span> w, <span class="keyword">int</span> h)</span></span>{</span><br><span class="line">  glViewport(<span class="number">0</span>, <span class="number">0</span>, (GLsizei) w, (GLsizei) h);</span><br><span class="line">  glMatrixMode(GL_PROJECTION);</span><br><span class="line">  glLoadIdentity();</span><br><span class="line">  gluOrtho2D(<span class="number">0.0</span>, (GLdouble)w, <span class="number">0.0</span>, (GLdouble)h);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">keyboard</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">char</span> key, <span class="keyword">int</span> x, <span class="keyword">int</span> y)</span></span>{</span><br><span class="line">  <span class="keyword">switch</span> (key){</span><br><span class="line">  <span class="keyword">case</span> <span class="string">'c'</span>:</span><br><span class="line">    cohensutherlandlineclip(rect, x0, y0, x1, y1);</span><br><span class="line">    glutPostRedisplay();</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> <span class="string">'r'</span>:</span><br><span class="line">    Init();</span><br><span class="line">    glutPostRedisplay();</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> <span class="string">'x'</span>:</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span>{</span><br><span class="line">  glutInit(&amp;argc, argv);</span><br><span class="line">  glutInitDisplayMode(GLUT_RGB | GLUT_SINGLE);</span><br><span class="line">  glutInitWindowPosition(<span class="number">100</span>, <span class="number">100</span>);</span><br><span class="line">  glutInitWindowSize(<span class="number">640</span>,<span class="number">480</span>);</span><br><span class="line">  glutCreateWindow(<span class="string">"Cohen-Sutherland"</span>);</span><br><span class="line"></span><br><span class="line">  Init();</span><br><span class="line">  glutDisplayFunc(myDisplay);</span><br><span class="line">  glutReshapeFunc(Reshape);</span><br><span class="line">  glutKeyboardFunc(keyboard);</span><br><span class="line">  glutMainLoop();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h3><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040307.jpg"><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://blog.csdn.net/yao1373446012/article/details/78375644" target="_blank" rel="noopener">计算机图形学-直线裁剪Cohen-Sutherland编码裁剪算法</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图形图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenGL </tag>
            
            <tag> Cohen-Sutherland </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo+GitHub+matery博客美化教程</title>
      <link href="/article/138c.html"/>
      <url>/article/138c.html</url>
      
        <content type="html"><![CDATA[<p>更换主题模板，实现个性化定制</p><a id="more"></a><h2 id="定制"><a href="#定制" class="headerlink" title="定制"></a>定制</h2><p>我们要定制自己的博客的话，首先就要来了解一下Hexo博客的一些目录和文件的作用，以及如何平滑更换漂亮的主题模板并加入自己的定制源代码实现个性化定制</p><h3 id="1-Hexo相关目录文件"><a href="#1-Hexo相关目录文件" class="headerlink" title="1. Hexo相关目录文件"></a>1. Hexo相关目录文件</h3><h4 id="1-1-博客目录构成介绍"><a href="#1-1-博客目录构成介绍" class="headerlink" title="1.1 博客目录构成介绍"></a>1.1 博客目录构成介绍</h4><p>从上图可以看出，博客的目录结构如下：</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">- node_modules</span><br><span class="line">- public</span><br><span class="line">- scaffolds</span><br><span class="line">- source</span><br><span class="line">  - _data</span><br><span class="line">  - _posts</span><br><span class="line">  - about</span><br><span class="line">  - archives</span><br><span class="line">  - categories</span><br><span class="line">  - friends</span><br><span class="line">  - tags</span><br><span class="line">- themes</span><br></pre></td></tr></tbody></table></figure><p>node_modules是node.js各种库的目录，public是生成的网页文件目录，scaffolds里面就三个文件，存储着新文章和新页面的初始设置，source是我们最常用到的一个目录，里面存放着文章、各类页面、图像等文件，themes存放着主题文件，一般也用不到。<br>我们平时写文章只需要关注source/_posts这个文件夹就行了。</p><hr><h4 id="1-2-hexo基本配置"><a href="#1-2-hexo基本配置" class="headerlink" title="1.2 hexo基本配置"></a>1.2 hexo基本配置</h4><p>在文件根目录下的_config.yml，就是整个hexo框架的配置文件了。可以在里面修改大部分的配置。详细可参考官方的<a href="https://hexo.io/zh-cn/docs/configuration" target="_blank" rel="noopener">配置描述</a>。</p><h5 id="1-2-1-网站"><a href="#1-2-1-网站" class="headerlink" title="1.2.1 网站"></a>1.2.1 网站</h5><p>参数描述<code>title</code>网站标题<code>subtitle</code>网站副标题<code>description</code>网站描述<code>author</code>您的名字<code>language</code>网站使用的语言<code>timezone</code>网站时区。<code>Hexo</code>默认使用您电脑的时区。时区列表。比如说：<code>America/New_York</code>,<code>Japan</code>, 和<code>UTC</code>。</p><p>其中，<code>description</code>主要用于<code>SEO</code>，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。<code>author</code>参数用于主题显示文章的作者。</p><h5 id="1-2-2-网址"><a href="#1-2-2-网址" class="headerlink" title="1.2.2 网址"></a>1.2.2 网址</h5><p>参数描述<code>url</code>网址<code>root</code>网站根目录<code>permalink</code>文章的永久链接格式<code>permalink_defaults</code>永久链接中各部分的默认值<br>在这里，你需要把url改成你的网站域名。<br><code>permalink</code>，也就是你生成某个文章时的那个链接格式。<br>比如我新建一个文章叫<code>temp.md</code>，那么这个时候他自动生成的地址就是<a href="https://yoursite.com/2018/09/05/temp" target="_blank" rel="noopener">https://yoursite.com/2018/09/05/temp</a> 。<br>以下是官方给出的示例，关于链接的变量还有很多，需要的可以去官网上查找<a href="https://hexo.io/zh-cn/docs/permalinks" target="_blank" rel="noopener">永久链接</a>。</p><blockquote><p>参数结果:year/:month/:day/:title/2019/08/10/hello-world :year-:month-:day-:title.html 2019-08-10-hello-world.html :category/:titlefoo/bar/hello-world<br>再往下翻，中间这些都默认就好了。</p></blockquote><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">landscap</span></span><br></pre></td></tr></tbody></table></figure><p><code>theme</code>就是选择什么主题，也就是在<code>themes</code>这个文件夹下，在官网上有很多个主题，默认给你安装的是<code>lanscape</code>这个主题。当你需要更换主题时，在官网上下载，把主题的文件放在<code>themes</code>文件夹下，再修改这个主题参数就可以了。</p><h5 id="1-2-3-Front-matter"><a href="#1-2-3-Front-matter" class="headerlink" title="1.2.3 Front-matter"></a>1.2.3 Front-matter</h5><p><code>Front-matter</code>是<code>md</code>文件最上方以<code>---</code>分隔的区域，用于指定个别文件的变量，举例来说：</p><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">Hexo+Github博客搭建记录</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2019</span><span class="bullet">-08</span><span class="bullet">-10</span> <span class="number">21</span><span class="string">:44:44</span></span><br></pre></td></tr></tbody></table></figure><p>下是预先定义的参数，您可在模板中使用这些参数值并加以利用。<br>参数描述<code>layout</code>布局<code>title</code>标题<code>date</code>建立日期<code>updated</code>更新日期<code>comments</code>开启文章的评论功能<code>tags</code>标签（不适用于分页）<code>categories</code>分类（不适用于分页）<code>permalink</code>覆盖文章网址<br>其中，分类和标签需要区别一下，分类具有顺序性和层次性，也就是说<code>Foo</code>，<code>Bar</code>不等于<code>Bar</code>，<code>Foo</code>；而标签没有顺序和层次。</p><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">Hexo+Github博客搭建记录</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2020</span><span class="bullet">-03</span><span class="bullet">-21</span> <span class="number">23</span><span class="string">:48:07</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">孔明</span></span><br><span class="line"><span class="attr">img:</span> <span class="string">/medias/banner/7.jpg</span></span><br><span class="line"><span class="attr">coverImg:</span> <span class="string">/medias/banner/7.jpg</span></span><br><span class="line"><span class="attr">top:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">cover:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">toc:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">password:</span> <span class="number">5</span><span class="string">f15b28ffe43f8be4f239bdd9b69af9d80dbafcb20a5f0df5d1677a120ae9110</span></span><br><span class="line"><span class="attr">mathjax:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">summary:</span> <span class="string">这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</span></span><br><span class="line"><span class="attr">tags:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">Hexo</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">Github</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">博客</span></span><br><span class="line"><span class="attr">categories:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">软件安装与配置</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></tbody></table></figure><h5 id="1-2-4-layout-布局"><a href="#1-2-4-layout-布局" class="headerlink" title="1.2.4 layout(布局)"></a>1.2.4 layout(布局)</h5><p><strong>1.2.4.1 post</strong><br>当你每一次使用代码</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new XXX</span><br></pre></td></tr></tbody></table></figure><p>它其实默认使用的是<code>post</code>这个布局，也就是在<code>source</code>文件夹下的<code>_post</code>里面。</p><p><code>Hexo</code>有三种默认布局：<code>post</code>、<code>page</code>和<code>draft</code>，它们分别对应不同的路径，而您自定义的其他布局和<code>post</code>相同，都将储存到<code>source/_posts</code>文件夹。</p><p>而new这个命令其实是：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new [layout] &lt;title&gt;</span><br></pre></td></tr></tbody></table></figure><p>只不过这个layout默认是post罢了。</p><p><strong>1.2.4.2 page</strong></p><p>如果你想另起一页，那么可以使用</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page newpage</span><br></pre></td></tr></tbody></table></figure><p>系统会自动给你在source文件夹下创建一个<code>newpage</code>文件夹，以及<code>newpage</code>文件夹中的<code>index.md</code>，这样你访问的<code>newpage</code>对应的链接就是<a href="https://xxx.xxx/newpage" target="_blank" rel="noopener">https://xxx.xxx/newpage</a></p><p><strong>1.2.4.3 draft</strong></p><p><code>draft</code>是草稿的意思，也就是你如果想写文章，又不希望被看到，那么可以</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new draft newdraft</span><br></pre></td></tr></tbody></table></figure><p>这样会在<code>source/_draft</code>中新建一个<code>newdraft.md</code>文件，如果你的草稿文件写的过程中，想要预览一下，那么可以使用</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo server --draft</span><br></pre></td></tr></tbody></table></figure><p>在本地端口中开启服务预览。<br>如果你的草稿文件写完了，想要发表到<code>post</code>中，</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo publish draft newdraft</span><br></pre></td></tr></tbody></table></figure><p>就会自动把<code>newdraft.md</code>发送到<code>post</code>中。</p><h3 id="2-更换主题"><a href="#2-更换主题" class="headerlink" title="2. 更换主题"></a>2. 更换主题</h3><p>我们在了解<code>Hexo</code>博客文件基础之后，知道主题文件就放在<code>themes</code>文件下，那么我们就可以去<code>Hexo</code>官网下载喜欢的主题，复制进去然后修改参数即可。<br>网上大多数主题都是github排名第一的<code>Next</code>主题，网上看到一个主题感觉还不错：<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank" rel="noopener">hexo-theme-matery</a>，地址在<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank" rel="noopener">传送门</a>。这个主题看着比较漂亮，并且响应式比较友好，点起来很舒服，功能也比较很多。</p><blockquote><p>特性：</p></blockquote><ul><li>简单漂亮，文章内容美观易读</li><li>Material Design 设计</li><li>响应式设计，博客在桌面端、平板、手机等设备上均能很好的展现</li><li>首页轮播文章及每天动态切换 Banner 图片</li><li>瀑布流式的博客文章列表（文章无特色图片时会有 24 张漂亮的图片代替）</li><li>时间轴式的归档页</li><li>词云的标签页和雷达图的分类页</li><li>丰富的关于我页面（包括关于我、文章统计图、我的项目、我的技能、相册等）</li><li>可自定义的数据的友情链接页面</li><li>支持文章置顶和文章打赏</li><li>支持 MathJax</li><li>TOC 目录</li><li>可设置复制文章内容时追加版权信息</li><li>可设置阅读文章时做密码验证</li><li>Gitalk、Gitment、Valine 和 Disqus 评论模块（推荐使用 Gitalk）</li><li>集成了不蒜子统计、谷歌分析（Google Analytics）和文章字数统计等功能</li><li>支持在首页的音乐播放和视频播放功能</li><li>他的介绍文档写得非常的详细，还有中英文两个版本。效果图如下：</li></ul><p>首先先按照文档教程安装一遍主题，然后是可以正常打开的，如果你是一般使用的话，基本没啥问题了。不过有些地方有些地方可以根据你自己的习惯和喜好修改一下， 下面记录一下我这个博客修改了的一些地方。</p><h4 id="2-1-新建文章模板修改"><a href="#2-1-新建文章模板修改" class="headerlink" title="2.1 新建文章模板修改"></a>2.1 新建文章模板修改</h4><p>首先为了新建文章方便，我们可以修改一下文章模板，建议将<code>/scaffolds/post.md</code>修改为如下代码：</p><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">{{</span> <span class="string">title</span> <span class="string">}}</span></span><br><span class="line"><span class="attr">date:</span> <span class="string">{{date</span> <span class="string">}}</span></span><br><span class="line"><span class="attr">author:</span></span><br><span class="line"><span class="attr">img:</span></span><br><span class="line"><span class="attr">coverImg:</span></span><br><span class="line"><span class="attr">top:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">cover:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">toc:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">mathjax:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">password:</span></span><br><span class="line"><span class="attr">summary:</span></span><br><span class="line"><span class="attr">tags:</span></span><br><span class="line"><span class="attr">categories:</span></span><br></pre></td></tr></tbody></table></figure><p>这样新建文章后 一些<code>Front-matter</code>参数不用你自己补充了，修改对应信息就可以了。</p><h4 id="2-2-添加404页面"><a href="#2-2-添加404页面" class="headerlink" title="2.2 添加404页面"></a>2.2 添加404页面</h4><p>原来的主题没有<code>404</code>页面，我们加一个。首先在<code>/source/</code>目录下新建一个<code>404.md</code>，内容如下：</p><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="number">404</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2019</span><span class="bullet">-08</span><span class="bullet">-5</span> <span class="number">16</span><span class="string">:41:10</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">"404"</span></span><br><span class="line"><span class="attr">layout:</span> <span class="string">"404"</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">"Oops～，我崩溃了！找不到你想要的页面 :("</span></span><br></pre></td></tr></tbody></table></figure><p>然后在/themes/matery/layout/目录下新建一个404.ejs文件，内容如下：</p><figure class="highlight js"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&lt;style type=<span class="string">"text/css"</span>&gt;</span><br><span class="line">    <span class="comment">/* don't remove. */</span></span><br><span class="line">    .about-cover {</span><br><span class="line">        height: <span class="number">75</span>vh;</span><br><span class="line">    }</span><br><span class="line">&lt;<span class="regexp">/style&gt;</span></span><br><span class="line"><span class="regexp"></span></span><br><span class="line"><span class="regexp">&lt;div class="bg-cover pd-header about-cover"&gt;</span></span><br><span class="line"><span class="regexp">    &lt;div class="container"&gt;</span></span><br><span class="line"><span class="regexp">        &lt;div class="row"&gt;</span></span><br><span class="line"><span class="regexp">            &lt;div class="col s10 offset-s1 m8 offset-m2 l8 offset-l2"&gt;</span></span><br><span class="line"><span class="regexp">                &lt;div class="brand"&gt;</span></span><br><span class="line"><span class="regexp">                    &lt;div class="title center-align"&gt;</span></span><br><span class="line"><span class="regexp">                        404</span></span><br><span class="line"><span class="regexp">                    &lt;/</span>div&gt;</span><br><span class="line">                    &lt;div <span class="class"><span class="keyword">class</span></span>=<span class="string">"description center-align"</span>&gt;</span><br><span class="line">                        &lt;%= page.description %&gt;</span><br><span class="line">                    &lt;<span class="regexp">/div&gt;</span></span><br><span class="line"><span class="regexp">                &lt;/</span>div&gt;</span><br><span class="line">            &lt;<span class="regexp">/div&gt;</span></span><br><span class="line"><span class="regexp">        &lt;/</span>div&gt;</span><br><span class="line">    &lt;<span class="regexp">/div&gt;</span></span><br><span class="line"><span class="regexp">&lt;/</span>div&gt;</span><br><span class="line"></span><br><span class="line">&lt;script&gt;</span><br><span class="line">    <span class="comment">// 每天切换 banner 图.  Switch banner image every day.</span></span><br><span class="line">    $(<span class="string">'.bg-cover'</span>).css(<span class="string">'background-image'</span>, <span class="string">'url(/medias/banner/'</span> + <span class="keyword">new</span> <span class="built_in">Date</span>().getDay() + <span class="string">'.jpg)'</span>);</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></tbody></table></figure><h4 id="2-3-关于页面增加简历"><a href="#2-3-关于页面增加简历" class="headerlink" title="2.3 关于页面增加简历"></a>2.3 关于页面增加简历</h4><p>修改<code>/themes/matery/layout/about.ejs</code>，找到<code>&lt;div class="card"&gt;</code>标签，然后找到它对应的<code>&lt;/div&gt;</code>标签，接在后面新增一个<code>card</code>，语句如下：</p><figure class="highlight applescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"card"</span>&gt;</span><br><span class="line">    &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"card-content"</span>&gt;</span><br><span class="line">        &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"card-content article-card-content"</span>&gt;</span><br><span class="line">                &lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"title center-align"</span> data-aos=<span class="string">"zoom-in-up"</span>&gt;</span><br><span class="line">                    &lt;i <span class="built_in">class</span>=<span class="string">"fa fa-address-book"</span>&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;&lt;%- __('myCV') %&gt;</span><br><span class="line">                &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">                &lt;<span class="keyword">div</span> <span class="built_in">id</span>=<span class="string">"articleContent"</span> data-aos=<span class="string">"fade-up"</span>&gt;</span><br><span class="line">                    &lt;%- page.content %&gt;</span><br><span class="line">                &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">        &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">    &lt;/<span class="keyword">div</span>&gt;</span><br><span class="line">&lt;/<span class="keyword">div</span>&gt;</span><br></pre></td></tr></tbody></table></figure><p>这样就会多出一张<code>card</code>，然后可以在<code>/source/about/index.md</code>下面写上你的简历了，当然这里的位置随你自己设置，你也可以把简历作为第一个<code>card</code>。</p><h4 id="2-4-数学公式渲染和代码高亮"><a href="#2-4-数学公式渲染和代码高亮" class="headerlink" title="2.4 数学公式渲染和代码高亮"></a>2.4 数学公式渲染和代码高亮</h4><h5 id="2-4-1-解决mathjax与代码高亮的冲突"><a href="#2-4-1-解决mathjax与代码高亮的冲突" class="headerlink" title="2.4.1 解决mathjax与代码高亮的冲突"></a>2.4.1 解决mathjax与代码高亮的冲突</h5><p>如果你按照教程安装了代码高亮插件hexo-prism-plugin，单独使用是没有问题的，但如果你又使用了mathjax，并且按照网上教程，安装kramed插件并修改了js文件里的正则表达式（为了解决markdown和mathjax的语法冲突），那你的代码就无法高亮了。解决方法很简单，别用kramed插件了，还用原来自带的marked插件，直接改它的正则表达式就行了。</p><h5 id="2-4-2-加数学公式显示"><a href="#2-4-2-加数学公式显示" class="headerlink" title="2.4.2 加数学公式显示"></a>2.4.2 加数学公式显示</h5><p>打开<code>/themes/matery/layout</code>中的<code>post.ejs</code>文件，在最下方粘贴如下代码：</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js"&gt;&lt;/script&gt;</span><br></pre></td></tr></tbody></table></figure><p>由于<code>markdown</code>语法与<code>mathjax</code>语法存在冲突，所以还需要修改源文件。<br>打开<code>/node_modules/marked/lib</code>中的<code>marked.js</code>文件，第539行的<code>escape:</code>处替换成：</p><figure class="highlight markdown"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">escape: /^$[<span class="string">`*\[\</span>](<span class="link"></span>)#$+\-.!_&gt;])/</span><br></pre></td></tr></tbody></table></figure><p>第553行的em:处替换成：</p><figure class="highlight taggerscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">em: /^<span class="symbol">\*</span>((?:<span class="symbol">\*</span><span class="symbol">\*</span>|[<span class="symbol">\s</span><span class="symbol">\S</span>])+?)<span class="symbol">\*</span>(?!<span class="symbol">\*</span>)/</span><br></pre></td></tr></tbody></table></figure><p>这时在文章里写数学公式基本没有问题了，但是要注意：<br><strong>数学公式中如果出现了连续两个{，中间一定要加空格！</strong></p><p>举个例子:<br>行内公式：$y=f(x)$<br>代码：</p><figure class="highlight gams"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"><span class="meta-keyword">$y</span> = f(x)$</span></span><br></pre></td></tr></tbody></table></figure><p>行间公式：<br>\[y = {f_{ {g_1}}}(x)\]<br>代码：</p><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">\\[y</span> = {f_{ {g_1}}}(x)<span class="string">\\]</span></span><br></pre></td></tr></tbody></table></figure><blockquote><p>注意上面花括号之间有空格！</p></blockquote><h4 id="2-5-增加建站时间"><a href="#2-5-增加建站时间" class="headerlink" title="2.5 增加建站时间"></a>2.5 增加建站时间</h4><p>修改<code>/themes/matery/layout/_partial</code>中的<code>footer.ejs</code>，在最后加上：</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&lt;script language=javascript&gt;</span><br><span class="line">    <span class="function">function <span class="title">siteTime</span><span class="params">()</span> </span>{</span><br><span class="line">        window.setTimeout(<span class="string">"siteTime()"</span>, <span class="number">1000</span>);</span><br><span class="line">        <span class="keyword">var</span> seconds = <span class="number">1000</span>;</span><br><span class="line">        <span class="keyword">var</span> minutes = seconds * <span class="number">60</span>;</span><br><span class="line">        <span class="keyword">var</span> hours = minutes * <span class="number">60</span>;</span><br><span class="line">        <span class="keyword">var</span> days = hours * <span class="number">24</span>;</span><br><span class="line">        <span class="keyword">var</span> years = days * <span class="number">365</span>;</span><br><span class="line">        <span class="keyword">var</span> today = <span class="keyword">new</span> Date();</span><br><span class="line">        <span class="keyword">var</span> todayYear = today.getFullYear();</span><br><span class="line">        <span class="keyword">var</span> todayMonth = today.getMonth() + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">var</span> todayDate = today.getDate();</span><br><span class="line">        <span class="keyword">var</span> todayHour = today.getHours();</span><br><span class="line">        <span class="keyword">var</span> todayMinute = today.getMinutes();</span><br><span class="line">        <span class="keyword">var</span> todaySecond = today.getSeconds();</span><br><span class="line">        <span class="comment">/* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)</span></span><br><span class="line"><span class="comment">        year - 作为date对象的年份，为4位年份值</span></span><br><span class="line"><span class="comment">        month - 0-11之间的整数，做为date对象的月份</span></span><br><span class="line"><span class="comment">        day - 1-31之间的整数，做为date对象的天数</span></span><br><span class="line"><span class="comment">        hours - 0(午夜24点)-23之间的整数，做为date对象的小时数</span></span><br><span class="line"><span class="comment">        minutes - 0-59之间的整数，做为date对象的分钟数</span></span><br><span class="line"><span class="comment">        seconds - 0-59之间的整数，做为date对象的秒数</span></span><br><span class="line"><span class="comment">        microseconds - 0-999之间的整数，做为date对象的毫秒数 */</span></span><br><span class="line">        <span class="keyword">var</span> t1 = Date.UTC(<span class="number">2020</span>, <span class="number">03</span>, <span class="number">15</span>, <span class="number">00</span>, <span class="number">00</span>, <span class="number">00</span>); <span class="comment">//北京时间2020-3-15 00:00:00</span></span><br><span class="line">        <span class="keyword">var</span> t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);</span><br><span class="line">        <span class="keyword">var</span> diff = t2 - t1;</span><br><span class="line">        <span class="keyword">var</span> diffYears = Math.floor(diff / years);</span><br><span class="line">        <span class="keyword">var</span> diffDays = Math.floor((diff / days) - diffYears * <span class="number">365</span>);</span><br><span class="line">        <span class="keyword">var</span> diffHours = Math.floor((diff - (diffYears * <span class="number">365</span> + diffDays) * days) / hours);</span><br><span class="line">        <span class="keyword">var</span> diffMinutes = Math.floor((diff - (diffYears * <span class="number">365</span> + diffDays) * days - diffHours * hours) / minutes);</span><br><span class="line">        <span class="keyword">var</span> diffSeconds = Math.floor((diff - (diffYears * <span class="number">365</span> + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds);</span><br><span class="line">        document.getElementById(<span class="string">"sitetime"</span>).innerHTML = <span class="string">"本站已运行 "</span> +diffYears+<span class="string">" 年 "</span>+diffDays + <span class="string">" 天 "</span> + diffHours + <span class="string">" 小时 "</span> + diffMinutes + <span class="string">" 分钟 "</span> + diffSeconds + <span class="string">" 秒"</span>;</span><br><span class="line">    }<span class="comment">/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/</span></span><br><span class="line">    siteTime();</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></tbody></table></figure><p>然后在合适的地方（比如<code>copyright</code>声明后面）加上下面的代码就行了：</p><figure class="highlight html"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"sitetime"</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure><h4 id="2-6-修改不蒜子初始化计数"><a href="#2-6-修改不蒜子初始化计数" class="headerlink" title="2.6 修改不蒜子初始化计数"></a>2.6 修改不蒜子初始化计数</h4><p>因为不蒜子至今未开放注册，所以没办法在官网修改初始化，只能自己动手了。和上一条一样，我们在<code>/themes/matery/layout/_partial</code>里的<code>footer.ejs</code>文件最后加上：</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line">    $(document).ready(function (){</span><br><span class="line"></span><br><span class="line">        <span class="keyword">var</span> <span class="keyword">int</span> = setInterval(fixCount, <span class="number">50</span>);  <span class="comment">// 50ms周期检测函数</span></span><br><span class="line">        <span class="keyword">var</span> pvcountOffset = <span class="number">80000</span>;  <span class="comment">// 初始化首次数据</span></span><br><span class="line">        <span class="keyword">var</span> uvcountOffset = <span class="number">20000</span>;</span><br><span class="line"></span><br><span class="line">        <span class="function">function <span class="title">fixCount</span><span class="params">()</span> </span>{</span><br><span class="line">            <span class="keyword">if</span> (document.getElementById(<span class="string">"busuanzi_container_site_pv"</span>).style.display != <span class="string">"none"</span>) {</span><br><span class="line">                $(<span class="string">"#busuanzi_value_site_pv"</span>).html(parseInt($(<span class="string">"#busuanzi_value_site_pv"</span>).html()) + pvcountOffset);</span><br><span class="line">                clearInterval(<span class="keyword">int</span>);</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">if</span> ($(<span class="string">"#busuanzi_container_site_pv"</span>).css(<span class="string">"display"</span>) != <span class="string">"none"</span>) {</span><br><span class="line">                $(<span class="string">"#busuanzi_value_site_uv"</span>).html(parseInt($(<span class="string">"#busuanzi_value_site_uv"</span>).html()) + uvcountOffset); <span class="comment">// 加上初始数据</span></span><br><span class="line">                clearInterval(<span class="keyword">int</span>); <span class="comment">// 停止检测</span></span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    });</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></tbody></table></figure><p>然后把上面几行有段代码：</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;% <span class="keyword">if</span> (theme.busuanziStatistics &amp;&amp; theme.busuanziStatistics.totalTraffic) { %&gt;</span><br><span class="line">    &lt;span id=<span class="string">"busuanzi_container_site_pv"</span>&gt;</span><br><span class="line">        &lt;i class="fa fa-heart-o"&gt;&lt;/i&gt;</span><br><span class="line">        本站总访问量 &lt;span id="busuanzi_value_site_pv" class="white-color"&gt;&lt;/span&gt;</span><br><span class="line">    &lt;/span&gt;</span><br><span class="line">&lt;% } %&gt;</span><br><span class="line">&lt;% <span class="keyword">if</span> (theme.busuanziStatistics &amp;&amp; theme.busuanziStatistics.totalNumberOfvisitors) { %&gt;</span><br><span class="line">    &lt;span id=<span class="string">"busuanzi_container_site_uv"</span>&gt;</span><br><span class="line">        人次,&amp;nbsp;访客数 &lt;span id="busuanzi_value_site_uv" class="white-color"&gt;&lt;/span&gt; 人.</span><br><span class="line">    &lt;/span&gt;</span><br><span class="line">&lt;% } %&gt;</span><br></pre></td></tr></tbody></table></figure><p>修改为：</p><figure class="highlight erb"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">%</span></span></span><span class="ruby"> <span class="keyword">if</span> (theme.busuanziStatistics &amp;&amp; theme.busuanziStatistics.totalTraffic) { </span><span class="xml"><span class="tag">%&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"busuanzi_container_site_pv"</span> <span class="attr">style</span>=<span class="string">'display:none'</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fa fa-heart-o"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span></span><br><span class="line"><span class="xml">        本站总访问量 <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"busuanzi_value_site_pv"</span> <span class="attr">class</span>=<span class="string">"white-color"</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">%</span></span></span><span class="ruby"> } </span><span class="xml"><span class="tag">%&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">%</span></span></span><span class="ruby"> <span class="keyword">if</span> (theme.busuanziStatistics &amp;&amp; theme.busuanziStatistics.totalNumberOfvisitors) { </span><span class="xml"><span class="tag">%&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"busuanzi_container_site_uv"</span> <span class="attr">style</span>=<span class="string">'display:none'</span>&gt;</span></span></span><br><span class="line"><span class="xml">        人次,&amp;nbsp;访客数 <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"busuanzi_value_site_uv"</span> <span class="attr">class</span>=<span class="string">"white-color"</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span> 人.</span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">%</span></span></span><span class="ruby"> } </span><span class="xml"><span class="tag">%&gt;</span></span></span><br></pre></td></tr></tbody></table></figure><p>其实就是增加了两个</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### 2.7 添加动漫人物 ####</span><br><span class="line">其实三步就行了，不用像网上有些教程那么复杂。</span><br><span class="line"></span><br><span class="line">**第一步：**</span><br><span class="line">```bash</span><br><span class="line">npm install --save hexo-helper-live2d</span><br></pre></td></tr></tbody></table></figure><p></p><p><strong>第二步：</strong></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install live2d-widget-model-shizuku</span><br></pre></td></tr></tbody></table></figure><blockquote><p>这里的动漫模型可以改，只需要下载对应模型就行了，你可以<a href="https://github.com/stevenjoezhang/live2d-widget" target="_blank" rel="noopener">官方仓库</a>去看有哪些模型，下载你喜欢的就行。</p></blockquote><p><strong>第三步：</strong><br>在根目录配置文件中添加如下代码：</p><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">live2d:</span></span><br><span class="line"><span class="attr">    enable:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    scriptFrom:</span> <span class="string">local</span></span><br><span class="line"><span class="attr">    pluginRootPath:</span> <span class="string">live2dw/</span></span><br><span class="line"><span class="attr">    pluginJsPath:</span> <span class="string">lib/</span></span><br><span class="line"><span class="attr">    pluginModelPath:</span> <span class="string">assets/</span></span><br><span class="line"><span class="attr">    tagMode:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">    log:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">    model:</span></span><br><span class="line"><span class="attr">        use:</span> <span class="string">live2d-widget-model-shizuku</span></span><br><span class="line"><span class="attr">    display:</span></span><br><span class="line"><span class="attr">        position:</span> <span class="string">right</span></span><br><span class="line"><span class="attr">        width:</span> <span class="number">150</span></span><br><span class="line"><span class="attr">        height:</span> <span class="number">300</span></span><br><span class="line"><span class="attr">    mobile:</span></span><br><span class="line"><span class="attr">        show:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">    react:</span></span><br><span class="line"><span class="attr">        opacity:</span> <span class="number">0.7</span></span><br></pre></td></tr></tbody></table></figure><p>然后<code>hexo g</code>再<code>hexo s</code>就能预览出效果了，但是有个注意的地方，这个动漫人物最好不要和不蒜子同时使用，不然不蒜子会显示不出来。</p><blockquote><p>解决动漫人物和不蒜子不能同时使用的bug：<br>打开<code>themes\matery\layout\_partial</code>中的<code>footer.ejs</code>，将本站总访问量和访客数的代码改为如下：</p></blockquote><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;% <span class="keyword">if</span> (theme.busuanziStatistics &amp;&amp; theme.busuanziStatistics.totalTraffic) { %&gt;</span><br><span class="line">    &lt;span id="busuanzi_container_site_pv" style='display:none'&gt;&lt;/span&gt;</span><br><span class="line">        &lt;i class="fa fa-heart-o"&gt;&lt;/i&gt;</span><br><span class="line">        本站总访问量 &lt;span id="busuanzi_value_site_pv" class="white-color"&gt;&lt;/span&gt;</span><br><span class="line"></span><br><span class="line">&lt;% } %&gt;</span><br><span class="line"></span><br><span class="line">&lt;% <span class="keyword">if</span> (theme.busuanziStatistics &amp;&amp; theme.busuanziStatistics.totalNumberOfvisitors) { %&gt;</span><br><span class="line">    &lt;span id="busuanzi_container_site_uv" style='display:none'&gt;&lt;/span&gt;</span><br><span class="line">        人次,&amp;nbsp;访客数 &lt;span id="busuanzi_value_site_uv" class="white-color"&gt;&lt;/span&gt; 人.</span><br><span class="line"></span><br><span class="line">&lt;% } %&gt;</span><br></pre></td></tr></tbody></table></figure><p>变化就在下面两句，将源代码对应字段后面的<code>＜/span＞</code>写在前面了。</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;span <span class="attribute">id</span>=<span class="string">"busuanzi_container_site_pv"</span> <span class="attribute">style</span>=<span class="string">'display:none'</span>&gt;&lt;/span&gt;</span><br><span class="line">&lt;span <span class="attribute">id</span>=<span class="string">"busuanzi_container_site_uv"</span> <span class="attribute">style</span>=<span class="string">'display:none'</span>&gt;&lt;/span&gt;</span><br></pre></td></tr></tbody></table></figure><blockquote><p>发现按照上面改了过后，又出现一个新bug：文章头部的阅读次数不显示了，解决办法：<br>打开<code>themes\matery\layout\_partial</code>中的<code>post-detail.ejs</code>，找到对应代码字段：</p></blockquote><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;% <span class="keyword">if</span> (theme.busuanziStatistics &amp;&amp; theme.busuanziStatistics.enable) { %&gt;</span><br><span class="line">    &lt;div id=<span class="string">"busuanzi_container_page_pv"</span> class=<span class="string">"info-break-policy"</span>&gt;</span><br><span class="line">        &lt;i class="fa fa-eye fa-fw"&gt;&lt;/i&gt;&lt;%- __('readCount') %&gt;:&amp;nbsp;&amp;nbsp;</span><br><span class="line">        &lt;span id=<span class="string">"busuanzi_value_page_pv"</span> &gt;&lt;/span&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line"></span><br><span class="line">&lt;% } %&gt;</span><br></pre></td></tr></tbody></table></figure><p>修改为下面的就可以了：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;% <span class="keyword">if</span> (theme.busuanziStatistics &amp;&amp; theme.busuanziStatistics.enable) { %&gt;</span><br><span class="line">        &lt;span id="busuanzi_container_site_pv" style='display:none'&gt;&lt;/span&gt;</span><br><span class="line">        &lt;i <span class="class"><span class="keyword">class</span>="<span class="title">fa</span> <span class="title">fa</span>-<span class="title">eye</span> <span class="title">fa</span>-<span class="title">fw</span>"&gt;&lt;/i&gt;&lt;%- __('readCount') %&gt;:</span>&amp;nbsp;&amp;nbsp;</span><br><span class="line">        &lt;span id=<span class="string">"busuanzi_value_page_pv"</span> &gt;&lt;/span&gt;</span><br><span class="line"></span><br><span class="line">&lt;% } %&gt;</span><br></pre></td></tr></tbody></table></figure><h4 id="2-8-添加评论插件"><a href="#2-8-添加评论插件" class="headerlink" title="2.8 添加评论插件"></a>2.8 添加评论插件</h4><p>由于这个主题自带了<code>gittalk</code>、<code>gitment</code>、<code>valine</code>等评论插件，所以我们只需要对应插件参数就行了。</p><h4 id="2-9-添加网易云音乐BGM"><a href="#2-9-添加网易云音乐BGM" class="headerlink" title="2.9 添加网易云音乐BGM"></a>2.9 添加网易云音乐BGM</h4><p>写文章的时候，想插入一段<code>BGM</code>怎么办？<br>其实我们可以借助一些在线音乐的外链播放方式，首先打开网易云网页版，找到想听的歌曲，然后点击生成外链：</p><p><img src="https://raw.githubusercontent.com/shw2018/cdn/master/blog_files/img/Hexo-Blog-Tutorial/14.png" alt=""></p><p>可能你会遇到问题，比如点击生成外链会提示你由于版权原因，不能生成，那么可以用下面办法目前还有效，不知道后面会不会失效</p><ol><li>以Chrome为例，其他浏览器类似，打开歌单页面，在“生成外链播放器”上右击，点击审查元素（检查）<code>ctrl+shift+i</code>；</li><li>接着找到生成外链播放器这段文字直接双击复制前面的<code>/outchain/2/20707408/</code></li></ol><p><img src="https://raw.githubusercontent.com/shw2018/cdn/master/blog_files/img/Hexo-Blog-Tutorial/15.png" alt=""></p><ol start="3"><li>然后在浏览器地址栏修改歌单链接，示例：<a href="https://music.163.com/#//outchain/2/20707408/" target="_blank" rel="noopener">https://music.163.com/#//outchain/2/20707408/</a></li><li>然后就转到外链设置页面了。<br>复制如下代码，粘贴到文章对应位置就行了，为了美观，设置一下居中，具体代码如下：</li></ol><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;div align="middle"&gt;这里粘贴刚刚复制的代码&lt;/div&gt;</span><br></pre></td></tr></tbody></table></figure><h4 id="2-10-博客音乐板块"><a href="#2-10-博客音乐板块" class="headerlink" title="2.10 博客音乐板块"></a>2.10 博客音乐板块</h4><p>如果我们自己写博客写疲劳了，想放松一下听听歌又不想切出博客主页，那么我们可以自己定制一个博客音乐播放界面，把自己喜欢的歌曲都放进来，这里用到是Aplayer插件，但是歌曲来源需要我们自己定义，但是，因为各大音乐平台，由于版权原因，很多歌曲是不支持外链播放的，难道我们就必须每首歌下载然后上传云空间，再获取词曲封面么？这就比较麻烦了。其实不然，研究了半个小时，我发现可以采取下面的办法，很方便：</p><ul><li>首先我们找到网易云在线平台，任意找到一首歌点进去播放，可以在地址栏拿到音乐<code>ID</code>号</li><li>然后通过下面网址：<a href="https://music.163.com/song/media/outer/url?id=XXXXXX.mp3" target="_blank" rel="noopener">https://music.163.com/song/media/outer/url?id=XXXXXX.mp3</a> ， XXXXXX就是歌曲<code>ID</code>号，每一首歌我们只需要换掉这个<code>ID</code>号就行了,就相当于每一首的外链了</li><li>最后封面图也可以按<code>F12</code>去找页面元素的链接，填到对应的<code>musics.jason</code>文件中就可以，批量填入，听到好听的歌曲随时更换随时新增，很方便。<br>操作如下图：<br><img src="https://raw.githubusercontent.com/shw2018/cdn/master/blog_files/img/Hexo-Blog-Tutorial/17.png" alt=""></li></ul><h4 id="2-11-Valine评论模块修改"><a href="#2-11-Valine评论模块修改" class="headerlink" title="2.11 Valine评论模块修改"></a>2.11 Valine评论模块修改</h4><p><code>matery</code>主题已经集成<code>Valine</code>评论模块，在主题配置文件<code>.yml</code>中配置相应的字段就行了。<code>nable: true</code>，<code>XXX</code>字段是需要自己注册登录<code>leancloud</code>官网，创建应用然后获取<code>appId</code>和<code>appKey</code>，其他参数根据自己的需求修改就是，如下：</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">valine:</span><br><span class="line">  enable: <span class="literal">true</span></span><br><span class="line">  appId: XXXXXXXXXXXXXXXXXXXXX</span><br><span class="line">  appKey: XXXXXXXXXXXXXXXXXXXX</span><br><span class="line">  notify: <span class="literal">true</span></span><br><span class="line">  verify: <span class="literal">true</span></span><br><span class="line">  visitor: <span class="literal">true</span></span><br><span class="line">  avatar: 'mm' # Gravatar style : mm/identicon/monsterid/wavatar/retro/hide</span><br><span class="line">  pageSize: <span class="number">10</span></span><br><span class="line">  placeholder: 'just go go' # Comment Box placeholder</span><br></pre></td></tr></tbody></table></figure><h4 id="2-12-添加博客动态标签"><a href="#2-12-添加博客动态标签" class="headerlink" title="2.12 添加博客动态标签"></a>2.12 添加博客动态标签</h4><p>原理就是给博客增加一个事件判断：<br>打开博客主题文件夹，路径：<code>themes/matery/layout/layout.ejs</code>，在对应位置添加如下代码：</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">    var OriginTitile = document.title,</span><br><span class="line">        st;</span><br><span class="line">    document.addEventListener(<span class="string">"visibilitychange"</span>, function () {</span><br><span class="line">        document.hidden ? (document.title = <span class="string">"看不见我🙈~看不见我🙈~"</span>, clearTimeout(st)) : (document.title =</span><br><span class="line">            <span class="string">"(๑•̀ㅂ•́) ✧被发现了～"</span>, st = setTimeout(function () {</span><br><span class="line">                document.title = OriginTitile</span><br><span class="line">            }, <span class="number">3e3</span>))</span><br><span class="line">    })</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></tbody></table></figure><p>然后<code>hexo clean</code>&amp;&amp;<code>hexo g</code>即可。</p><h4 id="2-13-添加鼠标点击烟花爆炸效果"><a href="#2-13-添加鼠标点击烟花爆炸效果" class="headerlink" title="2.13 添加鼠标点击烟花爆炸效果"></a>2.13 添加鼠标点击烟花爆炸效果</h4><p>在<code>/themes/matery/source/js</code>新建文件<code>fireworks.js</code>，并添加如下代码</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"use strict"</span>;</span><br><span class="line"><span class="function">function <span class="title">updateCoords</span><span class="params">(e)</span></span>{</span><br><span class="line">  pointerX=(e.clientX||e.touches[<span class="number">0</span>].clientX)</span><br><span class="line">  -canvasEl.getBoundingClientRect().left,</span><br><span class="line">  pointerY=e.clientY||e.touches[<span class="number">0</span>].clientY-canvasEl.getBoundingClientRect().top</span><br><span class="line">  }<span class="function">function <span class="title">setParticuleDirection</span><span class="params">(e)</span></span>{</span><br><span class="line">    <span class="keyword">var</span> t=anime.random(<span class="number">0</span>,<span class="number">360</span>)*Math.PI/<span class="number">180</span>,</span><br><span class="line">    a=anime.random(<span class="number">50</span>,<span class="number">180</span>),</span><br><span class="line">    n=[-<span class="number">1</span>,<span class="number">1</span>][anime.random(<span class="number">0</span>,<span class="number">1</span>)]*a;</span><br><span class="line">    <span class="keyword">return</span>{x:e.x+n*Math.cos(t),y:e.y+n*Math.sin(t)}</span><br><span class="line">    }<span class="function">function <span class="title">createParticule</span><span class="params">(e,t)</span></span>{</span><br><span class="line">      <span class="keyword">var</span> a={};<span class="keyword">return</span> a.x=e,</span><br><span class="line">      a.y=t,</span><br><span class="line">      a.color=colors[anime.random(<span class="number">0</span>,colors.length-<span class="number">1</span>)],</span><br><span class="line">      a.radius=anime.random(<span class="number">16</span>,<span class="number">32</span>),</span><br><span class="line">      a.endPos=setParticuleDirection(a),</span><br><span class="line">      a.draw=function(){</span><br><span class="line">        ctx.beginPath(),</span><br><span class="line">        ctx.arc(a.x,a.y,a.radius,<span class="number">0</span>,<span class="number">2</span>*Math.PI,!<span class="number">0</span>),</span><br><span class="line">        ctx.fillStyle=a.color,ctx.fill()},a</span><br><span class="line">    }<span class="function">function <span class="title">createCircle</span><span class="params">(e,t)</span></span>{</span><br><span class="line">      <span class="keyword">var</span> a={};</span><br><span class="line">      <span class="keyword">return</span> a.x=e,</span><br><span class="line">      a.y=t,</span><br><span class="line">      a.color=<span class="string">"#F00"</span>,a.radius=<span class="number">0.1</span>,</span><br><span class="line">      a.alpha=<span class="number">0.5</span>,</span><br><span class="line">      a.lineWidth=<span class="number">6</span>,</span><br><span class="line">      a.draw=function(){</span><br><span class="line">        ctx.globalAlpha=a.alpha,</span><br><span class="line">        ctx.beginPath(),</span><br><span class="line">        ctx.arc(a.x,a.y,a.radius,<span class="number">0</span>,<span class="number">2</span>*Math.PI,!<span class="number">0</span>),</span><br><span class="line">        ctx.lineWidth=a.lineWidth,</span><br><span class="line">        ctx.strokeStyle=a.color,ctx.stroke(),</span><br><span class="line">        ctx.globalAlpha=<span class="number">1</span>},a</span><br><span class="line">        }<span class="function">function <span class="title">renderParticule</span><span class="params">(e)</span></span>{</span><br><span class="line">          <span class="keyword">for</span>(<span class="keyword">var</span> t=<span class="number">0</span>;t&lt;e.animatables.length;t++){</span><br><span class="line">            e.animatables[t].target.draw()}</span><br><span class="line">        }<span class="function">function <span class="title">animateParticules</span><span class="params">(e,t)</span></span>{</span><br><span class="line">          <span class="keyword">for</span>(<span class="keyword">var</span> a=createCircle(e,t),n=[],i=<span class="number">0</span>;i&lt;numberOfParticules;i++){</span><br><span class="line">            n.push(createParticule(e,t))</span><br><span class="line">          }anime.timeline().add({</span><br><span class="line">            targets:n,</span><br><span class="line">            x:function(e){</span><br><span class="line">              <span class="keyword">return</span> e.endPos.x</span><br><span class="line">            },y:function(e){</span><br><span class="line">              <span class="keyword">return</span> e.endPos.y</span><br><span class="line">            },radius:<span class="number">0.1</span>,</span><br><span class="line">            duration:anime.random(<span class="number">1200</span>,<span class="number">1800</span>),</span><br><span class="line">            easing:<span class="string">"easeOutExpo"</span>,</span><br><span class="line">            update:renderParticule}).add({targets:a,</span><br><span class="line">            radius:anime.random(<span class="number">80</span>,<span class="number">160</span>),</span><br><span class="line">            lineWidth:<span class="number">0</span>,</span><br><span class="line">            alpha:{value:<span class="number">0</span>,easing:<span class="string">"linear"</span>,duration:anime.random(<span class="number">600</span>,<span class="number">800</span>)},</span><br><span class="line">            duration:anime.random(<span class="number">1200</span>,<span class="number">1800</span>),</span><br><span class="line">            easing:<span class="string">"easeOutExpo"</span>,</span><br><span class="line">            update:renderParticule,offset:<span class="number">0</span>})</span><br><span class="line">        }<span class="function">function <span class="title">debounce</span><span class="params">(e,t)</span></span>{</span><br><span class="line">          <span class="keyword">var</span> a;</span><br><span class="line">          <span class="keyword">return</span> function(){</span><br><span class="line">            <span class="keyword">var</span> n=<span class="keyword">this</span>,</span><br><span class="line">            i=arguments;</span><br><span class="line">            clearTimeout(a),</span><br><span class="line">            a=setTimeout(function(){e.apply(n,i)},t)}</span><br><span class="line">        }<span class="keyword">var</span> canvasEl=document.querySelector(<span class="string">".fireworks"</span>);</span><br><span class="line">        <span class="keyword">if</span>(canvasEl){<span class="keyword">var</span> ctx=canvasEl.getContext(<span class="string">"2d"</span>),</span><br><span class="line">        numberOfParticules=<span class="number">30</span>,</span><br><span class="line">        pointerX=<span class="number">0</span>,pointerY=<span class="number">0</span>,</span><br><span class="line">        tap=<span class="string">"mousedown"</span>,</span><br><span class="line">        colors=[<span class="string">"#FF1461"</span>,<span class="string">"#18FF92"</span>,<span class="string">"#5A87FF"</span>,<span class="string">"#FBF38C"</span>],</span><br><span class="line">        setCanvasSize=debounce(function(){</span><br><span class="line">          canvasEl.width=<span class="number">2</span>*window.innerWidth,</span><br><span class="line">          canvasEl.height=<span class="number">2</span>*window.innerHeight,</span><br><span class="line">          canvasEl.style.width=window.innerWidth+<span class="string">"px"</span>,</span><br><span class="line">          canvasEl.style.height=window.innerHeight+<span class="string">"px"</span>,</span><br><span class="line">          canvasEl.getContext(<span class="string">"2d"</span>).scale(<span class="number">2</span>,<span class="number">2</span>)},<span class="number">500</span>),</span><br><span class="line">          render=anime({duration:<span class="number">1</span>/<span class="number">0</span>,update:function(){</span><br><span class="line">            ctx.clearRect(<span class="number">0</span>,<span class="number">0</span>,canvasEl.width,canvasEl.height)}});</span><br><span class="line">          document.addEventListener(tap,function(e){</span><br><span class="line">            <span class="string">"sidebar"</span>!==e.target.id&amp;&amp;<span class="string">"toggle-sidebar"</span>!==e.target.id&amp;&amp;<span class="string">"A"</span>!==e.target.nodeName&amp;&amp;<span class="string">"IMG"</span>!==e.target.nodeName&amp;&amp;(render.play(),</span><br><span class="line">            updateCoords(e),animateParticules(pointerX,pointerY))},!<span class="number">1</span>),</span><br><span class="line">            setCanvasSize(),window.addEventListener(<span class="string">"resize"</span>,setCanvasSize,!<span class="number">1</span>)}<span class="string">"use strict"</span>;</span><br><span class="line">          <span class="function">function <span class="title">updateCoords</span><span class="params">(e)</span></span>{</span><br><span class="line">            pointerX=(e.clientX||e.touches[<span class="number">0</span>].clientX)-canvasEl.getBoundingClientRect().left,</span><br><span class="line">            pointerY=e.clientY||e.touches[<span class="number">0</span>].clientY-canvasEl.getBoundingClientRect().top}<span class="function">function <span class="title">setParticuleDirection</span><span class="params">(e)</span></span>{</span><br><span class="line">            <span class="keyword">var</span> t=anime.random(<span class="number">0</span>,<span class="number">360</span>)*Math.PI/<span class="number">180</span>,a=anime.random(<span class="number">50</span>,<span class="number">180</span>),</span><br><span class="line">            n=[-<span class="number">1</span>,<span class="number">1</span>][anime.random(<span class="number">0</span>,<span class="number">1</span>)]*a;</span><br><span class="line">            <span class="keyword">return</span>{x:e.x+n*Math.cos(t),y:e.y+n*Math.sin(t)}}<span class="function">function <span class="title">createParticule</span><span class="params">(e,t)</span></span>{<span class="keyword">var</span> a={};</span><br><span class="line">            <span class="keyword">return</span> a.x=e,a.y=t,a.color=colors[anime.random(<span class="number">0</span>,colors.length-<span class="number">1</span>)],</span><br><span class="line">            a.radius=anime.random(<span class="number">16</span>,<span class="number">32</span>),a.endPos=setParticuleDirection(a),</span><br><span class="line">            a.draw=function(){ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,<span class="number">0</span>,<span class="number">2</span>*Math.PI,!<span class="number">0</span>),</span><br><span class="line">            ctx.fillStyle=a.color,ctx.fill()},a}<span class="function">function <span class="title">createCircle</span><span class="params">(e,t)</span></span>{</span><br><span class="line">              <span class="keyword">var</span> a={};<span class="keyword">return</span> a.x=e,a.y=t,a.color=<span class="string">"#F00"</span>,</span><br><span class="line">              a.radius=<span class="number">0.1</span>,a.alpha=<span class="number">0.5</span>,a.lineWidth=<span class="number">6</span>,a.draw=function(){</span><br><span class="line">                ctx.globalAlpha=a.alpha,ctx.beginPath(),</span><br><span class="line">                ctx.arc(a.x,a.y,a.radius,<span class="number">0</span>,<span class="number">2</span>*Math.PI,!<span class="number">0</span>),</span><br><span class="line">                ctx.lineWidth=a.lineWidth,ctx.strokeStyle=a.color,</span><br><span class="line">                ctx.stroke(),ctx.globalAlpha=<span class="number">1</span>},a}<span class="function">function <span class="title">renderParticule</span><span class="params">(e)</span></span>{</span><br><span class="line">                  <span class="keyword">for</span>(<span class="keyword">var</span> t=<span class="number">0</span>;t&lt;e.animatables.length;t++){e.animatables[t].target.draw()}</span><br><span class="line">                }<span class="function">function <span class="title">animateParticules</span><span class="params">(e,t)</span></span>{</span><br><span class="line">                  <span class="keyword">for</span>(<span class="keyword">var</span> a=createCircle(e,t),n=[],i=<span class="number">0</span>;</span><br><span class="line">                  i&lt;numberOfParticules;i++){n.push(createParticule(e,t))}anime.timeline().add({targets:n,x:function(e){<span class="keyword">return</span> e.endPos.x},</span><br><span class="line">                  y:function(e){<span class="keyword">return</span> e.endPos.y},</span><br><span class="line">                  radius:<span class="number">0.1</span>,</span><br><span class="line">                  duration:anime.random(<span class="number">1200</span>,<span class="number">1800</span>),</span><br><span class="line">                  easing:<span class="string">"easeOutExpo"</span>,</span><br><span class="line">                  update:renderParticule}).add({targets:a,radius:anime.random(<span class="number">80</span>,<span class="number">160</span>),</span><br><span class="line">                  lineWidth:<span class="number">0</span>,alpha:{value:<span class="number">0</span>,easing:<span class="string">"linear"</span>,duration:anime.random(<span class="number">600</span>,<span class="number">800</span>)},</span><br><span class="line">                  duration:anime.random(<span class="number">1200</span>,<span class="number">1800</span>),</span><br><span class="line">                  easing:<span class="string">"easeOutExpo"</span>,</span><br><span class="line">                  update:renderParticule,</span><br><span class="line">                  offset:<span class="number">0</span>})}<span class="function">function <span class="title">debounce</span><span class="params">(e,t)</span></span>{</span><br><span class="line">                    <span class="keyword">var</span> a;</span><br><span class="line">                    <span class="keyword">return</span> function(){</span><br><span class="line">                      <span class="keyword">var</span> n=<span class="keyword">this</span>,</span><br><span class="line">                      i=arguments;</span><br><span class="line">                      clearTimeout(a),</span><br><span class="line">                      a=setTimeout(function(){</span><br><span class="line">                        e.apply(n,i)},t)}</span><br><span class="line">                      }<span class="keyword">var</span> canvasEl=document.querySelector(<span class="string">".fireworks"</span>);</span><br><span class="line">                      <span class="keyword">if</span>(canvasEl){<span class="keyword">var</span> ctx=canvasEl.getContext(<span class="string">"2d"</span>),</span><br><span class="line">                      numberOfParticules=<span class="number">30</span>,</span><br><span class="line">                      pointerX=<span class="number">0</span>,</span><br><span class="line">                      pointerY=<span class="number">0</span>,</span><br><span class="line">                      tap=<span class="string">"mousedown"</span>,</span><br><span class="line">                      colors=[<span class="string">"#FF1461"</span>,<span class="string">"#18FF92"</span>,<span class="string">"#5A87FF"</span>,<span class="string">"#FBF38C"</span>],</span><br><span class="line">                      setCanvasSize=debounce(function(){</span><br><span class="line">                        canvasEl.width=<span class="number">2</span>*window.innerWidth,</span><br><span class="line">                        canvasEl.height=<span class="number">2</span>*window.innerHeight,</span><br><span class="line">                        canvasEl.style.width=window.innerWidth+<span class="string">"px"</span>,</span><br><span class="line">                        canvasEl.style.height=window.innerHeight+<span class="string">"px"</span>,</span><br><span class="line">                        canvasEl.getContext(<span class="string">"2d"</span>).scale(<span class="number">2</span>,<span class="number">2</span>)},<span class="number">500</span>),</span><br><span class="line">                        render=anime({duration:<span class="number">1</span>/<span class="number">0</span>,</span><br><span class="line">                        update:function(){</span><br><span class="line">                          ctx.clearRect(<span class="number">0</span>,<span class="number">0</span>,canvasEl.width,canvasEl.height)}});</span><br><span class="line">                          document.addEventListener(tap,function(e){<span class="string">"sidebar"</span>!==e.target.id&amp;&amp;<span class="string">"toggle-sidebar"</span>!==e.target.id&amp;&amp;<span class="string">"A"</span>!==e.target.nodeName&amp;&amp;<span class="string">"IMG"</span>!==e.target.nodeName&amp;&amp;(render.play(),</span><br><span class="line">                          updateCoords(e),</span><br><span class="line">                          animateParticules(pointerX,pointerY))},!<span class="number">1</span>),</span><br><span class="line">                          setCanvasSize(),</span><br><span class="line">                          window.addEventListener(<span class="string">"resize"</span>,setCanvasSize,!<span class="number">1</span>)};</span><br></pre></td></tr></tbody></table></figure><p>然后在<code>/themes/matery/layout/_partial/footer.ejs</code>中添加如下代码：\</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;% <span class="keyword">if</span> (theme.fireworks.enable) { %&gt;</span><br><span class="line">&lt;canvas class="fireworks" style="position: fixed; left: 0; top: 0; z-index: 1; pointer-events: none;" &gt;&lt;/canvas&gt;</span><br><span class="line">&lt;script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"&gt;&lt;/script&gt;</span><br><span class="line">&lt;script type="text/javascript" src="/js/fireworks.js"&gt;&lt;/script&gt;</span><br><span class="line">&lt;% } %&gt;</span><br></pre></td></tr></tbody></table></figure><p>在主题配置文件<code>.yml</code>中配置:</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 鼠标点击烟花爆炸动效</span></span><br><span class="line"><span class="attr">fireworks:</span></span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span></span><br></pre></td></tr></tbody></table></figure><h4 id="2-14-添加页面樱花飘落动效"><a href="#2-14-添加页面樱花飘落动效" class="headerlink" title="2.14 添加页面樱花飘落动效"></a>2.14 添加页面樱花飘落动效</h4><p>在<code>/themes/matery/source/js</code>新建文件<code>sakura.js</code>，并添加如下代码</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> stop, staticx;</span><br><span class="line"><span class="keyword">var</span> img = <span class="keyword">new</span> Image();</span><br><span class="line">img.src = <span class="string">"data:image/png;base64,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"</span>;</span><br></pre></td></tr></tbody></table></figure><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">function <span class="title">Sakura</span><span class="params">(x, y, s, r, fn)</span> </span>{</span><br><span class="line">    <span class="keyword">this</span>.x = x;</span><br><span class="line">    <span class="keyword">this</span>.y = y;</span><br><span class="line">    <span class="keyword">this</span>.s = s;</span><br><span class="line">    <span class="keyword">this</span>.r = r;</span><br><span class="line">    <span class="keyword">this</span>.fn = fn;</span><br><span class="line">}</span><br><span class="line">Sakura.prototype.draw = function (cxt) {</span><br><span class="line">    cxt.save();</span><br><span class="line">    <span class="keyword">var</span> xc = <span class="number">40</span> * <span class="keyword">this</span>.s / <span class="number">4</span>;</span><br><span class="line">    cxt.translate(<span class="keyword">this</span>.x, <span class="keyword">this</span>.y);</span><br><span class="line">    cxt.rotate(<span class="keyword">this</span>.r);</span><br><span class="line">    cxt.drawImage(img, <span class="number">0</span>, <span class="number">0</span>, <span class="number">40</span> * <span class="keyword">this</span>.s, <span class="number">40</span> * <span class="keyword">this</span>.s)</span><br><span class="line">    cxt.restore();</span><br><span class="line">}</span><br><span class="line">Sakura.prototype.update = function () {</span><br><span class="line">    <span class="keyword">this</span>.x = <span class="keyword">this</span>.fn.x(<span class="keyword">this</span>.x, <span class="keyword">this</span>.y);</span><br><span class="line">    <span class="keyword">this</span>.y = <span class="keyword">this</span>.fn.y(<span class="keyword">this</span>.y, <span class="keyword">this</span>.y);</span><br><span class="line">    <span class="keyword">this</span>.r = <span class="keyword">this</span>.fn.r(<span class="keyword">this</span>.r);</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.x &gt; window.innerWidth || <span class="keyword">this</span>.x &lt; <span class="number">0</span> || <span class="keyword">this</span>.y &gt; window.innerHeight || <span class="keyword">this</span>.y &lt; <span class="number">0</span>) {</span><br><span class="line">        <span class="keyword">this</span>.r = getRandom(<span class="string">'fnr'</span>);</span><br><span class="line">        <span class="keyword">if</span> (Math.random() &gt; <span class="number">0.4</span>) {</span><br><span class="line">            <span class="keyword">this</span>.x = getRandom(<span class="string">'x'</span>);</span><br><span class="line">            <span class="keyword">this</span>.y = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">this</span>.s = getRandom(<span class="string">'s'</span>);</span><br><span class="line">            <span class="keyword">this</span>.r = getRandom(<span class="string">'r'</span>);</span><br><span class="line">        } <span class="keyword">else</span> {</span><br><span class="line">            <span class="keyword">this</span>.x = window.innerWidth;</span><br><span class="line">            <span class="keyword">this</span>.y = getRandom(<span class="string">'y'</span>);</span><br><span class="line">            <span class="keyword">this</span>.s = getRandom(<span class="string">'s'</span>);</span><br><span class="line">            <span class="keyword">this</span>.r = getRandom(<span class="string">'r'</span>);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line">SakuraList = function () {</span><br><span class="line">    <span class="keyword">this</span>.list = [];</span><br><span class="line">}</span><br><span class="line">SakuraList.prototype.push = function (sakura) {</span><br><span class="line">    <span class="keyword">this</span>.list.push(sakura);</span><br><span class="line">}</span><br><span class="line">SakuraList.prototype.update = function () {</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>, len = <span class="keyword">this</span>.list.length; i &lt; len; i++) {</span><br><span class="line">        <span class="keyword">this</span>.list[i].update();</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line">SakuraList.prototype.draw = function (cxt) {</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>, len = <span class="keyword">this</span>.list.length; i &lt; len; i++) {</span><br><span class="line">        <span class="keyword">this</span>.list[i].draw(cxt);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line">SakuraList.prototype.get = function (i) {</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.list[i];</span><br><span class="line">}</span><br><span class="line">SakuraList.prototype.size = function () {</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.list.length;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function">function <span class="title">getRandom</span><span class="params">(option)</span> </span>{</span><br><span class="line">    <span class="keyword">var</span> ret, random;</span><br><span class="line">    <span class="keyword">switch</span> (option) {</span><br><span class="line">        <span class="keyword">case</span> <span class="string">'x'</span>:</span><br><span class="line">            ret = Math.random() * window.innerWidth;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">'y'</span>:</span><br><span class="line">            ret = Math.random() * window.innerHeight;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">'s'</span>:</span><br><span class="line">            ret = Math.random();</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">'r'</span>:</span><br><span class="line">            ret = Math.random() * <span class="number">6</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">'fnx'</span>:</span><br><span class="line">            random = -<span class="number">0.5</span> + Math.random() * <span class="number">1</span>;</span><br><span class="line">            ret = function (x, y) {</span><br><span class="line">                <span class="keyword">return</span> x + <span class="number">0.5</span> * random - <span class="number">1.7</span>;</span><br><span class="line">            };</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">'fny'</span>:</span><br><span class="line">            random = <span class="number">1.5</span> + Math.random() * <span class="number">0.7</span></span><br><span class="line">            ret = function (x, y) {</span><br><span class="line">                <span class="keyword">return</span> y + random;</span><br><span class="line">            };</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">'fnr'</span>:</span><br><span class="line">            random = Math.random() * <span class="number">0.03</span>;</span><br><span class="line">            ret = function (r) {</span><br><span class="line">                <span class="keyword">return</span> r + random;</span><br><span class="line">            };</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function">function <span class="title">startSakura</span><span class="params">()</span> </span>{</span><br><span class="line">    requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame || window.webkitRequestAnimationFrame || window.msRequestAnimationFrame || window.oRequestAnimationFrame;</span><br><span class="line">    <span class="keyword">var</span> canvas = document.createElement(<span class="string">'canvas'</span>),</span><br><span class="line">        cxt;</span><br><span class="line">    staticx = <span class="keyword">true</span>;</span><br><span class="line">    canvas.height = window.innerHeight;</span><br><span class="line">    canvas.width = window.innerWidth;</span><br><span class="line">    canvas.setAttribute(<span class="string">'style'</span>, <span class="string">'position: fixed;left: 0;top: 0;pointer-events: none;'</span>);</span><br><span class="line">    canvas.setAttribute(<span class="string">'id'</span>, <span class="string">'canvas_sakura'</span>);</span><br><span class="line">    document.getElementsByTagName(<span class="string">'body'</span>)[<span class="number">0</span>].appendChild(canvas);</span><br><span class="line">    cxt = canvas.getContext(<span class="string">'2d'</span>);</span><br><span class="line">    <span class="keyword">var</span> sakuraList = <span class="keyword">new</span> SakuraList();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) {</span><br><span class="line">        <span class="keyword">var</span> sakura, randomX, randomY, randomS, randomR, randomFnx, randomFny;</span><br><span class="line">        randomX = getRandom(<span class="string">'x'</span>);</span><br><span class="line">        randomY = getRandom(<span class="string">'y'</span>);</span><br><span class="line">        randomR = getRandom(<span class="string">'r'</span>);</span><br><span class="line">        randomS = getRandom(<span class="string">'s'</span>);</span><br><span class="line">        randomFnx = getRandom(<span class="string">'fnx'</span>);</span><br><span class="line">        randomFny = getRandom(<span class="string">'fny'</span>);</span><br><span class="line">        randomFnR = getRandom(<span class="string">'fnr'</span>);</span><br><span class="line">        sakura = <span class="keyword">new</span> Sakura(randomX, randomY, randomS, randomR, {</span><br><span class="line">            x: randomFnx,</span><br><span class="line">            y: randomFny,</span><br><span class="line">            r: randomFnR</span><br><span class="line">        });</span><br><span class="line">        sakura.draw(cxt);</span><br><span class="line">        sakuraList.push(sakura);</span><br><span class="line">    }</span><br><span class="line">    stop = requestAnimationFrame(function () {</span><br><span class="line">        cxt.clearRect(<span class="number">0</span>, <span class="number">0</span>, canvas.width, canvas.height);</span><br><span class="line">        sakuraList.update();</span><br><span class="line">        sakuraList.draw(cxt);</span><br><span class="line">        stop = requestAnimationFrame(arguments.callee);</span><br><span class="line">    })</span><br><span class="line">}</span><br><span class="line">window.onresize = function () {</span><br><span class="line">    <span class="keyword">var</span> canvasSnow = document.getElementById(<span class="string">'canvas_snow'</span>);</span><br><span class="line">}</span><br><span class="line">img.onload = function () {</span><br><span class="line">    startSakura();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function">function <span class="title">stopp</span><span class="params">()</span> </span>{</span><br><span class="line">    <span class="keyword">if</span> (staticx) {</span><br><span class="line">        <span class="keyword">var</span> child = document.getElementById(<span class="string">"canvas_sakura"</span>);</span><br><span class="line">        child.parentNode.removeChild(child);</span><br><span class="line">        window.cancelAnimationFrame(stop);</span><br><span class="line">        staticx = <span class="keyword">false</span>;</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">        startSakura();</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>然后在<code>/themes/matery/layout/_partial/head.ejs</code>中添加如下代码：</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;% <span class="keyword">if</span> (theme.sakura.enable) { %&gt;</span><br><span class="line">    &lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">    <span class="comment">//只在桌面版网页启用特效</span></span><br><span class="line">    <span class="keyword">var</span> windowWidth = $(window).width();</span><br><span class="line">    <span class="keyword">if</span> (windowWidth &gt; <span class="number">768</span>) {</span><br><span class="line">        document.write(<span class="string">'&lt;script type="text/javascript" src="/js/sakura.js"&gt;&lt;/script&gt;'</span>);</span><br><span class="line">    }</span><br><span class="line">    &lt;/script&gt;</span><br><span class="line">&lt;% } %&gt;</span><br></pre></td></tr></tbody></table></figure><p>在主题配置文件<code>.yml</code>中配置:</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 页面樱花飘落动效</span><br><span class="line">sakura:</span><br><span class="line">  enable: <span class="keyword">true</span></span><br></pre></td></tr></tbody></table></figure><h4 id="2-15-添加鼠标点击文字特效"><a href="#2-15-添加鼠标点击文字特效" class="headerlink" title="2.15 添加鼠标点击文字特效"></a>2.15 添加鼠标点击文字特效</h4><p>在<code>/themes/matery/source/js</code>新建文件<code>wenzi.js</code>，并添加如下代码</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 鼠标点击文字特效 */</span></span><br><span class="line"><span class="keyword">var</span> a_idx = <span class="number">0</span>;</span><br><span class="line">jQuery(document).ready(function($) {</span><br><span class="line">    $(<span class="string">"body"</span>).click(function(e) {</span><br><span class="line">        <span class="comment">// var a = new Array("❤富强❤","❤民主❤","❤文明❤","❤和谐❤","❤自由❤","❤平等❤","❤公正❤","❤法治❤","❤爱国❤","❤敬业❤","❤诚信❤","❤友善❤");</span></span><br><span class="line">        <span class="keyword">var</span> a = <span class="keyword">new</span> Array(<span class="string">"富强"</span>,<span class="string">"民主"</span>,<span class="string">"文明"</span>,<span class="string">"和谐"</span>,<span class="string">"自由"</span>,<span class="string">"平等"</span>,<span class="string">"公正"</span>,<span class="string">"法治"</span>,<span class="string">"爱国"</span>,<span class="string">"敬业"</span>,<span class="string">"诚信"</span>,<span class="string">"友善"</span>);</span><br><span class="line">        <span class="keyword">var</span> $i = $(<span class="string">"&lt;span&gt;&lt;/span&gt;"</span>).text(a[a_idx]);</span><br><span class="line">        a_idx = (a_idx + <span class="number">1</span>) % a.length;</span><br><span class="line">        <span class="keyword">var</span> x = e.pageX,</span><br><span class="line">        y = e.pageY;</span><br><span class="line">        $i.css({</span><br><span class="line">            <span class="string">"z-index"</span>: <span class="number">999999999999999999999999999999999999999999999999999999999999999999999</span>,</span><br><span class="line">            <span class="string">"top"</span>: y - <span class="number">20</span>,</span><br><span class="line">            <span class="string">"left"</span>: x,</span><br><span class="line">            <span class="string">"position"</span>: <span class="string">"absolute"</span>,</span><br><span class="line">            <span class="string">"font-weight"</span>: <span class="string">"bold"</span>,</span><br><span class="line">            <span class="string">"color"</span>: <span class="string">"rgb("</span>+~~(<span class="number">255</span>*Math.random())+<span class="string">","</span>+~~(<span class="number">255</span>*Math.random())+<span class="string">","</span>+~~(<span class="number">255</span>*Math.random())+<span class="string">")"</span></span><br><span class="line">        });</span><br><span class="line">        $(<span class="string">"body"</span>).append($i);</span><br><span class="line">        $i.animate({</span><br><span class="line">            <span class="string">"top"</span>: y - <span class="number">180</span>,</span><br><span class="line">            <span class="string">"opacity"</span>: <span class="number">0</span></span><br><span class="line">        },</span><br><span class="line">        <span class="number">1500</span>,</span><br><span class="line">        function() {</span><br><span class="line">            $i.remove();</span><br><span class="line">        });</span><br><span class="line">    });</span><br><span class="line">});</span><br></pre></td></tr></tbody></table></figure><p>然后在<code>/themes/matery/layout/_partial/head.ejs</code>中添加如下代码：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;% <span class="keyword">if</span> (theme.wenzi.enable) { %&gt;</span><br><span class="line">    &lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">    <span class="comment">//只在桌面版网页启用特效</span></span><br><span class="line">    var windowWidth = $(window).width();</span><br><span class="line">    <span class="keyword">if</span> (windowWidth &gt; <span class="number">768</span>) {</span><br><span class="line">        document.write('&lt;script type="text/javascript" src="/js/wenzi.js"&gt;&lt;/script&gt;');</span><br><span class="line">    }</span><br><span class="line">    &lt;/script&gt;</span><br><span class="line">&lt;% } %&gt;</span><br></pre></td></tr></tbody></table></figure><p>在主题配置文件<code>.yml</code>中配置:</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 页面樱花飘落动效</span><br><span class="line">wenzi:</span><br><span class="line">  enable: <span class="literal">true</span></span><br></pre></td></tr></tbody></table></figure><h4 id="2-16-添加页面雪花飘落动效"><a href="#2-16-添加页面雪花飘落动效" class="headerlink" title="2.16 添加页面雪花飘落动效"></a>2.16 添加页面雪花飘落动效</h4><p>在<code>/themes/matery/source/js</code>新建文件<code>xuehuapiaoluo.js</code>，并添加如下代码</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*样式一*/</span></span><br><span class="line"><span class="comment">//背景雪花飘落特效</span></span><br><span class="line">(function($){</span><br><span class="line">  $.fn.snow = function(options){</span><br><span class="line">  var $flake = $('&lt;div id="snowbox" /&gt;').css({'position': 'absolute','z-index':'9999', 'top': '-50px'}).html('&amp;#10052;'),</span><br><span class="line">  documentHeight  = $(document).height(),</span><br><span class="line">  documentWidth = $(document).width(),</span><br><span class="line">  defaults = {</span><br><span class="line">    minSize   : <span class="number">10</span>,</span><br><span class="line">    maxSize   : <span class="number">20</span>,</span><br><span class="line">    newOn   : <span class="number">1000</span>,</span><br><span class="line">    flakeColor  : <span class="string">"#AFDAEF"</span> <span class="comment">/* 此处可以定义雪花颜色，若要白色可以改为#FFFFFF */</span></span><br><span class="line">  },</span><br><span class="line">  options = $.extend({}, defaults, options);</span><br><span class="line">  var interval= setInterval( function(){</span><br><span class="line">  var startPositionLeft = Math.random() * documentWidth - <span class="number">100</span>,</span><br><span class="line">  startOpacity = <span class="number">0.5</span> + Math.random(),</span><br><span class="line">  sizeFlake = options.minSize + Math.random() * options.maxSize,</span><br><span class="line">  endPositionTop = documentHeight - <span class="number">200</span>,</span><br><span class="line">  endPositionLeft = startPositionLeft - <span class="number">500</span> + Math.random() * <span class="number">500</span>,</span><br><span class="line">  durationFall = documentHeight * <span class="number">10</span> + Math.random() * <span class="number">5000</span>;</span><br><span class="line">  $flake.clone().appendTo('body').css({</span><br><span class="line">    left: startPositionLeft,</span><br><span class="line">    opacity: startOpacity,</span><br><span class="line">    'font-size': sizeFlake,</span><br><span class="line">    color: options.flakeColor</span><br><span class="line">  }).animate({</span><br><span class="line">    top: endPositionTop,</span><br><span class="line">    left: endPositionLeft,</span><br><span class="line">    opacity: <span class="number">0.2</span></span><br><span class="line">  },durationFall,'linear',function(){</span><br><span class="line">    $(<span class="keyword">this</span>).remove()</span><br><span class="line">  });</span><br><span class="line">  }, options.newOn);</span><br><span class="line">    };</span><br><span class="line">})(jQuery);</span><br><span class="line">$(function(){</span><br><span class="line">    $.fn.snow({</span><br><span class="line">      minSize: <span class="number">5</span>, <span class="comment">/* 定义雪花最小尺寸 */</span></span><br><span class="line">      maxSize: <span class="number">50</span>,<span class="comment">/* 定义雪花最大尺寸 */</span></span><br><span class="line">      newOn: <span class="number">500</span>  <span class="comment">/* 定义密集程度，数字越小越密集 */</span></span><br><span class="line">    });</span><br><span class="line">});</span><br></pre></td></tr></tbody></table></figure><p>然后在<code>/themes/matery/layout/_partial/head.ejs</code>中添加如下代码：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;% <span class="keyword">if</span> (theme.xuehuapiaoluo.enable) { %&gt;</span><br><span class="line">    &lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">    <span class="comment">//只在桌面版网页启用特效</span></span><br><span class="line">    var windowWidth = $(window).width();</span><br><span class="line">    <span class="keyword">if</span> (windowWidth &gt; <span class="number">768</span>) {</span><br><span class="line">        document.write('&lt;script type="text/javascript" src="/js/xuehuapiaoluo.js"&gt;&lt;/script&gt;');</span><br><span class="line">    }</span><br><span class="line">    &lt;/script&gt;</span><br><span class="line">&lt;% } %&gt;</span><br></pre></td></tr></tbody></table></figure><p>在主题配置文件<code>.yml</code>中配置:</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 页面樱花飘落动效</span><br><span class="line">xuehuapiaoluo:</span><br><span class="line">  enable: <span class="literal">true</span></span><br></pre></td></tr></tbody></table></figure><h4 id="2-17-添加博客天气插件"><a href="#2-17-添加博客天气插件" class="headerlink" title="2.17 添加博客天气插件"></a>2.17 添加博客天气插件</h4><p>在搜寻插件的过程中无意间用<code>google</code>搜到的一个网站，使用非常简单，在这里附上插件添加的方法<br>中国天气网：<a href="https://cj.weather.com.cn/plugin/pc" target="_blank" rel="noopener">https://cj.weather.com.cn/plugin/pc</a><br>选择自定义插件—&gt;自定义样式——&gt;生成代码，然后会生成这样一段代码</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Weather Widget --&gt;</span><br><span class="line">&lt;script type="text/javascript"&gt; WIDGET = {FID: 'your FID'}&lt;/script&gt;</span><br><span class="line">&lt;script type=<span class="string">"text/javascript"</span> src=<span class="string">"https://apip.weatherdt.com/float/static/js/r.js?v=1111"</span>&gt;&lt;/script&gt;</span><br></pre></td></tr></tbody></table></figure><p>在<code>/themes/matery/source/layout/_widget</code>新建文件<code>weather.ejs</code>，把上面生成的代码添加进入,可以设置只有桌面端显示,如下修改:</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 天气接口 --&gt;</span><br><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">  WIDGET = {FID: '1tFpFZ5Mtj'}</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;!-- &lt;script type=<span class="string">"text/javascript"</span> src=<span class="string">"https://apip.weatherdt.com/float/static/js/r.js?v=1111"</span>&gt;&lt;/script&gt; --&gt;</span><br><span class="line"></span><br><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">  <span class="comment">//只在桌面版网页启用特效</span></span><br><span class="line">  var windowWidth = $(window).width();</span><br><span class="line">  <span class="keyword">if</span> (windowWidth &gt; <span class="number">768</span>) {</span><br><span class="line">      document.write('&lt;script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"&gt;&lt;\/script&gt;');</span><br><span class="line">  }</span><br><span class="line">  &lt;/script&gt;</span><br></pre></td></tr></tbody></table></figure><p>然后在<code>/themes/matery/layout/_partial/layout.ejs</code>中添加如下代码：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;% <span class="keyword">if</span> (theme.weather.enable) { %&gt;</span><br><span class="line">  &lt;%- partial('_widget/weather') %&gt;</span><br><span class="line">&lt;% } %&gt;</span><br></pre></td></tr></tbody></table></figure><p>在主题配置文件<code>.yml</code>中配置:</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 天气接口插件</span></span><br><span class="line"><span class="attr">weather:</span></span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span></span><br></pre></td></tr></tbody></table></figure><p>展示效果可以参考我的<a href="https://gkm0120.gitee.io/" target="_blank" rel="noopener">主页</a></p><p>当然,如果你不想搞这么复杂,可以直接将下面代码插入<code>/themes/matery/layout/_partial/layout.ejs</code>中即可使用:</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">    WIDGET = {FID: '1tFpFZ5Mtj'}</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;script type=<span class="string">"text/javascript"</span> src=<span class="string">"https://apip.weatherdt.com/float/static/js/r.js?v=1111"</span>&gt;&lt;/script&gt;</span><br></pre></td></tr></tbody></table></figure><h4 id="2-18-修复-Valine-头像不显示问题"><a href="#2-18-修复-Valine-头像不显示问题" class="headerlink" title="2.18 修复 Valine 头像不显示问题"></a>2.18 修复 Valine 头像不显示问题</h4><p>关于头像显示问题，先去注册<a href="https://cn.gravatar.com/" target="_blank" rel="noopener">Gravatar</a>，之前看文档说是七天的同步时间，结果一直也没有显示头像，检查查看头像链接，发现把<code>&amp;v=1.3.x</code>去掉就可以了，于是下载 js 文件<code>valine</code>，下载后然后编辑，搜索关键字<code>&amp;v=</code>，找到<code>g.params=”?d=”+i.indexOf(a&gt;-1?a:”mp”)+”&amp;v=”+o+d</code>，将<code>"&amp;v="+o+d</code>删除即可，然后在<code>Gravatar</code>拿到头像的<code>url</code>填上去就行了</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">valine:</span><br><span class="line">  enable: <span class="literal">true</span></span><br><span class="line">  appId:</span><br><span class="line">  appKey:</span><br><span class="line">  notify: <span class="literal">true</span></span><br><span class="line">  verify: <span class="literal">true</span></span><br><span class="line">  visitor: <span class="literal">true</span></span><br><span class="line">  # avatar: 'mp' # Gravatar style : mm/identicon/monsterid/wavatar/retro/hide</span><br><span class="line">  avatar: https:<span class="comment">//s.gravatar.com/avatar/0007991f99268c04f1aa4cdd9bea93b4?s=80</span></span><br><span class="line">  pageSize: <span class="number">10</span></span><br><span class="line">  placeholder: '没有Github账号的在这里留言评论～' # Comment Box placeholder</span><br></pre></td></tr></tbody></table></figure><p>原因就是链接后跟了个<code>&amp;v=1.3.x</code>，解决就是将这段删掉就可以了，具体到<code>Valine.mini.js</code>文件就是删掉<code>&amp;v="+o+d</code>即可</p><h4 id="2-19-增加二级菜单"><a href="#2-19-增加二级菜单" class="headerlink" title="2.19 增加二级菜单"></a>2.19 增加二级菜单</h4><p>都知道，我们标题栏宽度有限，我们项目一多了，就放不下了，这时候你肯定就需要一个二级菜单来拆分一下项目，既可以减少标题栏项目数，使之更加清爽，又可以间项目分类，逻辑清晰。</p><p>好了，如果你用的<code>matery</code>主题，那么废话不多说，直接上教程，其实需要修改的就四个地方：<code>matery.css/matery.js/navgation.ejs/mobile-nav.ejs</code></p><p>第一步，在<code>/themes/matery/layout/_partial</code>中找到<code>mobile-nav.ejs</code>，找到下面这段代码：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;ul <span class="class"><span class="keyword">class</span>="<span class="title">menu</span>-<span class="title">list</span> <span class="title">mobile</span>-<span class="title">menu</span>-<span class="title">list</span>"&gt;</span></span><br><span class="line"><span class="class">    &lt;% Object.keys(theme.menu).forEach(function(key) { %&gt;</span></span><br><span class="line"><span class="class">    &lt;li&gt;</span></span><br><span class="line"><span class="class">        &lt;a href="&lt;%- theme.menu[key].url %&gt;" class="waves-effect waves-light"&gt;</span></span><br><span class="line"><span class="class">            &lt;% if (theme.menu[key].icon &amp;&amp; theme.menu[key].icon.length &gt; 0) {</span> %&gt;</span><br><span class="line">            &lt;i <span class="class"><span class="keyword">class</span>="<span class="title">fa</span> <span class="title">fa</span>-<span class="title">fw</span> &lt;%- theme.menu[key].icon %&gt;"&gt;&lt;/i&gt;</span></span><br><span class="line"><span class="class">            &lt;% } else { %&gt;</span></span><br><span class="line"><span class="class">            &lt;i class="fa fa-fw fa-link"&gt;&lt;/i&gt;</span></span><br><span class="line"><span class="class">            &lt;% } %&gt;</span></span><br><span class="line"><span class="class">            &lt;%- (config.language === 'zh-CN' &amp;&amp; menuMap.has(key)) ? menuMap.get(key) : key %&gt;</span></span><br><span class="line"><span class="class">        &lt;/a&gt;</span></span><br><span class="line"><span class="class">    &lt;/li&gt;</span></span><br><span class="line"><span class="class">    &lt;% }); %&gt;</span></span><br><span class="line"><span class="class">    &lt;% if (theme.githubLink &amp;&amp; theme.githubLink.enable) { %&gt;</span></span><br><span class="line"><span class="class">    &lt;li&gt;&lt;div class="divider"&gt;&lt;/div&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="class">    &lt;li&gt;</span></span><br><span class="line"><span class="class">        &lt;a href="&lt;%- theme.githubLink.url %&gt;" class="waves-effect waves-light" target="_blank"&gt;</span></span><br><span class="line"><span class="class">            &lt;i class="fa fa-github-square fa-fw"&gt;&lt;/i&gt;&lt;%- theme.githubLink.title %&gt;</span></span><br><span class="line"><span class="class">        &lt;/a&gt;</span></span><br><span class="line"><span class="class">    &lt;/li&gt;</span></span><br><span class="line"><span class="class">    &lt;% } %&gt;</span></span><br><span class="line"><span class="class">&lt;/ul&gt;</span></span><br></pre></td></tr></tbody></table></figure><p>替换成下面的：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 支持二级菜单特性 --&gt;</span><br><span class="line">&lt;ul <span class="class"><span class="keyword">class</span>="<span class="title">menu</span>-<span class="title">list</span> <span class="title">mobile</span>-<span class="title">menu</span>-<span class="title">list</span>"&gt;</span></span><br><span class="line"><span class="class">    &lt;% Object.keys(theme.menu).forEach(function(key) { %&gt;</span></span><br><span class="line"><span class="class">        &lt;li class="m-nav-item"&gt;</span></span><br><span class="line"><span class="class">                &lt;% if(!theme.menu[key].children) { %&gt;</span></span><br><span class="line"><span class="class">                    &lt;a href="&lt;%- theme.menu[key].url %&gt;" class="waves-effect waves-light"&gt;</span></span><br><span class="line"><span class="class">                        &lt;% if (theme.menu[key].icon &amp;&amp; theme.menu[key].icon.length &gt; 0) {</span> %&gt;</span><br><span class="line">                        &lt;i <span class="class"><span class="keyword">class</span>="<span class="title">fa</span> <span class="title">fa</span>-<span class="title">fw</span> &lt;%- theme.menu[key].icon %&gt;"&gt;&lt;/i&gt;</span></span><br><span class="line"><span class="class">                        &lt;% } else { %&gt;</span></span><br><span class="line"><span class="class">                        &lt;i class="fa fa-fw fa-link"&gt;&lt;/i&gt;</span></span><br><span class="line"><span class="class">                        &lt;% } %&gt;</span></span><br><span class="line"><span class="class">                        &lt;%- (config.language === 'zh-CN' &amp;&amp; menuMap.has(key)) ? menuMap.get(key) : key %&gt;</span></span><br><span class="line"><span class="class">                    &lt;/a&gt;</span></span><br><span class="line"><span class="class">              &lt;% } else { %&gt;</span></span><br><span class="line"><span class="class">                    &lt;a href="javascript:;"&gt;</span></span><br><span class="line"><span class="class">                            &lt;% if (theme.menu[key].icon &amp;&amp; theme.menu[key].icon.length &gt; 0) {</span> %&gt;</span><br><span class="line">                            &lt;i <span class="class"><span class="keyword">class</span>="<span class="title">fa</span> <span class="title">fa</span>-<span class="title">fw</span> &lt;%- theme.menu[key].icon %&gt;"&gt;&lt;/i&gt;</span></span><br><span class="line"><span class="class">                            &lt;% } else { %&gt;</span></span><br><span class="line"><span class="class">                            &lt;i class="fa fa-fw fa-link"&gt;&lt;/i&gt;</span></span><br><span class="line"><span class="class">                            &lt;% } %&gt;</span></span><br><span class="line"><span class="class">                            &lt;%- (config.language === 'zh-CN' &amp;&amp; menuMap.has(key)) ? menuMap.get(key) : key %&gt;</span></span><br><span class="line"><span class="class">                            &lt;span class="m-icon"&gt;&lt;i class="fa fa-chevron-right"&gt;&lt;/i&gt;&lt;/span&gt;</span></span><br><span class="line"><span class="class">                    &lt;/a&gt;</span></span><br><span class="line"><span class="class">                &lt;ul&gt;</span></span><br><span class="line"><span class="class">                  &lt;% for(let childrenLink of theme.menu[key].children){ %&gt;</span></span><br><span class="line"><span class="class">                    &lt;li&gt;</span></span><br><span class="line"><span class="class">                      &lt;a href="&lt;%- url_for(childrenLink.url)%&gt;" &gt;</span></span><br><span class="line"><span class="class">                           &lt;% if (childrenLink.icon &amp;&amp; childrenLink.icon.length &gt; 0) {</span> %&gt;</span><br><span class="line">                            &lt;i <span class="class"><span class="keyword">class</span>="<span class="title">fa</span> &lt;%- childrenLink.icon %&gt;" <span class="title">style</span>="<span class="title">left</span>:</span> <span class="number">25</span>px; position: absolute;<span class="string">"&gt;&lt;/i&gt;</span></span><br><span class="line"><span class="string">                       &lt;% } %&gt;</span></span><br><span class="line"><span class="string">                       &lt;span&gt;&lt;%- childrenLink.name %&gt;&lt;/span&gt;</span></span><br><span class="line"><span class="string">                      &lt;/a&gt;</span></span><br><span class="line"><span class="string">                    &lt;/li&gt;</span></span><br><span class="line"><span class="string">                  &lt;% } %&gt;</span></span><br><span class="line"><span class="string">                &lt;/ul&gt;</span></span><br><span class="line"><span class="string">              &lt;% } %&gt;</span></span><br><span class="line"><span class="string">            &lt;/li&gt;</span></span><br><span class="line"><span class="string">        &lt;% }); %&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &lt;% if (theme.githubLink &amp;&amp; theme.githubLink.enable) { %&gt;</span></span><br><span class="line"><span class="string">        &lt;li&gt;&lt;div class="</span>divider<span class="string">"&gt;&lt;/div&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">        &lt;li&gt;</span></span><br><span class="line"><span class="string">            &lt;a href="</span>&lt;%- theme.githubLink.url %&gt;<span class="string">" class="</span>waves-effect waves-light<span class="string">" target="</span>_blank<span class="string">"&gt;</span></span><br><span class="line"><span class="string">                &lt;i class="</span>fa fa-github-square fa-fw<span class="string">"&gt;&lt;/i&gt;&lt;%- theme.githubLink.title %&gt;</span></span><br><span class="line"><span class="string">            &lt;/a&gt;</span></span><br><span class="line"><span class="string">        &lt;/li&gt;</span></span><br><span class="line"><span class="string">      &lt;% } %&gt;</span></span><br><span class="line"><span class="string">&lt;/ul&gt;</span></span><br></pre></td></tr></tbody></table></figure><p>第二步，在<code>/themes/matery/layout/_partial</code>中找到<code>navagtion.ejs</code>，找到下面这段代码：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;a href=<span class="string">"#"</span> data-target=<span class="string">"mobile-nav"</span> class=<span class="string">"sidenav-trigger button-collapse"</span>&gt;&lt;i class=<span class="string">"fa fa-navicon"</span>&gt;&lt;/i&gt;&lt;/a&gt;</span><br><span class="line">&lt;ul class=<span class="string">"right"</span>&gt;</span><br><span class="line">    &lt;% Object.keys(theme.menu).forEach(function(key) { %&gt;</span><br><span class="line">    &lt;li class=<span class="string">"hide-on-med-and-down"</span>&gt;</span><br><span class="line">        &lt;a href=<span class="string">"&lt;%- theme.menu[key].url %&gt;"</span> class=<span class="string">"waves-effect waves-light"</span>&gt;</span><br><span class="line">            &lt;% <span class="keyword">if</span> (theme.menu[key].icon &amp;&amp; theme.menu[key].icon.length &gt; <span class="number">0</span>) { %&gt;</span><br><span class="line">            &lt;i class=<span class="string">"fa &lt;%- theme.menu[key].icon %&gt;"</span>&gt;&lt;/i&gt;</span><br><span class="line">            &lt;% } %&gt;</span><br><span class="line">            &lt;span&gt;&lt;%- (config.language === 'zh-CN' &amp;&amp; menuMap.has(key)) ? menuMap.get(key) : key %&gt;&lt;/span&gt;</span><br><span class="line">        &lt;/a&gt;</span><br><span class="line">    &lt;/li&gt;</span><br><span class="line">    &lt;% }); %&gt;</span><br><span class="line">    &lt;li&gt;</span><br><span class="line">        &lt;a href=<span class="string">"#searchModal"</span> class=<span class="string">"modal-trigger waves-effect waves-light"</span>&gt;</span><br><span class="line">            &lt;i id=<span class="string">"searchIcon"</span> class=<span class="string">"fa fa-search"</span> title=<span class="string">"&lt;%= __('search') %&gt;"</span>&gt;&lt;/i&gt;</span><br><span class="line">        &lt;/a&gt;</span><br><span class="line">    &lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br></pre></td></tr></tbody></table></figure><p>替换成下面的：</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 支持二级菜单特性 --&gt;</span><br><span class="line">&lt;a href=<span class="string">"#"</span> data-target=<span class="string">"mobile-nav"</span> class=<span class="string">"sidenav-trigger button-collapse"</span>&gt;&lt;i class=<span class="string">"fa fa-navicon"</span>&gt;&lt;/i&gt;&lt;/a&gt;</span><br><span class="line">&lt;ul class=<span class="string">"right nav-menu"</span>&gt;</span><br><span class="line">    &lt;% Object.keys(theme.menu).forEach(function(key) { %&gt;</span><br><span class="line">      &lt;li class=<span class="string">"hide-on-med-and-down nav-item"</span> &gt;</span><br><span class="line"></span><br><span class="line">        &lt;% <span class="keyword">if</span>(!theme.menu[key].children) { %&gt;</span><br><span class="line">            &lt;a href=<span class="string">"&lt;%- theme.menu[key].url %&gt;"</span> class=<span class="string">"waves-effect waves-light"</span>&gt;</span><br><span class="line">              &lt;% <span class="keyword">if</span> (theme.menu[key].icon &amp;&amp; theme.menu[key].icon.length &gt; <span class="number">0</span>) { %&gt;</span><br><span class="line">                &lt;i class=<span class="string">"fa &lt;%- theme.menu[key].icon %&gt;"</span>&gt;&lt;/i&gt;</span><br><span class="line">              &lt;% } %&gt;</span><br><span class="line">              &lt;span&gt;&lt;%- (config.language === 'zh-CN' &amp;&amp; menuMap.has(key)) ? menuMap.get(key) : key %&gt;&lt;/span&gt;</span><br><span class="line">            &lt;/a&gt;</span><br><span class="line"></span><br><span class="line">            &lt;% } <span class="keyword">else</span> { %&gt;</span><br><span class="line">              &lt;a href=<span class="string">"&lt;%- theme.menu[key].url %&gt;"</span> class=<span class="string">"waves-effect waves-light"</span>&gt;</span><br><span class="line">                &lt;% <span class="keyword">if</span> (theme.menu[key].icon &amp;&amp; theme.menu[key].icon.length &gt; <span class="number">0</span>) { %&gt;</span><br><span class="line">                  &lt;i class=<span class="string">"fa &lt;%- theme.menu[key].icon %&gt;"</span>&gt;&lt;/i&gt;</span><br><span class="line">                &lt;% } %&gt;</span><br><span class="line">                &lt;span&gt;&lt;%- (config.language === 'zh-CN' &amp;&amp; menuMap.has(key)) ? menuMap.get(key) : key %&gt;&lt;/span&gt;</span><br><span class="line">                &lt;i <span class="class"><span class="keyword">class</span>="<span class="title">fa</span> <span class="title">fa</span>-<span class="title">chevron</span>-<span class="title">down</span>" <span class="title">aria</span>-<span class="title">hidden</span>="<span class="title">true</span>"&gt;&lt;/i&gt;</span></span><br><span class="line"><span class="class">              &lt;/a&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">            &lt;ul class="sub-nav menus_item_child "&gt;</span></span><br><span class="line"><span class="class">              &lt;% for(let childrenLink of theme.menu[key].children){ %&gt;</span></span><br><span class="line"><span class="class">                &lt;li&gt;</span></span><br><span class="line"><span class="class">                  &lt;a href="&lt;%- url_for(childrenLink.url)%&gt;" &gt;</span></span><br><span class="line"><span class="class">                    &lt;% if (childrenLink.icon &amp;&amp; childrenLink.icon.length &gt; 0) {</span> %&gt;</span><br><span class="line">                      &lt;i <span class="class"><span class="keyword">class</span>="<span class="title">fa</span> &lt;%- childrenLink.icon %&gt;" <span class="title">style</span>="<span class="title">margin</span>-<span class="title">top</span>:</span> <span class="number">-20</span>px;<span class="string">"&gt;&lt;/i&gt;</span></span><br><span class="line"><span class="string">                    &lt;% } %&gt;</span></span><br><span class="line"><span class="string">                    &lt;span&gt;&lt;%- childrenLink.name %&gt;&lt;/span&gt;</span></span><br><span class="line"><span class="string">                  &lt;/a&gt;</span></span><br><span class="line"><span class="string">                &lt;/li&gt;</span></span><br><span class="line"><span class="string">              &lt;% } %&gt;</span></span><br><span class="line"><span class="string">            &lt;/ul&gt;</span></span><br><span class="line"><span class="string">          &lt;% } %&gt;</span></span><br><span class="line"><span class="string">      &lt;/li&gt;</span></span><br><span class="line"><span class="string">    &lt;% }); %&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &lt;li&gt;</span></span><br><span class="line"><span class="string">        &lt;a href="</span>#searchModal<span class="string">" class="</span>modal-trigger waves-effect waves-light<span class="string">"&gt;</span></span><br><span class="line">            &lt;i id="searchIcon" class="fa fa-search" title="&lt;%= __('search') %&gt;"&gt;&lt;/i&gt;</span><br><span class="line">        &lt;/a&gt;</span><br><span class="line">    &lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br></pre></td></tr></tbody></table></figure><p>第三步，在<code>/themes/matery/source/css</code>中找到<code>matery.css</code>，在最后添加下面这段代码：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*二级菜单样式定义*/</span></span><br><span class="line">.nav-menu {}</span><br><span class="line"></span><br><span class="line">.nav-menu li .sub-nav {</span><br><span class="line">    position: absolute;</span><br><span class="line">    top: <span class="number">77</span>px;</span><br><span class="line">    <span class="built_in">list</span>-style: none;</span><br><span class="line">    margin-left: <span class="number">-20</span>px;</span><br><span class="line">    display: none;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.nav-menu li .sub-nav li {</span><br><span class="line">    text-align: center;</span><br><span class="line">    clear: left;</span><br><span class="line">    width: <span class="number">140</span>px;</span><br><span class="line">    height: <span class="number">35</span>px;</span><br><span class="line">    line-height: <span class="number">35</span>px;</span><br><span class="line">    position: relative;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.nav-menu li .sub-nav li a {</span><br><span class="line">    height: <span class="number">34</span>px;</span><br><span class="line">    line-height: <span class="number">34</span>px;</span><br><span class="line">    width: <span class="number">138</span>px;</span><br><span class="line">    padding: <span class="number">0</span>px;</span><br><span class="line">    display: <span class="keyword">inline</span>-block;</span><br><span class="line">    border-radius: <span class="number">5</span>px;</span><br><span class="line">    color: #<span class="number">000</span>;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.nav-show i[aria-hidden=<span class="literal">true</span>] {</span><br><span class="line">    -webkit-transform: rotate(<span class="number">180</span>deg) !important;</span><br><span class="line">    -moz-transform: rotate(<span class="number">180</span>deg) !important;</span><br><span class="line">    -o-transform: rotate(<span class="number">180</span>deg) !important;</span><br><span class="line">    -ms-transform: rotate(<span class="number">180</span>deg) !important;</span><br><span class="line">    transform: rotate(<span class="number">180</span>deg) !important;</span><br><span class="line">    -webkit-transition: all <span class="number">.3</span>s;</span><br><span class="line">    -moz-transition: all <span class="number">.3</span>s;</span><br><span class="line">    -o-transition: all <span class="number">.3</span>s;</span><br><span class="line">    -ms-transition: all <span class="number">.3</span>s;</span><br><span class="line">    transition: all <span class="number">.3</span>s;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.menus_item_child {</span><br><span class="line">    background-color: rgba(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">.8</span>);</span><br><span class="line">    width: fit-content;</span><br><span class="line">    border-radius: <span class="number">10</span>px;</span><br><span class="line">    -webkit-box-shadow: <span class="number">0</span> <span class="number">5</span>px <span class="number">20</span>px <span class="number">-4</span><span class="function">px <span class="title">rgba</span><span class="params">(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">.5</span>)</span></span>;</span><br><span class="line">    box-shadow: <span class="number">0</span> <span class="number">5</span>px <span class="number">20</span>px <span class="number">-4</span><span class="function">px <span class="title">rgba</span><span class="params">(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">.5</span>)</span></span>;</span><br><span class="line">    display: none;</span><br><span class="line">    opacity: <span class="number">0.98</span>;</span><br><span class="line">    -ms-filter: none;</span><br><span class="line">    filter: none;</span><br><span class="line">    -webkit-animation: sub_menus <span class="number">.3</span>s <span class="number">.1</span>s ease both;</span><br><span class="line">    -moz-animation: sub_menus <span class="number">.3</span>s <span class="number">.1</span>s ease both;</span><br><span class="line">    -o-animation: sub_menus <span class="number">.3</span>s <span class="number">.1</span>s ease both;</span><br><span class="line">    -ms-animation: sub_menus <span class="number">.3</span>s <span class="number">.1</span>s ease both;</span><br><span class="line">    animation: sub_menus <span class="number">.3</span>s <span class="number">.1</span>s ease both;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.menus_item_child:before {</span><br><span class="line">    content: <span class="string">""</span>;</span><br><span class="line">    position: absolute;</span><br><span class="line">    top: <span class="number">-20</span>px;</span><br><span class="line">    left: <span class="number">50</span>%;</span><br><span class="line">    margin-left: <span class="number">-10</span>px;</span><br><span class="line">    border-width: <span class="number">10</span>px;</span><br><span class="line">    border-style: solid;</span><br><span class="line">    border-color: <span class="function">transparent transparent <span class="title">rgba</span><span class="params">(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">.8</span>)</span></span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.m-nav-item {</span><br><span class="line">    <span class="comment">/* position: relative; */</span></span><br><span class="line">    left: <span class="number">45</span>px</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.m-nav-item ul {</span><br><span class="line">    display: none;</span><br><span class="line">    background: rgba(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">.1</span>);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.m-nav-item ul li {</span><br><span class="line">    width: <span class="number">245</span>px;</span><br><span class="line">    height: <span class="number">50</span>px;</span><br><span class="line">    line-height: <span class="number">50</span>px;</span><br><span class="line">    text-align: center;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.m-nav-show .m-icon {</span><br><span class="line">    -webkit-transform: rotate(<span class="number">90</span>deg) !important;</span><br><span class="line">    -moz-transform: rotate(<span class="number">90</span>deg) !important;</span><br><span class="line">    -o-transform: rotate(<span class="number">90</span>deg) !important;</span><br><span class="line">    -ms-transform: rotate(<span class="number">90</span>deg) !important;</span><br><span class="line">    transform: rotate(<span class="number">90</span>deg) !important;</span><br><span class="line">    -webkit-transition: all <span class="number">.3</span>s;</span><br><span class="line">    -moz-transition: all <span class="number">.3</span>s;</span><br><span class="line">    -o-transition: all <span class="number">.3</span>s;</span><br><span class="line">    -ms-transition: all <span class="number">.3</span>s;</span><br><span class="line">    transition: all <span class="number">.3</span>s;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.m-nav-show .m-nav-item&gt;a:hover {</span><br><span class="line">    color: #FFF;</span><br><span class="line">    background: rgba(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">.8</span>);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.m-nav-show&gt;a:before,</span><br><span class="line">.m-nav-item&gt;a:hover:before {</span><br><span class="line">    opacity: <span class="number">1</span>;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.m-nav-item .m-icon {</span><br><span class="line">    position: absolute;</span><br><span class="line">    right: <span class="number">65</span>px;</span><br><span class="line">    height: <span class="number">50</span>px;</span><br><span class="line">    padding: <span class="number">0</span>px;</span><br><span class="line">    margin: <span class="number">0</span>px;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">.nav-item li:hover a {</span><br><span class="line">    color: #FFF;</span><br><span class="line">    background: rgba(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">.1</span>);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>第四步，在<code>/themes/matery/source/js</code>中找到<code>matery.js</code>，在最后一个 });前添加下面这段代码：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 增加二级菜单功能</span></span><br><span class="line">    $(<span class="string">".nav-menu&gt;li"</span>).hover(function(){</span><br><span class="line">        $(this).children('ul').stop(true,true).show();</span><br><span class="line">        $(this).addClass('nav-show').siblings('li').removeClass('nav-show');</span><br><span class="line"></span><br><span class="line">    },function(){</span><br><span class="line">        $(this).children('ul').stop(true,true).hide();</span><br><span class="line">        $('.nav-item.nav-show').removeClass('nav-show');</span><br><span class="line">    })</span><br><span class="line"></span><br><span class="line">    $('.m-nav-item&gt;a').on('click',function(){</span><br><span class="line">            if ($(this).next('ul').css('display') == "none") {</span><br><span class="line">                $('.m-nav-item').children('ul').slideUp(300);</span><br><span class="line">                $(this).next('ul').slideDown(300);</span><br><span class="line">                $(this).parent('li').addClass('m-nav-show').siblings('li').removeClass('m-nav-show');</span><br><span class="line">            }<span class="keyword">else</span>{</span><br><span class="line">                $(this).next('ul').slideUp(300);</span><br><span class="line">                $('.m-nav-item.m-nav-show').removeClass('m-nav-show');</span><br><span class="line">            }</span><br><span class="line">    });</span><br></pre></td></tr></tbody></table></figure><p>第五步，在主题配置文件<code>.yml</code>修改标题栏内容，按下面格式更改:</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">标题一级:</span><br><span class="line">  url: /XXX</span><br><span class="line">  icon: fa-XXXX</span><br><span class="line">  children:</span><br><span class="line">    -</span><br><span class="line">      name: 标题二级<span class="number">1</span></span><br><span class="line">      url: /XXX/XXX</span><br><span class="line">      icon: fa-XXXX</span><br><span class="line">    -</span><br><span class="line">      name: 标题二级<span class="number">2</span></span><br><span class="line">      url: /XXX/XXX</span><br><span class="line">      icon: fa-XXXX</span><br></pre></td></tr></tbody></table></figure><p>第六步，<code>source</code>文件夹新疆对应的标题目录，并放<code>index.md</code>模板就行了。</p><h3 id="3-参考链接"><a href="#3-参考链接" class="headerlink" title="3.参考链接"></a>3.参考链接</h3><ol><li><a href="https://sunhwee.coding.me/posts/6e8839eb.html#toc-heading-38" target="_blank" rel="noopener">洪卫の博客</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hill密码加密解密</title>
      <link href="/article/cded.html"/>
      <url>/article/cded.html</url>
      
        <content type="html"><![CDATA[<p>用C++实现Hill密码加解密</p><a id="more"></a><h2 id="希尔密码加密解密原理"><a href="#希尔密码加密解密原理" class="headerlink" title="希尔密码加密解密原理:"></a>希尔密码加密解密原理:</h2><p>  希尔密码是运用基本矩阵论原理的替换密码。每个字母当作26进制数字：A=0，B=1…一串字母当成n维向量，跟一个n×n的矩阵相乘，再将得出的结果MOD 26。注意用作加密的矩阵（即密钥）必须是可逆的，否则就不可能译码。只有矩阵的行列式和26互质，才是可逆的。</p><h3 id="1、产生随机矩阵，输入明文，产生密文"><a href="#1、产生随机矩阵，输入明文，产生密文" class="headerlink" title="1、产生随机矩阵，输入明文，产生密文"></a>1、产生随机矩阵，输入明文，产生密文</h3><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*hillcrypto.cpp*/</span></span><br><span class="line"><span class="comment">/*理解算法最重要，最好自己动手实现试试看，可以使用MFC写一个简单的交互界面*/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;ctime&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*定义一些常变量*/</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> M = <span class="number">26</span>;   <span class="comment">//定义集合{a,b,...,z}的26个英文字母</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//行和列均为5</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> ROW = <span class="number">5</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> COL = <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//定义5*5的加密矩阵</span></span><br><span class="line"><span class="keyword">int</span> K[ROW][COL];</span><br><span class="line"></span><br><span class="line"><span class="comment">//定义5*5的解密矩阵</span></span><br><span class="line"><span class="keyword">int</span> D[ROW][COL];</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> P[ROW];  <span class="comment">//明文单元</span></span><br><span class="line"><span class="keyword">int</span> C[ROW];  <span class="comment">//密文单元</span></span><br><span class="line"><span class="keyword">int</span> F[ROW];  <span class="comment">//密文解密后的单元</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*三元组gcd(a,b) = ax + by = d */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">GCD</span></span></span><br><span class="line"><span class="class">{</span></span><br><span class="line">    <span class="keyword">int</span> x;</span><br><span class="line">    <span class="keyword">int</span> y;</span><br><span class="line">    <span class="keyword">int</span> d;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Hill_Cipher</span></span></span><br><span class="line"><span class="class">{</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">//产生随机矩阵</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">random_Matrix</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">//求矩阵的行列式</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">Det</span><span class="params">(<span class="keyword">int</span> matrix[ROW][ROW],<span class="keyword">int</span> row)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//求两个数的最大公约数</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">gcd</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     *判断矩阵K是否在模26的情况下可逆</span></span><br><span class="line"><span class="comment">     *因为矩阵在模26的情形下存在可逆矩阵的充分必要条件是</span></span><br><span class="line"><span class="comment">     *gcd(det K,26) = 1</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Inverse</span><span class="params">(<span class="keyword">int</span> matrix[ROW][ROW])</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//矩阵相乘</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">multiphy</span><span class="params">(<span class="keyword">int</span> matrix[ROW][ROW],<span class="keyword">int</span> p[ROW],<span class="keyword">int</span> row)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//求出伴随矩阵</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">adjoint_matrix</span><span class="params">(<span class="keyword">int</span> matrix[ROW][ROW],<span class="keyword">int</span> row)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将明文加密为密文</span></span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">encryption</span><span class="params">(<span class="built_in">string</span> plaintext)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将密文解密为明文(为了辨识清楚,我们统一以小写字母作为明文,大写字母作为密文)</span></span><br><span class="line">    <span class="function"><span class="built_in">string</span> <span class="title">deciphering</span><span class="params">(<span class="built_in">string</span> ciphertext)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//欧几里得算法求模的逆</span></span><br><span class="line">    <span class="function">GCD <span class="title">extended_Euclid</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//模逆运算</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">inverse</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> m)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//由于C++不存在负数取模的内置函数,现在自己设定一个</span></span><br><span class="line">    <span class="comment">//定义一个模M的值</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">Mod</span><span class="params">(<span class="keyword">int</span> a)</span></span>;</span><br><span class="line">};</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> Hill_Cipher::random_Matrix()</span><br><span class="line">{</span><br><span class="line">    <span class="keyword">int</span> i,j;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; ROW;i++)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>;j &lt; COL;j++)</span><br><span class="line">        {</span><br><span class="line">            K[i][j] = rand() % <span class="number">26</span>;  <span class="comment">//产生一个5*5模26的矩阵</span></span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//求矩阵的行列式</span></span><br><span class="line"><span class="keyword">int</span> Hill_Cipher::Det(<span class="keyword">int</span> matrix[ROW][ROW],<span class="keyword">int</span> row)</span><br><span class="line">{</span><br><span class="line">    <span class="keyword">int</span> i,j;</span><br><span class="line">    <span class="keyword">int</span> cofa[ROW][ROW];            <span class="comment">//用于存放余子阵</span></span><br><span class="line">    <span class="keyword">int</span> l;   <span class="comment">//l为所递归的余子阵的行</span></span><br><span class="line">    <span class="keyword">int</span> p = <span class="number">0</span>,q = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> sum=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//由于行和列相同(方阵),所以行列式的值一定存在,故不需要判断是否为方阵</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//递归基</span></span><br><span class="line">    <span class="keyword">if</span>(row == <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> matrix[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">   <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; row; i++)</span><br><span class="line">   {</span><br><span class="line">     <span class="keyword">for</span>(l = <span class="number">0</span>;l &lt; row - <span class="number">1</span>;l++)</span><br><span class="line">     {</span><br><span class="line">       <span class="keyword">if</span>(l &lt; i)</span><br><span class="line">           p=<span class="number">0</span>;</span><br><span class="line">       <span class="keyword">else</span></span><br><span class="line">           p=<span class="number">1</span>;</span><br><span class="line">       <span class="keyword">for</span>(j = <span class="number">0</span>;j&lt; row - <span class="number">1</span>;j++)</span><br><span class="line">       {</span><br><span class="line">         cofa[l][j] = matrix[l + p][j + <span class="number">1</span>];</span><br><span class="line">       }</span><br><span class="line">     }</span><br><span class="line">     <span class="comment">//相当于(-1)^i</span></span><br><span class="line">     <span class="keyword">if</span>(i % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">         q=<span class="number">1</span>;</span><br><span class="line">     <span class="keyword">else</span></span><br><span class="line">         q=(<span class="number">-1</span>);</span><br><span class="line">     sum = sum + matrix[i][<span class="number">0</span>] * q * Det(cofa,row - <span class="number">1</span>);</span><br><span class="line">   }</span><br><span class="line">   <span class="keyword">return</span> sum;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//求两个数的最大公约数</span></span><br><span class="line"><span class="keyword">int</span> Hill_Cipher::gcd(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span><br><span class="line">{</span><br><span class="line">    <span class="keyword">int</span> temp;</span><br><span class="line">    <span class="comment">//交换两个数的大小,使得a为较大数</span></span><br><span class="line">    <span class="keyword">if</span>(a &lt; b)</span><br><span class="line">    {</span><br><span class="line">        temp = a;</span><br><span class="line">        a = b;</span><br><span class="line">        b = temp;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">while</span>(a % b)</span><br><span class="line">    {</span><br><span class="line">        temp = b;</span><br><span class="line">        b = a % b;</span><br><span class="line">        a = temp;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> b;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *判断矩阵K是否在模26的情况下可逆</span></span><br><span class="line"><span class="comment"> *因为矩阵在模26的情形下存在可逆矩阵的充分必要条件是</span></span><br><span class="line"><span class="comment"> *gcd(det K,26) = 1</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">bool</span> Hill_Cipher::Inverse(<span class="keyword">int</span> matrix[ROW][ROW])</span><br><span class="line">{</span><br><span class="line">    <span class="keyword">if</span>(gcd(Det(matrix,ROW),M) == <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> Hill_Cipher::multiphy(<span class="keyword">int</span> matrix[ROW][ROW],<span class="keyword">int</span> p[ROW],<span class="keyword">int</span> row)</span><br><span class="line">{</span><br><span class="line">    <span class="keyword">int</span> i,j;</span><br><span class="line">    <span class="comment">//先将密文单元清零</span></span><br><span class="line">    <span class="built_in">memset</span>(C,<span class="number">0</span>,<span class="keyword">sizeof</span>(C));</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; ROW;i++)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>;j &lt; ROW;j++)</span><br><span class="line">        {</span><br><span class="line">            C[i] += P[j] * K[j][i];</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//将明文加密为密文</span></span><br><span class="line"><span class="built_in">string</span> Hill_Cipher::encryption(<span class="built_in">string</span> plaintext)</span><br><span class="line">{</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="built_in">string</span> ciphertext;</span><br><span class="line">    <span class="comment">//将字符串转化为明文数组</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; ROW;i++)</span><br><span class="line">    {</span><br><span class="line">        P[i] = plaintext[i] - <span class="string">'a'</span>;</span><br><span class="line">    }</span><br><span class="line">    multiphy(K,P,ROW);</span><br><span class="line">    <span class="comment">//将密文数组转化为密文</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; ROW;i++)</span><br><span class="line">        <span class="comment">//这里先将其模26,再翻译为对应的字母</span></span><br><span class="line">    {</span><br><span class="line">        C[i] =Mod(C[i]);</span><br><span class="line">        ciphertext += C[i] + <span class="string">'A'</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> ciphertext;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//求出伴随矩阵</span></span><br><span class="line"><span class="keyword">void</span> Hill_Cipher::adjoint_matrix(<span class="keyword">int</span> matrix[ROW][ROW],<span class="keyword">int</span> row)</span><br><span class="line">{</span><br><span class="line">    <span class="keyword">int</span> i,j,k,l;</span><br><span class="line">    <span class="keyword">int</span> p,q;</span><br><span class="line">    p = q = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> temp[ROW][ROW];</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; ROW;i++)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>;j &lt; ROW;j++)</span><br><span class="line">        {</span><br><span class="line">            <span class="keyword">for</span>(k = <span class="number">0</span>;k &lt; ROW - <span class="number">1</span>;k++)</span><br><span class="line">            {</span><br><span class="line">                <span class="keyword">if</span>(k &lt; i)</span><br><span class="line">                    p = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    p = <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">for</span>(l = <span class="number">0</span>;l &lt; ROW - <span class="number">1</span>;l++)</span><br><span class="line">                {</span><br><span class="line">                    <span class="keyword">if</span>(l &lt; j)</span><br><span class="line">                        q = <span class="number">0</span>;</span><br><span class="line">                    <span class="keyword">else</span></span><br><span class="line">                        q = <span class="number">1</span>;</span><br><span class="line">                    temp[k][l] = matrix[k+p][l+q];</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            D[j][i] = (<span class="keyword">int</span>)<span class="built_in">pow</span>(<span class="number">-1</span>,(<span class="keyword">double</span>)i+j)*Det(temp,ROW<span class="number">-1</span>);</span><br><span class="line">            D[j][i] = Mod(D[j][i]);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//将密文解密为明文(为了辨识清楚,我们统一以小写字母作为明文,大写字母作为密文)</span></span><br><span class="line"><span class="built_in">string</span> Hill_Cipher::deciphering(<span class="built_in">string</span> ciphertext)</span><br><span class="line">{</span><br><span class="line">    <span class="comment">//求出矩阵的逆</span></span><br><span class="line">    <span class="built_in">string</span> text;</span><br><span class="line">    <span class="keyword">int</span> determinant = Det(K,ROW);</span><br><span class="line">    <span class="keyword">int</span> inver = inverse(determinant,<span class="number">26</span>);</span><br><span class="line">    adjoint_matrix(K,ROW);   <span class="comment">//伴随矩阵</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"行列式的值: "</span> &lt;&lt; determinant &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">int</span> i,j;</span><br><span class="line">    <span class="built_in">memset</span>(F,<span class="number">0</span>,<span class="keyword">sizeof</span>(F));</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; ROW;i++)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>;j &lt; ROW;j++)</span><br><span class="line">        {</span><br><span class="line">            F[i] += C[j] * D[j][i];</span><br><span class="line">        }</span><br><span class="line">        F[i] *= inver;</span><br><span class="line">        F[i] = Mod(F[i]);   <span class="comment">//算到的结果要模去26</span></span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; ROW;i++)</span><br><span class="line">        text += F[i] + <span class="string">'a'</span>;</span><br><span class="line">    <span class="keyword">return</span> text;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">GCD Hill_Cipher::extended_Euclid(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span><br><span class="line">{</span><br><span class="line">    GCD aa,bb;</span><br><span class="line">    <span class="keyword">if</span>(b == <span class="number">0</span>)</span><br><span class="line">    {</span><br><span class="line">        aa.x = <span class="number">1</span>;</span><br><span class="line">        aa.y = <span class="number">0</span>;</span><br><span class="line">        aa.d = a;</span><br><span class="line">        <span class="keyword">return</span> aa;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    {</span><br><span class="line">        bb = extended_Euclid(b,a%b);</span><br><span class="line">        aa.x = bb.y;</span><br><span class="line">        aa.y = bb.x - (a / b) * bb.y;</span><br><span class="line">        aa.d = bb.d;</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> aa;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> Hill_Cipher::inverse(<span class="keyword">int</span> a,<span class="keyword">int</span> m)</span><br><span class="line">{</span><br><span class="line">    GCD aa;</span><br><span class="line">    aa = extended_Euclid(a,m);</span><br><span class="line">    <span class="keyword">return</span> aa.x;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> Hill_Cipher::Mod(<span class="keyword">int</span> a)</span><br><span class="line">{</span><br><span class="line">    <span class="keyword">return</span> a &gt;= <span class="number">0</span> ? a % M : (M + a % M);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">int</span> i,j;</span><br><span class="line">    Hill_Cipher hh;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"使用希尔密码进行消息的加解密:"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//srand()函数产生一个以当前时间开始的随机种子.以保证每次产生的随机数矩阵都不相同</span></span><br><span class="line">    srand((<span class="keyword">unsigned</span>)time(<span class="number">0</span>));</span><br><span class="line">    hh.random_Matrix();</span><br><span class="line">    <span class="keyword">while</span>(!hh.Inverse(K))</span><br><span class="line">    {</span><br><span class="line">        hh.random_Matrix();</span><br><span class="line">    }</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"随机产生5*5的矩阵:"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; ROW;i++)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>;j &lt; COL;j++)</span><br><span class="line">        {</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%2d  "</span>,K[i][j]);</span><br><span class="line">        }</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"该矩阵模26可逆,因此可以作为密钥."</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//利用所选密钥，对给定的5元明文信息进行加解密</span></span><br><span class="line">    <span class="built_in">string</span> plaintext,ciphertext;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"请输入5元明文信息:"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cin</span> &gt;&gt; plaintext;</span><br><span class="line">    ciphertext = hh.encryption(plaintext);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"该明文通过希尔密码法加密过后,输出的密文消息为:"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; ciphertext &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入0:退出          ***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入1:查看明文空间对***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入2:查看密文空间对***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入3:查看密钥      ***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入4:将消息解密    ***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入5:查看菜单      ***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">char</span> c;</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">cin</span> &gt;&gt; c)</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">if</span>(c == <span class="string">'0'</span>)</span><br><span class="line">        {</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"退出"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(c == <span class="string">'1'</span>)</span><br><span class="line">        {</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"明文空间:"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; ROW;i++)</span><br><span class="line">                <span class="built_in">cout</span> &lt;&lt; P[i] &lt;&lt; <span class="string">"  "</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(c == <span class="string">'2'</span>)</span><br><span class="line">        {</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"密文空间:"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; ROW;i++)</span><br><span class="line">                <span class="built_in">cout</span> &lt;&lt; C[i] &lt;&lt; <span class="string">"  "</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(c == <span class="string">'3'</span>)</span><br><span class="line">        {</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"密钥:"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; ROW;i++)</span><br><span class="line">            {</span><br><span class="line">                <span class="keyword">for</span>(j = <span class="number">0</span>;j &lt; ROW;j++)</span><br><span class="line">                {</span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">"%2d  "</span>,K[i][j]);</span><br><span class="line">                }</span><br><span class="line">                <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            }</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(c == <span class="string">'4'</span>)</span><br><span class="line">        {</span><br><span class="line">            hh.adjoint_matrix(K,ROW);</span><br><span class="line">            <span class="built_in">string</span> ss;</span><br><span class="line">            ss = hh.deciphering(ciphertext);</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"该密文解密过后,显示的原来的明文消息:"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; ss &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        {</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入0:退出          ***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入1:查看明文空间对***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入2:查看密文空间对***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入3:查看密钥      ***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入4:将消息解密    ***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; <span class="string">"***输入5:查看菜单      ***"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><img width="200" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040309.jpg"><h3 id="2、输入密钥矩阵，输入明文，产生密文"><a href="#2、输入密钥矩阵，输入明文，产生密文" class="headerlink" title="2、输入密钥矩阵，输入明文，产生密文"></a>2、输入密钥矩阵，输入明文，产生密文</h3><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*hill.cpp*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 100</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//按第一列展开，递归计算行列式值</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">caluDet</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">int</span> **a)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">int</span> i, r, c, p, q;</span><br><span class="line">    <span class="keyword">int</span> sum=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(n==<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> a[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">int</span> **det = (<span class="keyword">int</span>**)<span class="built_in">malloc</span>((n<span class="number">-1</span>)*<span class="keyword">sizeof</span>(<span class="keyword">int</span>*));</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;(n<span class="number">-1</span>); i++)</span><br><span class="line">        det[i] = (<span class="keyword">int</span>*)<span class="built_in">malloc</span>((n<span class="number">-1</span>)*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;n; i++) {</span><br><span class="line">        <span class="keyword">for</span>(r=<span class="number">0</span>; r&lt;n<span class="number">-1</span>; r++) {         <span class="comment">//子矩阵 (n-1) 行</span></span><br><span class="line">            <span class="keyword">if</span>(r&lt;i) p = <span class="number">0</span>;              <span class="comment">//当前行 a[r] 赋值给子矩阵</span></span><br><span class="line">            <span class="keyword">else</span>    p = <span class="number">1</span>;             <span class="comment">//下一行 a[r+1] 赋值给子矩阵</span></span><br><span class="line">            <span class="keyword">for</span>(c=<span class="number">0</span>; c&lt;n<span class="number">-1</span>; c++)        <span class="comment">//子矩阵 (n-1) 列</span></span><br><span class="line">                det[r][c] = a[r+p][c+<span class="number">1</span>];</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span>(i%<span class="number">2</span>==<span class="number">0</span>) q = <span class="number">1</span>;               <span class="comment">//由于是对第一列展开，即 [i][0]</span></span><br><span class="line">        <span class="keyword">else</span> q = <span class="number">-1</span>;</span><br><span class="line">        sum = sum + a[i][<span class="number">0</span>] * q*caluDet(n<span class="number">-1</span>,det);</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;(n<span class="number">-1</span>); i++)</span><br><span class="line">        <span class="built_in">free</span>(det[i]);</span><br><span class="line">    <span class="built_in">free</span>(det);</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//初始化明文</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initPlain</span><span class="params">(<span class="keyword">char</span> p[], <span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">int</span> i, len, t;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"输入明文p: \n"</span>;</span><br><span class="line">    getchar(); gets(p);</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;<span class="built_in">strlen</span>(p); i++) {</span><br><span class="line">        <span class="keyword">if</span> (p[i] ==<span class="string">' '</span>)             <span class="comment">//跳过空格</span></span><br><span class="line">            <span class="built_in">strcpy</span>(p+i,p+i+<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span> (p[i]&gt;=<span class="string">'a'</span> &amp;&amp; p[i]&lt;=<span class="string">'z'</span>)  <span class="comment">//小写转大写</span></span><br><span class="line">            p[i] -= <span class="number">32</span>;</span><br><span class="line">    }</span><br><span class="line">    len = <span class="built_in">strlen</span>(p);</span><br><span class="line">    t = len%n&gt;<span class="number">0</span> ? n-len%n : len%n;</span><br><span class="line">    <span class="keyword">while</span>(t--)     <span class="comment">//若最后一个明文对字母不足，则添加与最后一个明文相同的字母</span></span><br><span class="line">        p[<span class="built_in">strlen</span>(p)] = p[len<span class="number">-1</span>];</span><br><span class="line">    p[<span class="built_in">strlen</span>(p)] = <span class="string">'\0'</span>;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt;<span class="string">"\nInit P: "</span> &lt;&lt; p &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//输入密钥矩阵</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">keyMatrix</span><span class="params">(<span class="keyword">int</span> **det, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">int</span> i, j;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;len; i++)</span><br><span class="line">        <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;len; j++)</span><br><span class="line">            <span class="built_in">cin</span> &gt;&gt; det[i][j];</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//分组、矩阵乘法</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">matricMultiply</span><span class="params">(<span class="keyword">char</span> p[], <span class="keyword">char</span> c[], <span class="keyword">int</span> **key, <span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">int</span> i,j,k;</span><br><span class="line">    <span class="keyword">int</span> len = <span class="built_in">strlen</span>(p);</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;<span class="built_in">strlen</span>(p)/n; i++){       <span class="comment">//明文每 n 个作为一行</span></span><br><span class="line">        <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;n; j++){             <span class="comment">//明文的列、密钥矩阵的列</span></span><br><span class="line">            <span class="keyword">for</span>(k=<span class="number">0</span>; k&lt;n; k++){         <span class="comment">//密钥矩阵的行</span></span><br><span class="line">                c[n*i+j] += ((p[n*i+k]-<span class="string">'A'</span>) * key[k][j]) % <span class="number">26</span>;</span><br><span class="line">            }</span><br><span class="line">            c[n*i+j] = c[n*i+j] % <span class="number">26</span> + <span class="string">'A'</span>;</span><br><span class="line">            <span class="comment">//cout &lt;&lt; (int)c[n*i+j] &lt;&lt; " ";</span></span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Cipher: "</span> &lt;&lt; c &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="keyword">int</span> i, j, n, len;</span><br><span class="line">    <span class="keyword">char</span> p[N]={<span class="number">0</span>}, c[N]={<span class="number">0</span>};</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"输入密钥的阶：\n"</span>;</span><br><span class="line">    <span class="built_in">cin</span> &gt;&gt; n;</span><br><span class="line">    <span class="comment">//为密钥矩阵申请内存空间</span></span><br><span class="line">    <span class="keyword">int</span> **key = (<span class="keyword">int</span>**)<span class="built_in">malloc</span>(n*<span class="keyword">sizeof</span>(<span class="keyword">int</span>*));</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;n; i++)</span><br><span class="line">        key[i] = (<span class="keyword">int</span>*)<span class="built_in">malloc</span>(n*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    <span class="comment">//获取密钥矩阵并验证是否可逆</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"输入"</span> &lt;&lt;n&lt;&lt;<span class="string">"阶密钥矩阵：\n"</span>;</span><br><span class="line">    keyMatrix(key,n);</span><br><span class="line">    <span class="keyword">while</span>(!caluDet(n, key)) {</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"密钥不存在逆矩阵! 请重新输入：\n"</span>;</span><br><span class="line">        keyMatrix(key,n);</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">//初始化明文</span></span><br><span class="line">    initPlain(p, n);</span><br><span class="line">    len = <span class="built_in">strlen</span>(p);</span><br><span class="line">    <span class="comment">//各组明文乘密钥矩阵加密</span></span><br><span class="line">    matricMultiply (p, c, key, n);</span><br><span class="line">    <span class="comment">//释放密钥矩阵的内存空间</span></span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;n; i++)</span><br><span class="line">        <span class="built_in">free</span>(key[i]);</span><br><span class="line">    <span class="built_in">free</span>(key);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h4 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h4><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040308.jpg"><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 密码学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hill </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sierpinski 镂垫程序</title>
      <link href="/article/d9d1.html"/>
      <url>/article/d9d1.html</url>
      
        <content type="html"><![CDATA[<p>用C++实现三个 Sierpinski 镂垫程序</p><a id="more"></a><blockquote><p>Sierpinski镂垫是一个非常有趣的图案，有着悠久的历史， 在分形几何中等领域里引起了人们极大地兴趣， 是用递归和随机方式定义的几何形状。</p></blockquote><p>生成算法如下：</p><ol><li>在三角形内部随机选取一个点作为初始点；</li><li>在三角形的3个顶点中随机选取一个，求出该顶点与初始点连线的中点，画出该中点；</li><li>将第二步中的中点作为初始点，循环第二步；</li></ol><h2 id="Sierpinski镂垫"><a href="#Sierpinski镂垫" class="headerlink" title="Sierpinski镂垫"></a>Sierpinski镂垫</h2><h3 id="二维Sierpinski镂垫"><a href="#二维Sierpinski镂垫" class="headerlink" title="二维Sierpinski镂垫"></a>二维Sierpinski镂垫</h3><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*使用随机选择的顶点和中点绘制二维Sierpinski镂垫*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;windows.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myinit</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">  glClearColor(<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>);<span class="comment">/*白色背景*/</span></span><br><span class="line">  glColor3f(<span class="number">1.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>);<span class="comment">/*红色*/</span></span><br><span class="line"></span><br><span class="line">  glMatrixMode(GL_PROJECTION);</span><br><span class="line">  glLoadIdentity();</span><br><span class="line">  gluOrtho2D(<span class="number">0.0</span>,<span class="number">50.0</span>,<span class="number">0.0</span>,<span class="number">50.0</span>);<span class="comment">/*50×50相机坐标窗口与原点左下角*/</span></span><br><span class="line">  glMatrixMode(GL_MODELVIEW);</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">  GLfloat vertices[<span class="number">3</span>][<span class="number">2</span>]={{<span class="number">0.0</span>,<span class="number">0.0</span>},{<span class="number">25.0</span>,<span class="number">50.0</span>},{<span class="number">50.0</span>,<span class="number">0.0</span>}};</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> j,k;</span><br><span class="line">  <span class="function"><span class="keyword">int</span> <span class="title">rand</span><span class="params">()</span></span>;<span class="comment">/*产生随机数*/</span></span><br><span class="line">  GLfloat p[<span class="number">2</span>]={<span class="number">7.5</span>,<span class="number">5.0</span>};<span class="comment">/*在三角形内任意初始点*/</span></span><br><span class="line">  glClear(GL_COLOR_BUFFER_BIT);<span class="comment">/*清理窗口*/</span></span><br><span class="line"></span><br><span class="line">  glBegin(GL_POINTS);<span class="comment">/*产生5000个新点*/</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(k=<span class="number">0</span>;k&lt;<span class="number">5000</span>;k++)</span><br><span class="line">  {</span><br><span class="line">    j=rand()%<span class="number">3</span>;<span class="comment">/*随机选择一个顶点*/</span></span><br><span class="line">    <span class="comment">/*计算点位于选定顶点和旧点之间*/</span></span><br><span class="line">    p[<span class="number">0</span>]=(p[<span class="number">0</span>]+vertices[j][<span class="number">0</span>])/<span class="number">2.0</span>;</span><br><span class="line">    p[<span class="number">1</span>]=(p[<span class="number">1</span>]+vertices[j][<span class="number">1</span>])/<span class="number">2.0</span>;</span><br><span class="line">    <span class="comment">/*画新点*/</span></span><br><span class="line">    glVertex2fv(p);</span><br><span class="line">  }</span><br><span class="line">  glEnd();</span><br><span class="line">  glFlush();<span class="comment">/*清除缓冲帧*/</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc,<span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">  glutInit(&amp;argc,argv);<span class="comment">/*标准的GLUT初始化*/</span></span><br><span class="line">  glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB);<span class="comment">/*默认设置*/</span></span><br><span class="line">  glutInitWindowSize(<span class="number">500</span>,<span class="number">500</span>);<span class="comment">/*500×500像素窗口*/</span></span><br><span class="line">  glutInitWindowPosition(<span class="number">0</span>,<span class="number">0</span>);<span class="comment">/*将窗口放在左下角*/</span></span><br><span class="line">  glutCreateWindow(<span class="string">"Sierpinski Gasket"</span>);<span class="comment">/*窗口名*/</span></span><br><span class="line">  glutDisplayFunc(display);<span class="comment">/*窗口打开时调用的显示回调*/</span></span><br><span class="line">  myinit();<span class="comment">/*设置属性*/</span></span><br><span class="line">  glutMainLoop();<span class="comment">/*进入事件循环*/</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040314.jpg"><h3 id="生成-Sierpinski-镂垫的递归程序"><a href="#生成-Sierpinski-镂垫的递归程序" class="headerlink" title="生成 Sierpinski 镂垫的递归程序"></a>生成 Sierpinski 镂垫的递归程序</h3><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 通过细分三角形的方法生成Sierpinski镂垫 */</span></span><br><span class="line"><span class="comment">/* 通过命令行输入递归的次数 */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="comment">/* 初始的三角形 */</span></span><br><span class="line">GLfloat v[<span class="number">3</span>][<span class="number">2</span>]={{<span class="number">-1.0</span>, <span class="number">-0.58</span>}, {<span class="number">1.0</span>, <span class="number">-0.58</span>}, {<span class="number">0.0</span>, <span class="number">1.15</span>}};</span><br><span class="line"><span class="keyword">int</span> n;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">triangle</span><span class="params">( GLfloat *a, GLfloat *b, GLfloat *c)</span></span></span><br><span class="line"><span class="function"><span class="comment">/* 定义某个三角形 */</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"> glVertex2fv(a);</span><br><span class="line"> glVertex2fv(b);</span><br><span class="line"> glVertex2fv(c);</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">divide_triangle</span><span class="params">(GLfloat *a, GLfloat *b, GLfloat *c, <span class="keyword">int</span> m)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"><span class="comment">/* 基于某个顶点的数量对三角形进行细分处理 */</span></span><br><span class="line"> GLfloat v0[<span class="number">2</span>], v1[<span class="number">2</span>], v2[<span class="number">2</span>];</span><br><span class="line"> <span class="keyword">int</span> j;</span><br><span class="line"> <span class="keyword">if</span>(m&gt;<span class="number">0</span>)</span><br><span class="line"> {</span><br><span class="line"> <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">2</span>; j++) v0[j]=(a[j]+b[j])/<span class="number">2</span>;</span><br><span class="line"> <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">2</span>; j++) v1[j]=(a[j]+c[j])/<span class="number">2</span>;</span><br><span class="line"> <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">2</span>; j++) v2[j]=(b[j]+c[j])/<span class="number">2</span>;</span><br><span class="line"> divide_triangle(a, v0, v1, m<span class="number">-1</span>);</span><br><span class="line"> divide_triangle(c, v1, v2, m<span class="number">-1</span>);</span><br><span class="line"> divide_triangle(b, v2, v0, m<span class="number">-1</span>);</span><br><span class="line"> }</span><br><span class="line"> <span class="keyword">else</span> triangle(a,b,c); <span class="comment">/* 递归结束时绘制三角形 */</span></span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">display</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">     glClear(GL_COLOR_BUFFER_BIT);</span><br><span class="line">         glBegin(GL_TRIANGLES);</span><br><span class="line">         divide_triangle(v[<span class="number">0</span>], v[<span class="number">1</span>], v[<span class="number">2</span>], n);</span><br><span class="line">         glEnd();</span><br><span class="line">     glFlush();</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myinit</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">     glMatrixMode(GL_PROJECTION);</span><br><span class="line">     glLoadIdentity();</span><br><span class="line">     gluOrtho2D(<span class="number">-2.0</span>, <span class="number">2.0</span>, <span class="number">-2.0</span>, <span class="number">2.0</span>);</span><br><span class="line">     glMatrixMode(GL_MODELVIEW);</span><br><span class="line">     glClearColor(<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>);</span><br><span class="line">     glColor3f(<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>);</span><br><span class="line">}</span><br><span class="line">main(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span><br><span class="line">{</span><br><span class="line">     n=<span class="number">3</span>;    <span class="comment">/* 或者在此输入三角形细分的步数 */</span></span><br><span class="line">     glutInit(&amp;argc, argv);</span><br><span class="line">     glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB);</span><br><span class="line">     glutInitWindowSize(<span class="number">500</span>, <span class="number">500</span>);</span><br><span class="line">     glutCreateWindow(<span class="string">"Sierpinski Gasket"</span>);</span><br><span class="line">     glutDisplayFunc(display);</span><br><span class="line">         myinit();</span><br><span class="line">     glutMainLoop();</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h4 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h4><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040312.jpg"><h3 id="三维-Sierpinski-镂垫的递归程序"><a href="#三维-Sierpinski-镂垫的递归程序" class="headerlink" title="三维 Sierpinski 镂垫的递归程序"></a>三维 Sierpinski 镂垫的递归程序</h3><h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 通过递归细分四面体方法生成Sierpinski镂垫 */</span></span><br><span class="line"><span class="comment">/* 通过命令行递归的次数 */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"><span class="comment">/* 初始的四面体 */</span></span><br><span class="line">GLfloat v[<span class="number">4</span>][<span class="number">3</span>]={{<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>},{<span class="number">0.0</span>, <span class="number">0.942809</span>, <span class="number">-0.33333</span>},</span><br><span class="line">  {<span class="number">-0.816497</span>, <span class="number">-0.471405</span>, <span class="number">-0.333333</span>},{<span class="number">0.816497</span>, <span class="number">-0.471405</span>, <span class="number">-0.333333</span>}};</span><br><span class="line">GLfloat colors[<span class="number">4</span>][<span class="number">3</span>]={{<span class="number">1.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>},{<span class="number">0.0</span>,<span class="number">1.0</span>,<span class="number">0.0</span>},</span><br><span class="line">{<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">1.0</span>},{<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>}};</span><br><span class="line"><span class="keyword">int</span> n;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">triangle</span><span class="params">( GLfloat *va, GLfloat *vb, GLfloat *vc)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"> glVertex3fv(va);</span><br><span class="line"> glVertex3fv(vb);</span><br><span class="line"> glVertex3fv(vc);</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">tetra</span><span class="params">(GLfloat *a, GLfloat *b, GLfloat *c, GLfloat *d)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"> glColor3fv(colors[<span class="number">0</span>]);</span><br><span class="line"> triangle(a,b,c);</span><br><span class="line"> glColor3fv(colors[<span class="number">1</span>]);</span><br><span class="line"> triangle(a,c,d);</span><br><span class="line"> glColor3fv(colors[<span class="number">2</span>]);</span><br><span class="line"> triangle(a,d,b);</span><br><span class="line"> glColor3fv(colors[<span class="number">3</span>]);</span><br><span class="line"> triangle(b,d,c);</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">divide_tetra</span><span class="params">(GLfloat *a, GLfloat *b, GLfloat *c, GLfloat *d, <span class="keyword">int</span> m)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"> GLfloat mid[<span class="number">6</span>][<span class="number">3</span>];</span><br><span class="line"> <span class="keyword">int</span> j;</span><br><span class="line"> <span class="keyword">if</span>(m&gt;<span class="number">0</span>)</span><br><span class="line"> {</span><br><span class="line">   <span class="comment">/* 计算六个中点 */</span></span><br><span class="line"> <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">3</span>; j++) mid[<span class="number">0</span>][j]=(a[j]+b[j])/<span class="number">2</span>;</span><br><span class="line"> <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">3</span>; j++) mid[<span class="number">1</span>][j]=(a[j]+c[j])/<span class="number">2</span>;</span><br><span class="line"> <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">3</span>; j++) mid[<span class="number">2</span>][j]=(a[j]+d[j])/<span class="number">2</span>;</span><br><span class="line"> <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">3</span>; j++) mid[<span class="number">3</span>][j]=(b[j]+c[j])/<span class="number">2</span>;</span><br><span class="line"> <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">3</span>; j++) mid[<span class="number">4</span>][j]=(c[j]+d[j])/<span class="number">2</span>;</span><br><span class="line"> <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">3</span>; j++) mid[<span class="number">5</span>][j]=(b[j]+d[j])/<span class="number">2</span>;</span><br><span class="line">   <span class="comment">/* 通过细分生成四个四面体 */</span></span><br><span class="line"> divide_tetra(a,mid[<span class="number">0</span>],mid[<span class="number">1</span>],mid[<span class="number">2</span>], m<span class="number">-1</span>);</span><br><span class="line"> divide_tetra(mid[<span class="number">0</span>],b,mid[<span class="number">3</span>],mid[<span class="number">5</span>], m<span class="number">-1</span>);</span><br><span class="line"> divide_tetra(mid[<span class="number">1</span>],mid[<span class="number">3</span>],c,mid[<span class="number">4</span>], m<span class="number">-1</span>);</span><br><span class="line"> divide_tetra(mid[<span class="number">2</span>],mid[<span class="number">4</span>],d,mid[<span class="number">5</span>], m<span class="number">-1</span>);</span><br><span class="line"> }</span><br><span class="line"> <span class="keyword">else</span>   tetra(a,b,c,d); <span class="comment">/* 递归结束时绘制四面体 */</span></span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">display</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"> glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);</span><br><span class="line"> glBegin(GL_TRIANGLES);</span><br><span class="line">     divide_tetra(v[<span class="number">0</span>],v[<span class="number">1</span>],v[<span class="number">2</span>],v[<span class="number">3</span>],n);</span><br><span class="line">     glEnd();</span><br><span class="line">     glFlush();</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myReshape</span><span class="params">(<span class="keyword">int</span> w, <span class="keyword">int</span> h)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">     glViewport(<span class="number">0</span>, <span class="number">0</span>, w, h);</span><br><span class="line">     glMatrixMode(GL_PROJECTION);</span><br><span class="line">     glLoadIdentity();</span><br><span class="line">     <span class="keyword">if</span> (w &lt;= h)</span><br><span class="line">     glOrtho(<span class="number">-2.0</span>, <span class="number">2.0</span>, <span class="number">-2.0</span> * (GLfloat) h / (GLfloat) w,</span><br><span class="line"> <span class="number">2.0</span> * (GLfloat) h / (GLfloat) w, <span class="number">-10.0</span>, <span class="number">10.0</span>);</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line">     glOrtho(<span class="number">-2.0</span> * (GLfloat) w / (GLfloat) h,</span><br><span class="line"> <span class="number">2.0</span> * (GLfloat) w / (GLfloat) h, <span class="number">-2.0</span>, <span class="number">2.0</span>, <span class="number">-10.0</span>, <span class="number">10.0</span>);</span><br><span class="line"> glMatrixMode(GL_MODELVIEW);</span><br><span class="line"> glutPostRedisplay();</span><br><span class="line">}</span><br><span class="line">main(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span><br><span class="line">{</span><br><span class="line"> n=atoi(argv[<span class="number">1</span>]);  <span class="comment">/* 或者在此处输入四面体细分的步数 */</span></span><br><span class="line"> glutInit(&amp;argc, argv);</span><br><span class="line"> glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB | GLUT_DEPTH);</span><br><span class="line"> glutInitWindowSize(<span class="number">500</span>, <span class="number">500</span>);</span><br><span class="line"> glutCreateWindow(<span class="string">"3D Gasket"</span>);</span><br><span class="line"> glutReshapeFunc(myReshape);</span><br><span class="line"> glutDisplayFunc(display);</span><br><span class="line"> glEnable(GL_DEPTH_TEST);</span><br><span class="line"> glClearColor (<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>);</span><br><span class="line"> glutMainLoop();</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h4 id="结果-2"><a href="#结果-2" class="headerlink" title="结果"></a>结果</h4><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040313.jpg"><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图形图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>球体的细分逼近程序</title>
      <link href="/article/1454.html"/>
      <url>/article/1454.html</url>
      
        <content type="html"><![CDATA[<p>用C++实现四面体递归逼近球体</p><a id="more"></a><h3 id="球体的细分逼近程序"><a href="#球体的细分逼近程序" class="headerlink" title="球体的细分逼近程序"></a>球体的细分逼近程序</h3><blockquote><p>通过递归细分四面体生成球体，三种显示模式：线性框、均匀着色，插值着色</p></blockquote><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><figure class="highlight cpp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 该程序在init()函数中还定义了材质和光源 */</span></span><br><span class="line"><span class="comment">/* mode 0 = 线性框, mode 1 = 均与着色,</span></span><br><span class="line"><span class="comment">mode 3 = 插值着色 */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;GL/glut.h&gt;</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">float</span> point[<span class="number">4</span>];</span><br><span class="line"><span class="comment">/* 初始化四面体 */</span></span><br><span class="line">point v[]={{<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>}, {<span class="number">0.0</span>, <span class="number">0.942809</span>, <span class="number">-0.33333</span>},</span><br><span class="line">    {<span class="number">-0.816497</span>, <span class="number">-0.471405</span>, <span class="number">-0.333333</span>}, {<span class="number">0.816497</span>, <span class="number">-0.471405</span>, <span class="number">-0.333333</span>}};</span><br><span class="line"></span><br><span class="line">GLfloat theta[] = {<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>};</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> n;</span><br><span class="line"><span class="keyword">int</span> mode;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">triangle</span><span class="params">( point a, point b, point c)</span></span></span><br><span class="line"><span class="function"><span class="comment">/*利用GL_LINR_LOOP模式显示一个三角形的线性图，定义一个法向量用于均匀着色，</span></span></span><br><span class="line"><span class="function"><span class="comment">定义三个法向量用于插值着色*/</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"> <span class="keyword">if</span> (mode==<span class="number">0</span>)  glBegin(GL_LINE_LOOP);</span><br><span class="line"> <span class="keyword">else</span>  glBegin(GL_POLYGON);</span><br><span class="line">    <span class="keyword">if</span>(mode==<span class="number">1</span>) glNormal3fv(a);</span><br><span class="line">    <span class="keyword">if</span>(mode==<span class="number">2</span>) glNormal3fv(a);</span><br><span class="line">     glVertex3fv(a);</span><br><span class="line">    <span class="keyword">if</span>(mode==<span class="number">2</span>) glNormal3fv(b);</span><br><span class="line">    glVertex3fv(b);</span><br><span class="line">    <span class="keyword">if</span>(mode==<span class="number">2</span>) glNormal3fv(c);</span><br><span class="line">    glVertex3fv(c);</span><br><span class="line"> glEnd();</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">normal</span><span class="params">(point p)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"><span class="comment">/* 矢量归一化 */</span></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">sqrt</span><span class="params">(<span class="keyword">double</span> d)</span></span>;</span><br><span class="line"><span class="keyword">float</span> d = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) d += p[i] * p[i];</span><br><span class="line">d = <span class="built_in">sqrt</span>(d);</span><br><span class="line"><span class="keyword">if</span> (d &gt; <span class="number">0.0</span>)</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) p[i] /= d;</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">divide_triangle</span><span class="params">(point a, point b, point c, <span class="keyword">int</span> m)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"><span class="comment">/* 基于顶点数目细分三角形，应用右手规则生成对象的外向表面 */</span></span><br><span class="line"> point v1, v2, v3;</span><br><span class="line"> <span class="keyword">int</span> j;</span><br><span class="line"> <span class="keyword">if</span>(m&gt;<span class="number">0</span>)</span><br><span class="line"> {</span><br><span class="line">    <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">3</span>; j++) v1[j]=a[j]+b[j];</span><br><span class="line">    normal(v1);</span><br><span class="line">    <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">3</span>; j++) v2[j]=a[j]+c[j];</span><br><span class="line">    normal(v2);</span><br><span class="line">    <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;<span class="number">3</span>; j++) v3[j]=b[j]+c[j];</span><br><span class="line">    normal(v3);</span><br><span class="line">    divide_triangle(a, v1, v2, m<span class="number">-1</span>);</span><br><span class="line">    divide_triangle(c, v2, v3, m<span class="number">-1</span>);</span><br><span class="line">    divide_triangle(b, v3, v1, m<span class="number">-1</span>);</span><br><span class="line">    divide_triangle(v1, v3, v2, m<span class="number">-1</span>);</span><br><span class="line"> }</span><br><span class="line"> <span class="keyword">else</span> triangle(a,b,c); <span class="comment">/* 递归结束时绘制三角形 */</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">tetrahedron</span><span class="params">(<span class="keyword">int</span> m)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"><span class="comment">/* 对四面体的表面应用三角细分 */</span></span><br><span class="line"> divide_triangle(v[<span class="number">0</span>], v[<span class="number">1</span>], v[<span class="number">2</span>], m);</span><br><span class="line"> divide_triangle(v[<span class="number">3</span>], v[<span class="number">2</span>], v[<span class="number">1</span>], m);</span><br><span class="line"> divide_triangle(v[<span class="number">0</span>], v[<span class="number">3</span>], v[<span class="number">1</span>], m);</span><br><span class="line"> divide_triangle(v[<span class="number">0</span>], v[<span class="number">2</span>], v[<span class="number">3</span>], m);</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">display</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"><span class="comment">/* 逐一显示这三种模式下的四面体 */</span></span><br><span class="line"> glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);</span><br><span class="line"> glLoadIdentity();</span><br><span class="line"> mode=<span class="number">0</span>;</span><br><span class="line"> tetrahedron(n);</span><br><span class="line"> mode=<span class="number">1</span>;</span><br><span class="line"> glTranslatef(<span class="number">-2.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>);</span><br><span class="line"> tetrahedron(n);</span><br><span class="line"> mode=<span class="number">2</span>;</span><br><span class="line"> glTranslatef(<span class="number">4.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>);</span><br><span class="line"> tetrahedron(n);</span><br><span class="line"> glFlush();</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myReshape</span><span class="params">(<span class="keyword">int</span> w, <span class="keyword">int</span> h)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line"> glViewport(<span class="number">0</span>, <span class="number">0</span>, w, h);</span><br><span class="line"> glMatrixMode(GL_PROJECTION);</span><br><span class="line"> glLoadIdentity();</span><br><span class="line"> <span class="keyword">if</span> (w &lt;= h)</span><br><span class="line">    glOrtho(<span class="number">-4.0</span>, <span class="number">4.0</span>, <span class="number">-4.0</span> * (GLfloat) h / (GLfloat) w,</span><br><span class="line">        <span class="number">4.0</span> * (GLfloat) h / (GLfloat) w, <span class="number">-10.0</span>, <span class="number">10.0</span>);</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line">    glOrtho(<span class="number">-4.0</span> * (GLfloat) w / (GLfloat) h,</span><br><span class="line">        <span class="number">4.0</span> * (GLfloat) w / (GLfloat) h, <span class="number">-4.0</span>, <span class="number">4.0</span>, <span class="number">-10.0</span>, <span class="number">10.0</span>);</span><br><span class="line"> glMatrixMode(GL_MODELVIEW);</span><br><span class="line"> display();</span><br><span class="line">}</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myinit</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    GLfloat mat_specular[]={<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>};</span><br><span class="line">    GLfloat mat_diffuse[]={<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>};</span><br><span class="line">    GLfloat mat_ambient[]={<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>};</span><br><span class="line">    GLfloat mat_shininess={<span class="number">100.0</span>};</span><br><span class="line">    GLfloat light_ambient[]={<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>};</span><br><span class="line">    GLfloat light_diffuse[]={<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>};</span><br><span class="line">    GLfloat light_specular[]={<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>};</span><br><span class="line"><span class="comment">/* 为光源0分别设置环境光、漫反射光和镜面反射光的参数 */</span></span><br><span class="line">    glLightfv(GL_LIGHT0, GL_AMBIENT, light_ambient);</span><br><span class="line">    glLightfv(GL_LIGHT0, GL_DIFFUSE, light_diffuse);</span><br><span class="line">    glLightfv(GL_LIGHT0, GL_SPECULAR, light_specular);</span><br><span class="line"><span class="comment">/* 为所有三角形正面定义材质属性 */</span></span><br><span class="line">    glMaterialfv(GL_FRONT, GL_SPECULAR, mat_specular);</span><br><span class="line">    glMaterialfv(GL_FRONT, GL_AMBIENT, mat_ambient);</span><br><span class="line">    glMaterialfv(GL_FRONT, GL_DIFFUSE, mat_diffuse);</span><br><span class="line">    glMaterialf(GL_FRONT, GL_SHININESS, mat_shininess);</span><br><span class="line">    glShadeModel(GL_SMOOTH); <span class="comment">/* 开启平滑着色 */</span></span><br><span class="line">    glEnable(GL_LIGHTING); <span class="comment">/* 开启光照 */</span></span><br><span class="line">    glEnable(GL_LIGHT0); <span class="comment">/* 开启光源0 */</span></span><br><span class="line">    glEnable(GL_DEPTH_TEST); <span class="comment">/* 开启z-buffer */</span></span><br><span class="line">    glClearColor (<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>);</span><br><span class="line">    glColor3f (<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>);</span><br><span class="line">}</span><br><span class="line">main(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span><br><span class="line">{</span><br><span class="line">    n=<span class="number">4</span>;<span class="comment">//n=1,2,3,4,5,6……</span></span><br><span class="line">  <span class="comment">//n=atoi(argv[1]);//直接运行会出错，具体参照BookCode的此处源码处理方案</span></span><br><span class="line">    glutInit(&amp;argc, argv);</span><br><span class="line">    glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB | GLUT_DEPTH);</span><br><span class="line">    glutInitWindowSize(<span class="number">500</span>, <span class="number">500</span>);</span><br><span class="line">    glutCreateWindow(<span class="string">"sphere"</span>);</span><br><span class="line">    myinit();</span><br><span class="line">    glutReshapeFunc(myReshape);</span><br><span class="line">    glutDisplayFunc(display);</span><br><span class="line">    glutMainLoop();</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><img width="300" height="200" src="https://cdn.jsdelivr.net/gh/gkm0120/CDN/images/2020040311.jpg"><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图形图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git和Node.js安装</title>
      <link href="/article/7966.html"/>
      <url>/article/7966.html</url>
      
        <content type="html"><![CDATA[<p>Git、Node.js安装</p><a id="more"></a><h2 id="Git和Node-js重新安装"><a href="#Git和Node-js重新安装" class="headerlink" title="Git和Node.js重新安装"></a>Git和Node.js重新安装</h2><h3 id="1-Git安装教程"><a href="#1-Git安装教程" class="headerlink" title="1 Git安装教程"></a>1 Git安装教程</h3><h4 id="1-1-Git下载地址"><a href="#1-1-Git下载地址" class="headerlink" title="1.1 Git下载地址"></a>1.1 <a href="https://git-scm.com/downloads" target="_blank" rel="noopener">Git下载地址</a></h4><h4 id="1-2-安装步骤："><a href="#1-2-安装步骤：" class="headerlink" title="1.2 安装步骤："></a>1.2 安装步骤：</h4><ol><li>点击next</li><li>根据自己想安装软件的位置来选择路径(我这里选择的是D:\blog)</li><li>安装配置文件，自己需要选择</li><li>不创建启动文件夹（勾选Don’t create a Star Menu folder）</li><li>选择默认编辑器</li><li>点击Next(Git from the command…)</li><li>使用默认设置就行(use the OpenSSL libuary)</li><li>默认(Checkout Windows-style,…)</li><li>在终端模拟器选择页面，默认即可，配置后Git</li><li>最后配置Git额外选择默认安装</li><li>安装完成（鼠标右键出现Git GUI Here和Git Bash Here）</li></ol><hr><h3 id="2-Node-js安装"><a href="#2-Node-js安装" class="headerlink" title="2 Node.js安装"></a>2 Node.js安装</h3><h4 id="2-1-Node-js下载地址"><a href="#2-1-Node-js下载地址" class="headerlink" title="2.1 Node.js下载地址"></a>2.1 <a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">Node.js下载地址</a></h4><h4 id="2-2-安装步骤"><a href="#2-2-安装步骤" class="headerlink" title="2.2 安装步骤:"></a>2.2 安装步骤:</h4><ol><li>下载完成后，开始安装</li><li>接受协议</li><li>根据自己要安装的地方选择安装目录(我这里选择D:\blog\node.js路径下)</li><li>选择安装项，一般默认</li><li>点击“Install”按钮，开始安装，完成安装</li><li>检验：<ul><li>node -v 查看 node 版本</li><li>npm -v 查看 npm 版本</li></ul></li></ol><hr><h3 id="3、环境配置"><a href="#3、环境配置" class="headerlink" title="3、环境配置"></a>3、环境配置</h3><ol><li>设置环境变量，“我的电脑”-右键-“属性”-“高级系统设置”-“高级”-“环境变量”</li><li>在用户变量里选择Path，点击新建，在弹出的框中点击新建，然后在其中添加D:\blog\Node.js\node_modules</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
            <tag> Nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git常见报错及处理方法</title>
      <link href="/article/d3ea.html"/>
      <url>/article/d3ea.html</url>
      
        <content type="html"><![CDATA[<p>一些常见Git报错处理</p><a id="more"></a><h2 id="Git常见报错及处理方法"><a href="#Git常见报错及处理方法" class="headerlink" title="Git常见报错及处理方法"></a>Git常见报错及处理方法</h2><h3 id="Error-1"><a href="#Error-1" class="headerlink" title="Error 1"></a>Error 1</h3><p><strong>Fatal:remote origin already exists.</strong><br>如果输入<code>$ git remote add origin git@github.com:gkm0120（github帐号名）/gitdemo（项目名）.git</code><br>提示出错信息：<code>fatal: remote origin already exists</code>.</p><h4 id="解决办法："><a href="#解决办法：" class="headerlink" title="解决办法："></a>解决办法：</h4><ol><li>先输入<code>$ git remote rm origin</code></li><li>再输入<code>$ git remote add origin git@github.com:gkm0120/gkm0120.github.io.git</code> 就不会报错了！</li><li>若输入<code>$ git remote rm origin</code> 还是报错的话，error: Could not remove config section ‘remote.origin’. 我们需要修改gitconfig文件的内容</li><li>找到你的github的安装路径，我的是C:/Users/gkm0120/.git</li><li>找到一个名为gitconfig的文件，打开它把里面的[remote “origin”]那一行删掉就好了！</li></ol><h3 id="Error-2"><a href="#Error-2" class="headerlink" title="Error 2"></a>Error 2</h3><p><strong>Permission denied (publickey)</strong><br>如果输入<code>$ ssh -T git@github.com</code>出现错误提示：Permission denied (publickey).因为新生成的key不能加入ssh就会导致连接不上github。</p><h4 id="解决办法：-1"><a href="#解决办法：-1" class="headerlink" title="解决办法："></a>解决办法：</h4><ol><li>先输入<code>$ ssh-agent</code>，再输入$ ssh-add ~/.ssh/id_key，这样就可以了。</li><li>如果还是不行的话，输入ssh-add ~/.ssh/id_key 命令后出现报错Could not open a connection to your authentication agent.解决方法是key用Git Gui的ssh工具生成，这样生成的时候key就直接保存在ssh中了，不需要再ssh-add命令加入了，其它的user，token等配置都用命令行来做。</li><li>最好检查一下在你复制id_rsa.pub文件的内容时有没有产生多余的空格或空行，有些编辑器会帮你添加这些的。</li></ol><h3 id="Error-3"><a href="#Error-3" class="headerlink" title="Error 3"></a>Error 3</h3><p><strong>Failed to push some refs to…</strong><br>如果输入<code>$ git push origin master</code>提示出错信息：error: failed to push some refs to ‘git@github.com:gkm0120/-.git’错误分析：本地没有update到最新版本的项目（git上有README.md文件没下载下来）、本地直接push所以会出错。</p><h4 id="解决办法：-2"><a href="#解决办法：-2" class="headerlink" title="解决办法："></a>解决办法：</h4><h5 id="First"><a href="#First" class="headerlink" title="First"></a>First</h5><p>输入 <code>$ git pull --rebase origin master</code>……显示一串拉代码的英文，此时已经把github上最新的文件，然后在输入git push origin master,即可成功把本地的文件都上传到github上面去了，<code>$ git push origin master</code></p><h5 id="Second"><a href="#Second" class="headerlink" title="Second"></a>Second</h5><ol><li>先输入<code>$ git pull origin master</code> //先把远程服务器github上面的文件拉下来</li><li>再输入<code>$ git push origin master</code></li><li>如果出现报错 fatal: Couldn’t find remote ref master或者fatal: ‘origin’ does not appear to be a git repository以及fatal: Could not read from remote repository.</li><li>则需要重新输入<code>$ git remote add origin git@github.com:gkm0120/gkm0120.github.io.git</code><br>使用git在本地创建一个项目的过程</li></ol><ul><li>$ makdir ~/hello-world //创建一个项目hello-world</li><li>$ cd ~/hello-world  //打开这个项目</li><li>$ git init //初始化</li><li>$ git add README //更新README文件</li><li>$ git commit -m ‘first commit’ //提交更新，并注释信息“first commit”</li><li>$ git remote add origin <a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:gkm0120/gkm0120.github.io.git //连接远程github项目</li><li>$ git push -u origin master //将本地项目更新到github项目上去</li></ul><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://blog.csdn.net/Umbrella_Um/article/details/97271486" target="_blank" rel="noopener">https://blog.csdn.net/Umbrella_Um/article/details/97271486</a></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
